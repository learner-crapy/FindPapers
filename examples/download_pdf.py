from tools.page_extract import download_pdf

import os
import re
import psycopg
import requests

def sanitize_filename(name: str) -> str:
    """ç§»é™¤æ–‡ä»¶åä¸­ä¸å…è®¸çš„å­—ç¬¦"""
    return re.sub(r'[\\/*?:"<>|]', "_", name).strip()

def download_pdf(url: str, file_path: str):
    """ä¸‹è½½ PDF æ–‡ä»¶"""
    try:
        print(f"â¬‡ï¸  Downloading: {url}")
        response = requests.get(url, stream=True, timeout=30)
        response.raise_for_status()

        with open(file_path, "wb") as f:
            for chunk in response.iter_content(1024):
                f.write(chunk)

        print(f"âœ… Saved to: {file_path}\n")
    except Exception as e:
        print(f"âŒ Failed to download {url}: {e}")

def main():
    # ---- æ•°æ®åº“è¿æ¥ ----
    conn = psycopg.connect(
        dbname="dazelu",
        user="",
        password="",
        host="localhost",
        port="5432"
    )
    cur = conn.cursor()

    # ---- æŸ¥è¯¢åŒ¹é…è®ºæ–‡ ----
    query = """
    SELECT link, title
    FROM papers
    WHERE TRUE = ANY(if_match);
    """
    cur.execute(query)
    results = cur.fetchall()

    print(f"ğŸ” Found {len(results)} matched papers.\n")

    # ---- ä¸‹è½½ç›®å½• ----
    save_dir = "downloaded_papers"
    os.makedirs(save_dir, exist_ok=True)

    # ---- éå†ä¸‹è½½ ----
    for link, title in results:
        pdf_link = link.replace("/abs/", "/pdf/")
        safe_title = sanitize_filename(title) + ".pdf"
        file_path = os.path.join(save_dir, safe_title)
        download_pdf(pdf_link, file_path)

    # ---- å…³é—­è¿æ¥ ----
    cur.close()
    conn.close()

if __name__ == "__main__":
    main()