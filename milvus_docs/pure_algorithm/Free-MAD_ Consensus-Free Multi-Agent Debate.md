## FREE-MAD: Consensus-Free Multi-Agent Debate
Yu Cui1Hang Fu1Haibin Zhang2Licheng Wang1Cong Zuo1 1Beijing Institute of Technology 2Yangtze Delta Region Institute of Tsinghua University, Zhejiang cuiyu@bit.edu.cn, bchainzhang@aliyun.com
* * *
## _Abstract_
Multi-agent debate (MAD) is an emerging approach to improving the reasoning
* * *
capabilities of large language models (LLMs). Existing MAD methods rely on multiple rounds of interaction among agents to reach consensus, and the final output is selected by majority voting in the last round. However, this consensus-based design faces several limitations. First, multiple rounds of communication increases token overhead and limits scalability. Second, due to the inherent conformity of LLMs, agents that initially produce correct responses may be influenced by incorrect ones during the debate process, causing error propagation. Third, majority voting introduces randomness and unfairness in the decision-making phase, and can degrade the reasoning performance. To address these issues, we propose FREE-MAD, a novel MAD framework that eliminates the need for consensus among agents. FREE-MAD introduces a novel score-based decision mechanism that evaluates the entire debate trajectory rather than relying on the last round only. This mechanism tracks how each agent’s reason ing evolves, enabling more accurate and fair outcomes. In addition, FREE-MAD reconstructs the debate phase by introducing anti-conformity, a mechanism that enables agents to mitigate excessive influence from the majority. Experiments on eight benchmark datasets demonstrate that FREE-MAD significantly improves reasoning performance while requiring only a single-round debate and thus re ducing token costs. We also show that compared to existing MAD approaches, FREE-MAD exhibits improved robustness in real-world attack scenarios.
* * *
## _1 Introduction_
Large language models (LLMs), due to their strong reasoning capabilities, have been widely applied
* * *
in domains such as chatbots [ 1], programming [ 2], healthcare [ 3,4], and cybersecurity [ 5]. Recently, increasing applications of LLM agents [ 6] have placed increasing demands on the reasoning perfor mance of LLMs. To improve the reasoning accuracy of LLM agents, many studies have explored training-free methods such as Chain-of-Thought (CoT) [7], self-refinement [8] and self-consistency [9]. However, these methods focuses on the usage of single LLMs and lack collaboration among multiple models. In contrast, multi-agent debate (MAD) [ 10–14] has emerged as a prominent solution, showing that multiple agents engaged in multi-round interactions can achieve substantially better rea soning performance than a single agent. Indeed, MAD has been successfully used in various scenarios such as software issue resolution [15], mathematical reasoning [16], and code summarization [17]. Existing efforts to optimize MAD primarily focus on the reasoning strategies of individual agents during debates [ 14] or improving scalability [ 10]. Recent studies reveal that LLM agents can exhibit conformity [ 18–20], meaning that during multi-agent interactions, agents tend to favor answers endorsed by the majority. Indeed, in existing MAD frameworks, conformity-driven consensus [21,10,12,22] during the debate process is required to yield the correct answer as a final decision [13]. However, stronger consensus not only reduces reasoning accuracy, but also demands more Preprint. Under review.arXiv:2509.11035v1 [cs.AI] 14 Sep 2025
* * *
debate rounds, increasing token consumption and limiting scalability. These consensus-based MAD schemes also suffer from the Silent Agreement problem [ 23]. Even when the agents start with divergent opinions, they remain silent during the discussion due to conformity. As a result, the agent group eventually provides an incorrect answer. To address these limitations, we propose FREE-MAD, a consensus-free MAD framework that introduces optimizations in both the debate and decision stages. In the debate stage, we incorporate two complementary modes: conformity and anti-conformity. In particular, the anti-conformity mode leverages CoT to encourage agents to identify flaws in other agents’ outputs, rather than relying on consensus as an indicator of correctness. In the decision stage, we propose a score-based mechanism that evaluates all intermediate outputs across debate rounds, instead of focusing solely on the final round as in traditional MAD frameworks. By tracking changes in the reasoning trajectories of all agents, FREE-MAD assigns scores to all candidate responses without requiring consensus in the debate stage. Furthermore, we theoretically formalize the MAD protocol, enabling a comparative analysis between FREE-MAD and existing MAD variants. Extensive experiments on eight benchmark datasets covering knowledge-based reasoning, logical reasoning, and mathematical reasoning with varying levels of difficulty demonstrate that FREE-MAD achieves significant improvements in reasoning accuracy compared to baseline methods. In particular, FREE-MAD achieves improved accuracy with fewer debate rounds, thus accelerating the debate process while maintaining strong scalability. Furthermore, we show that FREE-MAD exhibits enhanced robustness in real-world deployments. We have the following contributions: •We propose a novel consensus-free MAD framework, called FREE-MAD, with dedicated opti mizations in both the debate and decision stages. We design a score-based decision mechanism that evaluates all intermediate results across debate rounds, enabling accurate reasoning without requiring consensus. •We provide a syntax for the MAD protocol and perform a formal analysis of FREE-MAD and existing mechanisms. •We implement FREE-MAD and conduct extensive experiments on eight benchmarks, showing that FREE-MAD outperforms existing protocols in terms of reasoning accuracy, scalability, and robustness.
* * *
## _2 Related Work_
Evolution of MAD protocols. When MAD was first introduced, it aimed to improve reasoning by
* * *
encouraging LLMs to reach consensus across their answers. However, such consensus cannot be guaranteed in theory and is only generally achievable in practice [ 12]. Moreover, consensus becomes easier to achieve when agents adjust their trust between self-generated and externally generated content, yet this adjustment tends to reduce reasoning accuracy. The researchers did not investigate the deeper conformity issue that underlies this performance drop. Subsequent studies have focused on optimizing the debate stage of MAD [ 13,24,10,25,14]. In these works, consensus is commonly treated as the default goal of the debate stage [ 22]. In this paper, we show that MAD can operate effectively without requiring consensus. MAD protocol security. In the debate stage, traditional consensus-oriented approaches for agents tend to lack robustness in unreliable network environments. Communication attacks [ 26] can force some agents to withdraw from the debate, preventing them from receiving others’ responses. This delays consensus and increases overhead in adaptive schemes [ 25], ultimately reducing reasoning accuracy. Another line of work allows agents to return both their individual responses and a self assessed confidence score [ 24], which is then used in a weighted aggregation of the final result. However, due to LLM hallucinations [ 27], such confidence may be unreliable. Existing decision mechanisms in MAD are inadequate for addressing the security risks associated with LLM conformity. In real-world deployments, if a small subset of agents is compromised via prompt injection attacks [ 28– 30], the system may converge toward a shared but incorrect answer. When decisions are made using mechanisms such as majority voting, this can lead to a complete failure of the MAD system. Other approaches [ 25] use an LLM-as-a-Judge [ 31] framework, where an LLM decides the final outcome. This approach can produce biased results and is prone to conformity, making it effectively equivalent to majority voting. In addition, if the LLM is compromised by a prompt injection attack, the accuracy 2
* * *
of the MAD system’s final output may drop significantly. We discuss related work on agent diversity in MAD further in Appendix B.
* * *
## _3 Preliminary Analysis_
3.1 MAD Protocol: A Formal Two-Phase Decomposition
* * *
To facilitate the subsequent discussion on the derivation details of MAD’s final answer, we decompose the MAD protocol into two core stages:DebateandDecision. The Debate stage internally unfolds overRiterative rounds, culminating in a set of final answers. Formally, given a set of Nagents denoted as{a i}N i=1, the protocol is defined as: {rR i}N i=1←Debate({a i}N i=1, q, p, R)(1) rfinal←Decide({rR i}N i=1)(2) In theDebatestage, all agents engage in a multi-round interaction based on a user query qand a guiding prompt pthat specifies how agents should debate. The debate unfolds over Rrounds. The debate begins with an initial step where each agent generates a preliminary response to q, which is then broadcast to all other agents as an auxiliary context [ 32]. Subsequently, each agent aiiteratively updates its own answer rk ioverRrounds, resulting in a final set of responses {rR i}N i=1. The complete history of utterances up to round k−1 is denoted as the context C(k−1). We model LLM agents as a probabilistic process, which more accurately captures their generative behavior. In round k, agent ai produces its response rk iby sampling from a conditional probability distribution defined over the preceding context andp: rk i∼Pai(r|C(k−1), p).(3) To study the interplay between independent reasoning and conformity, we model the overall probabil ity distributionP aiwith a formulation that separates the contributions of the two factors: Pai(r|C(k−1), p) =1 Z·Pin(r|q, p)·exp(β(p)·S con(r, C(k−1))),(4) where the independent reasoning distribution Pin(r|q, p) mathematically characterizes the agent’s intrinsic reasoning ability given the question qand prompt p. This ability excludes peer influence. The conformity score Scon(r, C(k−1))measures how much a candidate response raligns with peer utterances in C(k−1). Its effect is scaled by the conformity parameter β(p), which is determined byp. By default, LLMs exhibit a tendency to conform. We capture this by assuming βdefault >0 when pis empty or neutral. If pencourages critical reasoning, β(p) can be negative, acting as a regularizer that reduces alignment and pushes responses toward Pin. Conversely, if pencourages agreement with majority opinions, β(p) assumes a larger positive value, which speeds up convergence towards consensus. Finally, the model combines all components via an exponential transformation and normalizes byZto ensure a valid probability distribution. In theDecisionstage, a final output rfinalis selected from {rR i}N i=1, typically through mechanisms such as majority voting. In this work, Rexcludes initial response generation and begins once agents start receiving responses from others. 3.2 Weaknesses of Existing MAD Approaches Reasoning accuracy. MAD approaches [ 12,32,22] design the decision stage1to operate on the final round’sNresponses in the debate, while overlooking the remainingR×Nintermediate responses that emerged throughout the debate process. This omission diminishes the influence of these earlier responses on determining rfinal, thereby reducing both the accuracy and fairness of the final outcome. In consensus-based debates, the process ends once the agents reach agreement, even if the answer is incorrect [ 24,23]. However, Du et al. [12] has shown that it is still possible for the correct answer to emerge during later stages of the debate, even if none of the agents initially generates a correct answer. 1In this work, we focus exclusively on scenarios where only one option can be selected. 3
* * *
User Query Agent 2 Agent 3Agent 1 Ground Truth Answer
* * *
> "C""…Your final answer
must be the letter corresponding to the correct option (e.g., A, B, C, D)…" Correct Answer Wrong Answer Correct Answer"B"
* * *
> "C"
> "C"
Debate StageInitial Answers Sample 2 Sample 3 Sample 1Debate Result Majority Voting"B B C"
* * *
> "B C C"
> "A B C"
Wrong Answer Wrong Answer Correct Answer"B"
* * *
> "C"
> "A"Final Answer
User Query Agent 2 Agent 3Agent 1 Ground Truth Answer
* * *
> "C""…Your final answer
must be the letter corresponding to the correct option (e.g., A, B, C, D)…" Correct Answer Wrong Answer Correct Answer"B"
* * *
> "C"
> "C"
Debate StageInitial Answers Sample 2 Sample 3 Sample 1Debate Result Majority Voting"B B C"
* * *
> "B C C"
> "A B C"
Wrong Answer Wrong Answer Correct Answer"B"
* * *
> "C"
> "A"Final Answer
## _Figure 1: Existing MAD approaches may obtain final answers that are even less accurate than the_
initial ones. Early termination thus reduces MAD’s problem-solving accuracy. From empirical observations, we
* * *
find that the initial responses generated independently by multiple agents may outperform the debate results obtained after applying MAD. As shown in Figure 1, applying majority voting directly to initial answers can yield the correct result, while debate outcomes may be incorrect. We illustrate three possibilities. In Sample 1, the agents reach consensus on an incorrect answer. Sample 2 represents the desired outcome, where the correct answer "C" holds the majority. Outcomes such as Sample 3 have received little attention. The set {ri}N i=1contains entirely distinct outputs, with no repetitions or equal counts for multiple answers. Under these circumstances, the final answer is determined either by selecting a response at random from the set {ri}N i=1or by choosing the first one. Both strategies substantially degrade the accuracy of MAD. Therefore, majority voting is unsuitable for decisions based on debate outcomes. More robust and practical mechanisms are required. Robustness. Most existing multi-agent systems lack byzantine robustness [ 33,34,26]. MAD is even more vulnerable to attacks [ 35] due to its consensus mechanism. Researchers [ 36] mainly enhance the robustness of multi-agent systems by introducing blockchain and leveraging its traditional distributed consensus protocols. However, the use of blockchain, including smart contracts [ 37] and consensus execution [38, 39], significantly reduces overall system performance.
* * *
## _4 Methodology_
In this section, we first provide a formalization to introduce our proposed FREE-MAD (See Section
* * *
4.1). We then present the two core techniques within FREE-MAD: a debate protocol that operates without requiring consensus (See Section 4.2), and a score-based decision mechanism (See Section 4.3). Then, we provide a description of FREE-MAD (See Section 4.4). Finally, we conduct an analysis between FREE-MAD and existing approaches (See Section 4.5). 4.1 FREE-MAD FREE-MAD focuses on the complete set of outcomes generated throughout the entire MAD process, rather than limiting attention to only the final-round responses, as done in traditional approaches. Our proposed debate protocol incorporates all responses into the decision-making process. This perspective can be formally represented using the following matrix formulation: Decide[α 0, α1,..., α R−1, αR] = r0 1r1 1···rR−1 1 rR 1............... r0 Nr1 N···rR−1 N rR N →r final.(5) The highlighted entries represent components that were not considered in previous MAD approaches. r0 idenotes the initial response generated by agent i. Unlike prior MAD frameworks that decouple the debate and decision stages, FREE-MAD innovatively integrates decision-making into the debate phase, resulting in a unified process (See Figure 2). 4.2 Consensus-Free Debate The agents in MAD exchange responses and update their answers based on a prefix prompt. A common prompt is "The responses from other agents are as follows" [ 12]. Due to the conformity 4
* * *
of LLMs, such prompts often bias the agent toward the majority answer. This undermines rigorous reasoning and raises the likelihood that reasoning errors remain unnoticed. To mitigate this conformity, we design an additional CoT-based prompt (see Appendix E) appended after the prefix prompt, motivated by [ 18]. We provide agents with a scenario that includes adversarial agents. We instruct agents to carefully assess the discrepancies between their own answers and those from peers. Agents are expected to change their beliefs only if there is a clear indication that their own answer is incorrect, rather than aiming to reach consensus with others. This mechanism is intended to reduce the propagation of incorrect answers during the MAD process. Our structured and critical reasoning prompt forms the core mechanism for optimizing the probabilis tic model (Equation 4) and has two main effects. First, it improves the quality of the independent reasoning distribution Pin. FREE-MAD requires each agent to provide an answer along with a detailed reasoning trace, which is incorporated into the next-round context C(k−1). Agent aiuses this context to analyze peers’ reasoning rather than just their answers. If the reasoning behind the majority answer is flawed, ai’s own critical thinking will assign a very low probability to that answer inPin. Second, it balances conformity. Even if a popular but incorrect answer has a high Scon, a low Pinkeeps its overall probabilityP ailow. Algorithm 1:MAD Protocol via Score-Based Decision and its Evaluation Input:Answer matrixA∈RN×(R+1)fromNagents overRrounds; List of task inputs and ground truth responsesD task={q i, rg i}; WeightsW={w i}4 i=1; Guiding promptp Output:Accuracy success←0; Initialize empty score dictionaryS← ∅ forq, rginD taskdo fork←0toRdo f= (k+ 1)−1# Initial scoring factor with a non-zero value. fori←1toNdo ifk̸= 0then ContextC←Aggregate responses from other agents in roundk−1 rk i←P ai(q, p); UpdateCandAwithrk i ˆr←A[i][k] ifk= 0then S[ˆr]←S[ˆr] +w 1f# Assign an initial score to the answer. else rp←A[i][k−1]# Find the answer of agenta iin the previous round. ifˆr̸=r pthen ifrp∈Sthen S[rp]←S[r p]−w 2f# The answer has been transferred fromr ptoˆr. S[ˆr]←S[ˆr] +w 3f else S[ˆr]←S[ˆr] +w 4f# The agenta imaintains this answer. Remove keys fromSwhere key isNone. MS←arg maxkS[k] if|MS|>1then Randomly chooser final∈MS# Guarantee robustness. else rfinal←MS[0] success←success+I(r final=rg) Returnsuccess |D| 4.3 Score-Based Decision Mechanism Based on the existing MAD framework [ 12] and formalization of the traditional MAD protocol [ 11], we describe our protocol as shown in Algorithm 1. This method maintains a matrixA∈RN×(R+1) that records the real-time responses of each agent across debate rounds. Concurrently, a score dictionary Sis used to track the scores associated with multiple answers that emerge throughout the debate. The mechanism evaluates the likelihood of an answer being correct by tracking whether agents exhibit a shift in their opinions across rounds (whether the answer provided in the current 5
* * *
round differs from that in the previous round). Since agents in this framework are designed not to seek consensus but to rigorously assess the reasoning behind answers, a change in an agent’s response is interpreted as an indicator that a more accurate answer has been identified. Specifically, answers that agents abandon are considered more likely to be incorrect, whereas newly adopted answers are treated as more likely to be correct. This dynamic informs the score updates within the dictionary S.
* * *
## _Table 1: A comprehensive comparison between our proposed_
approach and existing methods. Approaches Decision Anti-Conformity Fairness Security
* * *
Sparse MADLi et al. [22] Majority V oting✗ ✗ ✗ Liang et al. [25] LLM-as-a-Judge✗ ✗ ✗ ReConcile [24] Weighted V oting✗ ✓ ✗ ChatEval [13] Majority V oting✗ ✗ ✗ DMAD [14] Majority V oting✗ ✗ ✓ SoM [12] Majority V oting✗ ✓ ✓ FREE-MAD-N score✓ ✓ ✓ FREE-MAD-C score✗ ✓ ✓We assign different weights wifto answers based on whether agents have changed their responses between rounds. Here, wi∈ W represents system-defined parameters, and fis a correction factor inversely propor tional to the current round number. As the number of rounds increases, the amount of contextual informa tion each agent receives also grows, thereby increasing the risk of confor mity, particularly for agents based on smaller models. To limit the influence of conformity, the impact of opinion shifts in later rounds is downweighted via the factor f. We define MS as the set of answers with the highest score. Although this set usually contains a single candidate, we adopt a randomized selection strategy to maintain theoretical robustness. 4.4 Framework Design Correct Answer Wrong Answer Correct Answer
* * *
> "B" "C" "C"
Consensus -Free Debate StageInitial Answers Wrong Answer Correct Answer
* * *
> "B" "C"Debate Answers
Wrong Answer
* * *
> "B"
Score Computation
* * *
> "C""B" 35.83
36.67 Final Answer Correct Answer Wrong Answer Correct Answer
* * *
> "B" "C" "C"
Consensus -Free Debate StageInitial Answers Wrong Answer Correct Answer
* * *
> "B" "C"Debate Answers
Wrong Answer
* * *
> "B"
Score Computation
* * *
> "C""B" 35.83
36.67 Final Answer
* * *
## _Figure 2: The inference process of our MAD_
framework. When the correct answers are in the
* * *
minority in the final round, the framework is still able to identify the correct one as the final answer.As noted in [ 18], LLMs’ conformity presents a double-edged sword. On the one hand, it fosters consensus and cohesive outcomes. On the other hand, it undermines the reliability of agents’ judgments in sensitive domains such as voting. Debate based on anti-conformity mitigates the negative effects of blind confor mity among agents. However, for relatively simple tasks, LLMs may show excessive anti conformity, which causes stubbornness and re duces reasoning accuracy. Therefore, we argue that conformity-oriented and anti-conformity oriented debate modes should be adapted and switched according to the task. To achieve finer control over excessive conformity, the weight parameter Win the score mechanism can be adjusted, which regulates the balance between an agent changing its opinion and maintaining its original stance. Based on this idea, we pro pose the FREE-MAD framework consisting of two sub-schemes: FREE-MAD-N, which combines an anti-conformity debate process with a score-based decision stage, and FREE-MAD-C, which combines a conformity-based debate process with a score-based decision stage. These two schemes together enable coverage of a wider range of real-world applications. 4.5 Analysis We compare our proposed FREE-MAD framework with existing MAD approaches, as shown in
* * *
## _Table 1. Below, we provide a detailed analysis of the advantages of FREE-MAD._
Accuracy. The FREE-MAD framework adopts a consensus-free debate strategy, which helps reduce
* * *
the influence of conformity. This approach encourages agents to concentrate more on the correctness of reasoning steps, and may alleviate the effect of error propagation. In addition, existing methods usually require multiple rounds of debate to reach consensus. When the number of rounds Ris small, such as when R= 1, these approaches may experience reduced reasoning performance due to the lack of consensus, which can lead to lower accuracy. In contrast, the performance of FREE-MAD is not closely tied toR. 6
* * *
Scalability. Prior work [ 10] provides a general complexity analysis of the token cost (TC) in MAD as:O  NR2V+N2RV+NR|q|, whereVis the maximum token cost for each agent. Therefore, a practical MAD framework should aim to achieve high accuracy with fewer agents and fewer rounds [ 14]. The consensus-building process generally takes 2 to 3 rounds [ 24,12,32,40] to be effective. In contrast, our method theoretically requires only a single round of debate without any consensus constraint, which substantially reduces token consumption. Security. Under communication attacks, agents that withdraw from the debate process generally trigger only S[ˆr]←S[ˆr] +w 4fin Algorithm 1 under our score scheme, because these agents retain context containing only their own prior responses, which does not affect the overall debate process. In addition, the score strategy is executed entirely outside the LLM reasoning and follows a deterministic protocol, rendering it immune to LLM hallucination. Fairness. During the debate stage, some approaches adopt role-based debate strategies [ 13], where agents are assigned unequal statuses and perform different functions. This design reinforces the implicit biases of LLMs [ 41–43] and undermines the fairness of MAD systems [ 40]. In contrast, agents in FREE-MAD do not require any predefined roles, and all agents participate equally in the debate process.
* * *
## _5 Experiments_
5.1 Experimental Setup
* * *
Evaluation benchmark. Based on the comparison in Table 1 and the analysis in Section 4.5, we select the SoM framework [ 12] as the baseline for our experiments to ensure a fair comparison (SoM is also widely adopted as a baseline in related work [ 24,44,22]). Moreover, our proposed FREE-MAD is implemented on top of SoM to minimize the influence of confounding factors. In Algorithm 1, the weights Ware initialized to {20,25,30,20} based on theoretical analysis. We present the experimental setup for evaluating the security of FREE-MAD in Appendix A. For the ablation study, we compare four schemes, as summarized in Table 2, including our FREE-MAD and the SoM baseline. This comparison highlights the effectiveness of the two core modules we developed.
* * *
## _Table 2: Module configurations of multiple comparative_
variants in ablation experiments. Schemes FREE-MAD-NFREE-MAD-CBaseline 1 Baseline 2 (SoM)
* * *
Debate Anti-conformity Conformity Anti-conformity Conformity Decision Score Score Majority V oting Majority V otingDatasets. To comprehensively evalu ate the capability of FREE-MAD, we conduct experiments on 8 benchmark datasets. For mathematical reasoning, we use GSM-Ranges [ 45] (levels 4 and 6), AIME2024, AIME2025 [ 46], and MATH500 [ 47]. For logical reasoning, we employ StrategyQA [ 48] and the Logical Fallacies dataset of MMLU [ 49]. For knowledge and theoretical reasoning, we adopt the multiple-choice questions dataset from AICrypto [ 50], which constitutes the first benchmark specifically constructed to assess the cryptographic capabilities of LLMs. Agent groups. To ensure that the MAD framework possesses the basic capability to handle our datasets, we design two configurations of MAD. For AIME2024 and AIME2025, we construct MAD with N= 3 based on Qwen1.5-7B-Chat2and DeepSeek-V3 [ 51]. For the other datasets, we uniformly construct MAD with N= 4 using Qwen1.5-7B-Chat and Qwen2.5-72B-Instruct [ 52]. Other details are provided in Appendix. 5.2 Evaluation Metrics To evaluate the reasoning performance and scalability of MAD, we assess both inference accuracy and token consumption. Following [ 10], we adopt token consumption as the metric for scalability. The computation of accuracy follows Algorithm 1, while the calculation of token consumption is defined as follows: TC=RX k=0NX i=1Ti k,(6) 2https://qwenlm.github.io/zh/blog/qwen1.5 7
* * *
GSM-Level4 GSM-Level6 AIME2024 AIME2025 MATH500 Logical Fallacies AICrypto StrategyQA Benchmark Datasets0102030405060708090Accuracy (%)73.75 70.00 53.33 43.3365.0070.0075.00 65.00 65.00 61.25 43.33 36.6766.2572.5075.00 71.25 66.25 63.75 26.67 26.6762.5067.5071.25 61.2560.00 52.50 33.33 26.6765.0066.25 63.7565.00Free-MAD-n Free-MAD-c Baseline 1 Baseline 2GSM-Level4 GSM-Level6 AIME2024 AIME2025 MATH500 Logical Fallacies AICrypto StrategyQA Benchmark Datasets0102030405060708090Accuracy (%)73.75 70.00 53.33 43.3365.0070.0075.00 65.00 65.00 61.25 43.33 36.6766.2572.5075.00 71.25 66.25 63.75 26.67 26.6762.5067.5071.25 61.2560.00 52.50 33.33 26.6765.0066.25 63.7565.00Free-MAD-n Free-MAD-c Baseline 1 Baseline 2Figure 4: Comprehensive comparative experimental results for MAD frameworks across multiple benchmarks.
* * *
## _Table 3: Comparison of reasoning accuracy between our schemes and baselines whenR= 1._
Schemes FREE-MAD-NFREE-MAD-CBaseline 1 Baseline 2
* * *
Accuracy 64.43% (↑16%/19%) 61.41% (↑10%/14%) 55.73% 54.06% whereTi kdenotes the number of output tokens generated by agenta iin thek-th round.
* * *
## _6 Main Results_
6.1 Reasoning Performance
* * *
50 55 60 65 70 75 80 Accuracy (%)100000150000200000250000300000350000400000450000500000 Token Consumption Free-MAD-n (R= 1) Free-MAD-c (R= 1) Baseline 1 (R= 1) Baseline 2 (R= 1)Free-MAD-n (R= 2) Free-MAD-c (R= 2) Baseline 1 (R= 2) Baseline 2 (R= 2)50 55 60 65 70 75 80 Accuracy (%)100000150000200000250000300000350000400000450000500000 Token Consumption Free-MAD-n (R= 1) Free-MAD-c (R= 1) Baseline 1 (R= 1) Baseline 2 (R= 1)Free-MAD-n (R= 2) Free-MAD-c (R= 2) Baseline 1 (R= 2) Baseline 2 (R= 2)
* * *
## _Figure 3: Comparison of token consumption and_
reasoning accuracy between our proposed schemes
* * *
and baselines under different debate rounds.The evaluation results of reasoning accuracy on eight benchmarks are presented in Figure 4 and
* * *
## _Table 4. Overall, our proposed FREE-MAD sub-_
stantially outperforms the baselines, achieving
* * *
average improvements of 13.0% and 16.5% over baselines, respectively. These results demon strate a significant enhancement in reasoning performance. In particular, for mathematical rea soning tasks, the advantage of FREE-MAD be comes more evident with increasing problem dif ficulty. Reducing conformity clearly improves the effectiveness of MAD. The specific effects of conformity and anti-conformity on the reason ing process of LLMs are detailed in Appendix F. Notably, under anti-conformity, the reasoning process of LLMs appears to be more rational. On the MATH500 dataset, we observe that weaker models exhibit a previously mentioned tendency toward rigidity in reasoning when conformity is suppressed. In such cases, these models fail to switch to correct lines of reasoning, resulting in comparable performance between FREE-MAD and the baselines. This limitation is expected, as a fixed set of agents cannot be universally optimal across all task categories. For logical and knowledge-based reasoning, FREE-MAD still significantly outperforms the baselines. However, FREE-MAD-Cconsistently achieves better results than FREE MAD-N, because for models lacking relevant knowledge, idea switching under anti-conformity tends to occur with relatively high randomness. Consequently, in such scenarios, conformity may lead to more effective outcomes. By comparing the four variants in our ablation study, we demonstrate that the proposed core score-based decision mechanism exhibits superior performance. 8
* * *
GSM-Level4MATH500 Logical FallaciesAICryptoFree-MAD-n Free-MAD-c Baseline 1 Baseline 267.50 65.00 71.25 80.00 72.50 65.00 73.75 76.25 47.50 42.50 48.75 66.25 41.25 48.75 60.00 52.50 20 40 60 80 100GSM-Level4MATH500 Logical FallaciesAICryptoFree-MAD-n Free-MAD-c Baseline 1 Baseline 267.50 65.00 71.25 80.00 72.50 65.00 73.75 76.25 47.50 42.50 48.75 66.25 41.25 48.75 60.00 52.50 20 40 60 80 100(a) Experimental results whenR= 1. GSM-Level4MATH500 Logical FallaciesAICryptoFree-MAD-n Free-MAD-c Baseline 1 Baseline 286.25 73.75 81.25 82.50 75.00 65.00 80.00 82.50 65.00 58.75 20.00 17.50 62.50 62.50 21.25 18.75 20 40 60 80 100GSM-Level4MATH500 Logical FallaciesAICryptoFree-MAD-n Free-MAD-c Baseline 1 Baseline 286.25 73.75 81.25 82.50 75.00 65.00 80.00 82.50 65.00 58.75 20.00 17.50 62.50 62.50 21.25 18.75 20 40 60 80 100 (b) Experimental results whenR= 2.
* * *
## _Figure 5: Empirical evaluation of the security of MAD frameworks across multiple benchmarks,_
showing the comparison of their reasoning accuracy under communication attacks across varying
* * *
numbers of rounds. 6.2 Scalability We compared the token consumption and reasoning accuracy of four MAD variants under R= 1 andR= 2, as shown in Figure 3. With an increasing number of debate rounds, the reasoning accuracy of MAD improves. Notably, FREE-MAD achieves accuracy comparable to or even higher than the two-round baseline 2 setting with only a single debate round, while incurring almost no additional token consumption, demonstrating promising scalability. Specifically, FREE-MAD-N achieves stronger reasoning accuracy compared to the baselines, whereas FREE-MAD-Coffers better scalability. More importantly, our approach eliminates the need for multiple debate rounds to reach consensus, which significantly reduces the execution time of the MAD system. 6.3 Security Compared to the normal scenario, both baseline 1 and baseline 2 exhibit a substantial drop in accuracy, reaching up to 20% (See Figure 5). In contrast, FREE-MAD consistently maintains very high accuracy. Interestingly, in some cases, it even slightly outperforms the original accuracy. This behavior can be attributed to the fact that communication attacks prevent some agents from receiving responses from others, while simultaneously reducing the probability of receiving incorrect information. These results demonstrate that FREE-MAD possesses strong robustness and security.
* * *
## _7 Conclusion_
This paper proposes FREE-MAD, a novel MAD framework that integrates controllable conformity
* * *
with a score-based decision mechanism. Unlike traditional MAD approaches, FREE-MAD does not rely on multi-round interactions or need to reach a consensus. By evaluating the entire debate trajectory instead of relying solely on the final round, the accuracy of deciding the answer is improved. Extensive experiments demonstrate that FREE-MAD achieves significantly improved reasoning accuracy, scalability, and resilience compared to baseline protocols.
* * *
## _References_
[1]Weitao Li, Junkai Li, Weizhi Ma, and Yang Liu. Citation-enhanced generation for LLM-based
* * *
chatbots. In Lun-Wei Ku, Andre Martins, and Vivek Srikumar, editors,Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1451–1466, Bangkok, Thailand, August 2024. Association for Computational Linguistics. doi: 10.18653/v1/2024.acl-long.79. URL https://aclanthology.org/2024.acl-long. 79/. [2]Weixiang Yan, Haitian Liu, Yunkun Wang, Yunzhe Li, Qian Chen, Wen Wang, Tingyu Lin, Weishan Zhao, Li Zhu, Hari Sundaram, and Shuiguang Deng. CodeScope: An execution-based multilingual multitask multidimensional benchmark for evaluating LLMs on code understanding 9
* * *
and generation. In Lun-Wei Ku, Andre Martins, and Vivek Srikumar, editors,Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 5511–5558, Bangkok, Thailand, August 2024. Association for Computational Linguistics. doi: 10.18653/v1/2024.acl-long.301. URL https://aclanthology.org/2024. acl-long.301/. [3]Lei Liu, Xiaoyan Yang, Junchi Lei, Yue Shen, Jian Wang, Peng Wei, Zhixuan Chu, Zhan Qin, and Kui Ren. A survey on medical large language models: Technology, application, trustworthiness, and future directions.arXiv preprint arXiv:2406.03712, 2024. [4]Sagar Goyal, Eti Rastogi, Sree Prasanna Rajagopal, Dong Yuan, Fen Zhao, Jai Chintagunta, Gautam Naik, and Jeff Ward. Healai: A healthcare llm for effective medical documentation. In Proceedings of the 17th ACM International Conference on Web Search and Data Mining, WSDM ’24, page 1167–1168, New York, NY, USA, 2024. Association for Computing Machinery. ISBN 9798400703713. doi: 10.1145/3616855.3635739. URL https://doi.org/10.1145/ 3616855.3635739. [5]Yuwen Zou, Yang Hong, Jingyi Xu, Lekun Liu, and Wenjun Fan. Leveraging large language models for challenge solving in capture-the-flag. In2024 IEEE 23rd International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom), pages 1541–1550, 2024. doi: 10.1109/TrustCom63139.2024.00213. [6]Junyu Luo, Weizhi Zhang, Ye Yuan, Yusheng Zhao, Junwei Yang, Yiyang Gu, Bohan Wu, Binqi Chen, Ziyue Qiao, Qingqing Long, et al. Large language model agent: A survey on methodology, applications and challenges.arXiv preprint arXiv:2503.21460, 2025. [7]Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, brian ichter, Fei Xia, Ed Chi, Quoc V Le, and Denny Zhou. Chain-of-thought prompting elicits reasoning in large language models. In S. Koyejo, S. Mohamed, A. Agarwal, D. Belgrave, K. Cho, and A. Oh, editors, Advances in Neural Information Processing Systems, volume 35, pages 24824–24837. Curran Associates, Inc., 2022. URL https://proceedings.neurips.cc/paper_files/paper/ 2022/file/9d5609613524ecf4f15af0f7b31abca4-Paper-Conference.pdf. [8]Aman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hallinan, Luyu Gao, Sarah Wiegreffe, Uri Alon, Nouha Dziri, Shrimai Prabhumoye, Yiming Yang, Shashank Gupta, Bodhisattwa Prasad Majumder, Katherine Hermann, Sean Welleck, Amir Yazdanbakhsh, and Peter Clark. Self-refine: iterative refinement with self-feedback. InProceedings of the 37th International Conference on Neural Information Processing Systems, NIPS ’23, Red Hook, NY, USA, 2023. Curran Associates Inc. [9]Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc V Le, Ed H. Chi, Sharan Narang, Aakanksha Chowdhery, and Denny Zhou. Self-consistency improves chain of thought reasoning in language models. InThe Eleventh International Conference on Learning Representations, 2023. URL https://openreview.net/forum?id=1PL1NIMMrw. [10] Yuting Zeng, Weizhe Huang, Lei Jiang, Tongxuan Liu, XiTai Jin, Chen Tianying Tiana, Jing Li, and Xiaohua Xu. S2-MAD: Breaking the token barrier to enhance multi-agent debate efficiency. In Luis Chiruzzo, Alan Ritter, and Lu Wang, editors,Proceedings of the 2025 Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers), pages 9393–9408, Albuquerque, New Mexico, April 2025. Association for Computational Linguistics. ISBN 979-8-89176-189-6. doi: 10.18653/v1/2025.naacl-long.475. URL https://aclanthology.org/2025.naacl-long. 475/. [11] Vighnesh Subramaniam, Yilun Du, Joshua B. Tenenbaum, Antonio Torralba, Shuang Li, and Igor Mordatch. Multiagent finetuning: Self improvement with diverse reasoning chains. In The Thirteenth International Conference on Learning Representations, 2025. URL https: //openreview.net/forum?id=JtGPIZpOrz. [12] Yilun Du, Shuang Li, Antonio Torralba, Joshua B. Tenenbaum, and Igor Mordatch. Improving factuality and reasoning in language models through multiagent debate. InProceedings of the 41st International Conference on Machine Learning, ICML’24. JMLR.org, 2024. 10
* * *
[13] Chi-Min Chan, Weize Chen, Yusheng Su, Jianxuan Yu, Wei Xue, Shanghang Zhang, Jie Fu, and Zhiyuan Liu. Chateval: Towards better LLM-based evaluators through multi-agent debate. InThe Twelfth International Conference on Learning Representations, 2024. URL https://openreview.net/forum?id=FQepisCUWu. [14] Yexiang Liu, Jie Cao, Zekun Li, Ran He, and Tieniu Tan. Breaking mental set to improve reasoning through diverse multi-agent debate. InThe Thirteenth International Conference on Learning Representations, 2025. URL https://openreview.net/forum?id=t6QHYUOQL7. [15] Han Li, Yuling Shi, Shaoxin Lin, Xiaodong Gu, Heng Lian, Xin Wang, Yantao Jia, Tao Huang, and Qianxiang Wang. Swe-debate: Competitive multi-agent debate for software issue resolution. arXiv preprint arXiv:2507.23348, 2025. [16] Shaowei Zhang and Deyi Xiong. Debate4MATH: Multi-agent debate for fine-grained reasoning in math. In Wanxiang Che, Joyce Nabende, Ekaterina Shutova, and Mohammad Taher Pilehvar, editors,Findings of the Association for Computational Linguistics: ACL 2025, pages 16810– 16824, Vienna, Austria, July 2025. Association for Computational Linguistics. ISBN 979-8 89176-256-5. doi: 10.18653/v1/2025.findings-acl.862. URL https://aclanthology.org/ 2025.findings-acl.862/. [17] Jina Chun, Qihong Chen, Jiawei Li, and Iftekhar Ahmed. Is multi-agent debate (mad) the silver bullet? an empirical analysis of mad in code summarization and translation.arXiv preprint arXiv:2503.12029, 2025. [18] Zhiyuan Weng, Guikun Chen, and Wenguan Wang. Do as we do, not as you think: the conformity of large language models. InThe Thirteenth International Conference on Learning Representations, 2025. URLhttps://openreview.net/forum?id=st77ShxP1K. [19] Xiaochen Zhu, Caiqi Zhang, Tom Stafford, Nigel Collier, and Andreas Vlachos. Conformity in large language models. In Wanxiang Che, Joyce Nabende, Ekaterina Shutova, and Moham mad Taher Pilehvar, editors,Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 3854–3872, Vienna, Austria, July 2025. Association for Computational Linguistics. ISBN 979-8-89176-251-0. doi: 10.18653/v1/ 2025.acl-long.195. URLhttps://aclanthology.org/2025.acl-long.195/. [20] Young-Min Cho, Sharath Chandra Guntuku, and Lyle Ungar. Herd behavior: Investigating peer influence in llm-based multi-agent systems, 2025. URL https://arxiv.org/abs/2505. 21588. [21] Qiushi Sun, Zhangyue Yin, Xiang Li, Zhiyong Wu, Xipeng Qiu, and Lingpeng Kong. Corex: Pushing the boundaries of complex reasoning through multi-model collaboration. InICLR 2024 Workshop on Large Language Model (LLM) Agents, 2024. URL https://openreview.net/ forum?id=cCQRjpOru5. [22] Yunxuan Li, Yibing Du, Jiageng Zhang, Le Hou, Peter Grabowski, Yeqing Li, and Eugene Ie. Improving multi-agent debate with sparse communication topology. In Yaser Al-Onaizan, Mohit Bansal, and Yun-Nung Chen, editors,Findings of the Association for Computational Linguistics: EMNLP 2024, pages 7281–7294, Miami, Florida, USA, November 2024. Association for Computational Linguistics. doi: 10.18653/v1/2024.findings-emnlp.427. URL https:// aclanthology.org/2024.findings-emnlp.427/. [23] Yihan Wang, Qiao Yan, Zhenghao Xing, Lihao Liu, Junjun He, Chi-Wing Fu, Xiaowei Hu, and Pheng-Ann Heng. Silence is not consensus: Disrupting agreement bias in multi-agent llms via catfish agent for clinical decision making.arXiv preprint arXiv:2505.21503, 2025. [24] Justin Chen, Swarnadeep Saha, and Mohit Bansal. ReConcile: Round-table conference improves reasoning via consensus among diverse LLMs. In Lun-Wei Ku, Andre Martins, and Vivek Srikumar, editors,Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 7066–7085, Bangkok, Thailand, August 2024. Association for Computational Linguistics. doi: 10.18653/v1/2024.acl-long.381. URL https: //aclanthology.org/2024.acl-long.381/. 11
* * *
[25] Tian Liang, Zhiwei He, Wenxiang Jiao, Xing Wang, Yan Wang, Rui Wang, Yujiu Yang, Shuming Shi, and Zhaopeng Tu. Encouraging divergent thinking in large language models through multi-agent debate. In Yaser Al-Onaizan, Mohit Bansal, and Yun-Nung Chen, editors, Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing, pages 17889–17904, Miami, Florida, USA, November 2024. Association for Computational Linguistics. doi: 10.18653/v1/2024.emnlp-main.992. URL https://aclanthology.org/ 2024.emnlp-main.992/. [26] Pengfei He, Yuping Lin, Shen Dong, Han Xu, Yue Xing, and Hui Liu. Red-teaming LLM multi-agent systems via communication attacks. In Wanxiang Che, Joyce Nabende, Ekaterina Shutova, and Mohammad Taher Pilehvar, editors,Findings of the Association for Computa tional Linguistics: ACL 2025, pages 6726–6747, Vienna, Austria, July 2025. Association for Computational Linguistics. ISBN 979-8-89176-256-5. doi: 10.18653/v1/2025.findings-acl.349. URLhttps://aclanthology.org/2025.findings-acl.349/. [27] Ziwei Ji, Tiezheng Yu, Yan Xu, Nayeon Lee, Etsuko Ishii, and Pascale Fung. Towards mitigating LLM hallucination via self reflection. In Houda Bouamor, Juan Pino, and Kalika Bali, editors, Findings of the Association for Computational Linguistics: EMNLP 2023, pages 1827–1843, Singapore, December 2023. Association for Computational Linguistics. doi: 10.18653/v1/2023. findings-emnlp.123. URLhttps://aclanthology.org/2023.findings-emnlp.123/. [28] Kai Greshake, Sahar Abdelnabi, Shailesh Mishra, Christoph Endres, Thorsten Holz, and Mario Fritz. Not what you’ve signed up for: Compromising real-world llm-integrated applications with indirect prompt injection. InProceedings of the 16th ACM Workshop on Artificial Intelligence and Security, AISec ’23, page 79–90, New York, NY, USA, 2023. Association for Computing Machinery. ISBN 9798400702600. doi: 10.1145/3605764.3623985. URL https://doi.org/ 10.1145/3605764.3623985. [29] Yupei Liu, Yuqi Jia, Runpeng Geng, Jinyuan Jia, and Neil Zhenqiang Gong. Formalizing and benchmarking prompt injection attacks and defenses. In33rd USENIX Security Sym posium (USENIX Security 24), pages 1831–1847, Philadelphia, PA, August 2024. USENIX Association. ISBN 978-1-939133-44-1. URL https://www.usenix.org/conference/ usenixsecurity24/presentation/liu-yupei. [30] Qiusi Zhan, Richard Fang, Henil Shalin Panchal, and Daniel Kang. Adaptive attacks break defenses against indirect prompt injection attacks on LLM agents. In Luis Chiruzzo, Alan Ritter, and Lu Wang, editors,Findings of the Association for Computational Linguistics: NAACL 2025, pages 7101–7117, Albuquerque, New Mexico, April 2025. Association for Computational Linguistics. ISBN 979-8-89176-195-7. doi: 10.18653/v1/2025.findings-naacl.395. URL https://aclanthology.org/2025.findings-naacl.395/. [31] Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric Xing, Hao Zhang, Joseph E Gonzalez, and Ion Stoica. Judging llm-as-a-judge with mt-bench and chatbot arena. In A. Oh, T. Nau mann, A. Globerson, K. Saenko, M. Hardt, and S. Levine, editors,Advances in Neu ral Information Processing Systems, volume 36, pages 46595–46623. Curran Associates, Inc., 2023. URL https://proceedings.neurips.cc/paper_files/paper/2023/file/ 91f18a1287b398d378ef22505bf41832-Paper-Datasets_and_Benchmarks.pdf. [32] Yongjin Yang, Euiin Yi, Jongwoo Ko, Kimin Lee, Zhijing Jin, and Se-Young Yun. Revisiting multi-agent debate as test-time scaling: A systematic study of conditional effectiveness.arXiv preprint arXiv:2505.22960, 2025. [33] Bei Chen, Gaolei Li, Xi Lin, Zheng Wang, and Jianhua Li. Blockagents: Towards byzantine robust llm-based multi-agent coordination via blockchain. InProceedings of the ACM Turing Award Celebration ConferenceChina 2024, ACM-TURC ’24, page 187–192, New York, NY, USA, 2024. Association for Computing Machinery. ISBN 9798400710117. doi: 10.1145/ 3674399.3674445. URLhttps://doi.org/10.1145/3674399.3674445. [34] Boyang Zhang, Yicong Tan, Yun Shen, Ahmed Salem, Michael Backes, Savvas Zannettou, and Yang Zhang. Breaking agents: Compromising autonomous llm agents through malfunction amplification.arXiv preprint arXiv:2407.20859, 2024. 12
* * *
[35] Senmao Qi, Yifei Zou, Peng Li, Ziyi Lin, Xiuzhen Cheng, and Dongxiao Yu. Amplified vulnerabilities: Structured jailbreak attacks on llm-based multi-agent debate.arXiv preprint arXiv:2504.16489, 2025. [36] Haoxiang Luo, Gang Sun, Yinqiu Liu, Dongcheng Zhao, Dusit Niyato, Hongfang Yu, and Schahram Dustdar. A weighted byzantine fault tolerance consensus driven trusted multiple large language models network.arXiv preprint arXiv:2505.05103, 2025. [37] Huizhong Li, Yujie Chen, Xiang Shi, Xingqiang Bai, Nan Mo, Wenlin Li, Rui Guo, Zhang Wang, and Yi Sun. Fisco-bcos: An enterprise-grade permissioned blockchain system with high-performance. InProceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis, SC ’23, New York, NY, USA, 2023. Association for Computing Machinery. ISBN 9798400701092. doi: 10.1145/3581784.3607053. URL https://doi.org/10.1145/3581784.3607053. [38] Haibin Zhang, Sisi Duan, Boxin Zhao, and Liehuang Zhu. Waterbear: practical asynchronous bft matching security guarantees of partially synchronous bft. InProceedings of the 32nd USENIX Conference on Security Symposium, SEC ’23, USA, 2023. USENIX Association. ISBN 978-1-939133-37-3. [39] Sisi Duan, Michael K. Reiter, and Haibin Zhang. Beat: Asynchronous bft made practical. In Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security, CCS ’18, page 2028–2041, New York, NY, USA, 2018. Association for Computing Machinery. ISBN 9781450356930. doi: 10.1145/3243734.3243812. URL https://doi.org/10.1145/ 3243734.3243812. [40] Kai Xiong, Xiao Ding, Yixin Cao, Ting Liu, and Bing Qin. Examining inter-consistency of large language models collaboration: An in-depth analysis via debate. InThe 2023 Conference on Empirical Methods in Natural Language Processing, 2023. URL https://openreview. net/forum?id=XEwQ1fDbDN. [41] Ishwara Vasista, Imran Mirza, Cole Huang, Rohan Rajasekhara Patil, Aslihan Akalin, Kevin Zhu, and Sean O’Brien. MALIBU benchmark: Multi-agent LLM implicit bias uncovered. In ICLR 2025 Workshop on Building Trust in Language Models and Applications, 2025. URL https://openreview.net/forum?id=iilhN2MycO. [42] Junho Myung, Yeon Su Park, Sunwoo Kim, Shin Yoo, and Alice Oh. PapersPlease: A benchmark for evaluating motivational values of large language models based on ERG theory. In Ofir Arviv, Miruna Clinciu, Kaustubh Dhole, Rotem Dror, Sebastian Gehrmann, Eliya Habba, Itay Itzhak, Simon Mille, Yotam Perlitz, Enrico Santus, João Sedoc, Michal Shmueli Scheuer, Gabriel Stanovsky, and Oyvind Tafjord, editors,Proceedings of the Fourth Workshop on Generation, Evaluation and Metrics (GEM²), pages 522–531, Vienna, Austria and virtual meeting, July 2025. Association for Computational Linguistics. ISBN 979-8-89176-261-9. URLhttps://aclanthology.org/2025.gem-1.47/. [43] Alex Kim, Keonwoo Kim, and Sangwon Yoon. DEBATE: Devil’s advocate-based assessment and text evaluation. In Lun-Wei Ku, Andre Martins, and Vivek Srikumar, editors,Findings of the Association for Computational Linguistics: ACL 2024, pages 1885–1897, Bangkok, Thailand, August 2024. Association for Computational Linguistics. doi: 10.18653/v1/2024.findings-acl. 112. URLhttps://aclanthology.org/2024.findings-acl.112/. [44] Haotian Wang, Xiyuan Du, Weijiang Yu, Qianglong Chen, Kun Zhu, Zheng Chu, Lian Yan, and Yi Guan. Learning to break: Knowledge-enhanced reasoning in multi-agent debate system. Neurocomputing, 618:129063, 2025. [45] Safal Shrestha, Minwu Kim, and Keith Ross. Mathematical reasoning in large language models: Assessing logical and arithmetic errors across wide numerical ranges.arXiv preprint arXiv:2502.08680, 2025. [46] Art of Problem Solving. AIME Problems and Solutions, 2025. URL https:// artofproblemsolving.com/wiki/index.php/AIME_Problems_and_Solutions. Ac cessed: 2025-05-15. 13
* * *
[47] Hunter Lightman, Vineet Kosaraju, Yuri Burda, Harrison Edwards, Bowen Baker, Teddy Lee, Jan Leike, John Schulman, Ilya Sutskever, and Karl Cobbe. Let’s verify step by step. InThe Twelfth International Conference on Learning Representations, 2024. URL https: //openreview.net/forum?id=v8L0pN6EOi. [48] Mor Geva, Daniel Khashabi, Elad Segal, Tushar Khot, Dan Roth, and Jonathan Berant. Did aristotle use a laptop? a question answering benchmark with implicit reasoning strategies. Transactions of the Association for Computational Linguistics, 9:346–361, 2021. doi: 10.1162/ tacl_a_00370. URLhttps://aclanthology.org/2021.tacl-1.21/. [49] Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob Steinhardt. Measuring massive multitask language understanding.Proceedings of the International Conference on Learning Representations (ICLR), 2021. [50] Yu Wang, Yijian Liu, Liheng Ji, Han Luo, Wenjie Li, Xiaofei Zhou, Chiyun Feng, Puji Wang, Yuhan Cao, Geyuan Zhang, et al. Aicrypto: A comprehensive benchmark for evaluating cryptography capabilities of large language models.arXiv preprint arXiv:2507.09580, 2025. [51] DeepSeek-AI, Aixin Liu, Bei Feng, Bing Xue, Bingxuan Wang, Bochao Wu, Chengda Lu, Chenggang Zhao, Chengqi Deng, Chenyu Zhang, Chong Ruan, Damai Dai, Daya Guo, Dejian Yang, Deli Chen, Dongjie Ji, Erhang Li, Fangyun Lin, Fucong Dai, Fuli Luo, Guangbo Hao, Guanting Chen, Guowei Li, H. Zhang, Han Bao, Hanwei Xu, Haocheng Wang, Haowei Zhang, Honghui Ding, Huajian Xin, Huazuo Gao, Hui Li, Hui Qu, J. L. Cai, Jian Liang, Jianzhong Guo, Jiaqi Ni, Jiashi Li, Jiawei Wang, Jin Chen, Jingchang Chen, Jingyang Yuan, Junjie Qiu, Junlong Li, Junxiao Song, Kai Dong, Kai Hu, Kaige Gao, Kang Guan, Kexin Huang, Kuai Yu, Lean Wang, Lecong Zhang, Lei Xu, Leyi Xia, Liang Zhao, Litong Wang, Liyue Zhang, Meng Li, Miaojun Wang, Mingchuan Zhang, Minghua Zhang, Minghui Tang, Mingming Li, Ning Tian, Panpan Huang, Peiyi Wang, Peng Zhang, Qiancheng Wang, Qihao Zhu, Qinyu Chen, Qiushi Du, R. J. Chen, R. L. Jin, Ruiqi Ge, Ruisong Zhang, Ruizhe Pan, Runji Wang, Runxin Xu, Ruoyu Zhang, Ruyi Chen, S. S. Li, Shanghao Lu, Shangyan Zhou, Shanhuang Chen, Shaoqing Wu, Shengfeng Ye, Shengfeng Ye, Shirong Ma, Shiyu Wang, Shuang Zhou, Shuiping Yu, Shunfeng Zhou, Shuting Pan, T. Wang, Tao Yun, Tian Pei, Tianyu Sun, W. L. Xiao, Wangding Zeng, Wanjia Zhao, Wei An, Wen Liu, Wenfeng Liang, Wenjun Gao, Wenqin Yu, Wentao Zhang, X. Q. Li, Xiangyue Jin, Xianzu Wang, Xiao Bi, Xiaodong Liu, Xiaohan Wang, Xiaojin Shen, Xiaokang Chen, Xiaokang Zhang, Xiaosha Chen, Xiaotao Nie, Xiaowen Sun, Xiaoxiang Wang, Xin Cheng, Xin Liu, Xin Xie, Xingchao Liu, Xingkai Yu, Xinnan Song, Xinxia Shan, Xinyi Zhou, Xinyu Yang, Xinyuan Li, Xuecheng Su, Xuheng Lin, Y. K. Li, Y. Q. Wang, Y. X. Wei, Y. X. Zhu, Yang Zhang, Yanhong Xu, Yanhong Xu, Yanping Huang, Yao Li, Yao Zhao, Yaofeng Sun, Yaohui Li, Yaohui Wang, Yi Yu, Yi Zheng, Yichao Zhang, Yifan Shi, Yiliang Xiong, Ying He, Ying Tang, Yishi Piao, Yisong Wang, Yixuan Tan, Yiyang Ma, Yiyuan Liu, Yongqiang Guo, Yu Wu, Yuan Ou, Yuchen Zhu, Yuduan Wang, Yue Gong, Yuheng Zou, Yujia He, Yukun Zha, Yunfan Xiong, Yunxian Ma, Yuting Yan, Yuxiang Luo, Yuxiang You, Yuxuan Liu, Yuyang Zhou, Z. F. Wu, Z. Z. Ren, Zehui Ren, Zhangli Sha, Zhe Fu, Zhean Xu, Zhen Huang, Zhen Zhang, Zhenda Xie, Zhengyan Zhang, Zhewen Hao, Zhibin Gou, Zhicheng Ma, Zhigang Yan, Zhihong Shao, Zhipeng Xu, Zhiyu Wu, Zhongyu Zhang, Zhuoshu Li, Zihui Gu, Zijia Zhu, Zijun Liu, Zilin Li, Ziwei Xie, Ziyang Song, Ziyi Gao, and Zizheng Pan. Deepseek-v3 technical report. arXiv preprint arXiv:2412.19437, 2024. [52] Qwen, An Yang, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, Chengyuan Li, Dayiheng Liu, Fei Huang, Haoran Wei, Huan Lin, Jian Yang, Jianhong Tu, Jianwei Zhang, Jianxin Yang, Jiaxi Yang, Jingren Zhou, Junyang Lin, Kai Dang, Keming Lu, Keqin Bao, Kexin Yang, Le Yu, Mei Li, Mingfeng Xue, Pei Zhang, Qin Zhu, Rui Men, Runji Lin, Tianhao Li, Tianyi Tang, Tingyu Xia, Xingzhang Ren, Xuancheng Ren, Yang Fan, Yang Su, Yichang Zhang, Yu Wan, Yuqiong Liu, Zeyu Cui, Zhenru Zhang, and Zihan Qiu. Qwen2.5 technical report, 2025. URLhttps://arxiv.org/abs/2412.15115. [53] Daya Guo, Dejian Yang, Haowei Zhang, Junxiao Song, Ruoyu Zhang, Runxin Xu, Qihao Zhu, Shirong Ma, Peiyi Wang, Xiao Bi, et al. Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning.arXiv preprint arXiv:2501.12948, 2025. 14
* * *
[54] Long Phan, Alice Gatti, Ziwen Han, Nathaniel Li, Josephina Hu, Hugh Zhang, Chen Bo Calvin Zhang, Mohamed Shaaban, John Ling, Sean Shi, et al. Humanity’s last exam.arXiv preprint arXiv:2501.14249, 2025. 15
* * *
## A FREE-MAD under Communication Attacks and its Evaluation
For the security evaluation, we construct MAD under communication attacks based on Algorithm 2, and apply the same modification to the SoM framework to serve as a baseline for comparison. Specifically, in the modified setting, we perform the operation of aggregating responses from other agents only for the Context Cof agents that are not under attack. The compromised agent is unable to receive responses from other agents, while the other agents can still receive the outputs generated by this agent. We evaluate the accuracy of MAD across multiple benchmark datasets by setting the proportion of compromised agents to |V|/|N|= 50% (see Algorithm 2), which better reflects the adversarial capability in real-world deployments. We evaluate the security of the MAD framework under communication attacks on four datasets: GSM-Ranges (Level 4), MATH500, Logical Fallacies, and AICrypto. Algorithm 2:FREE-MAD under Communication Attacks Input:Answer matrixA∈RN×(R+1)fromNagents overRrounds; List of task inputs and ground truth responsesD task={q i, rg i}; WeightsW={w i}4 i=1; Guiding promptp; Agents under attackV={v i}L i=1 Output:Accuracy success←0; Initialize empty score dictionaryS← ∅ forq, rginD taskdo fork←0toRdo f= (k+ 1)−1# Initial scoring factor with a non-zero value. fori←1toNdo ifk̸= 0anda i/∈ Vthen ContextC←Aggregate responses from other agents in roundk−1 rk i←P ai(q, p); UpdateCandAwithrk i ˆr←A[i][k] ifk= 0then S[ˆr]←S[ˆr] +w 1f# Assign an initial score to the answer. else rp←A[i][k−1]# Find the answer of agenta iin the previous round. ifˆr̸=r pthen ifrp∈Sthen S[rp]←S[r p]−w 2f# The answer has been transferred fromr ptoˆr. S[ˆr]←S[ˆr] +w 3f else S[ˆr]←S[ˆr] +w 4f# The agenta imaintains this answer. Remove keys fromSwhere key isNone. MS←arg maxkS[k] if|MS|>1then Randomly chooser final∈MS# Guarantee robustness. else rfinal←MS[0] success←success+I(r final=rg) Accuracy←success |D| ReturnAccuracy B Additional Related Work Agent diversity in MAD. In previous studies, although some MAD frameworks have considered heterogeneity and diversity among agents, their experimental evaluations were typically conducted using LLMs with similar model sizes [ 32], such as Llama3.1-8B3, Qwen2.5-7B4, and Gemma-2-9B5. This setup significantly limits the effectiveness of MAD and, in certain cases, results in worse performance than self-consistency approaches. In real-world deployments, however, we aim to enable 3https://huggingface.co/meta-llama/Llama-3.1-8B 4https://huggingface.co/Qwen/Qwen2.5-7B 5https://huggingface.co/google/gemma-2-9b 16
* * *
collaboration among diverse LLMs, each possessing different strengths [ 13,14], to act as equal peers within a MAD framework. Such collaboration is expected to outperform the strongest single agent on the same task and to solve a broader range of problems through cooperation, analogous to human team-based collaboration. However, when the participating agents in a heterogeneous MAD system exhibit substantial differ ences in their capabilities, it may lead to significant variance in their confidence regarding their own responses. As a consequence of conformity in LLMs [ 18], agents may tend to adopt the outputs of peers, even when those outputs are incorrect. While conformity can be beneficial in facilitating consensus, it also introduces detrimental effects that require external mitigation. Consensus in MAD. Reaching consensus was the fundamental objective when MAD was first proposed [ 12]. It is also a necessary condition for obtaining a correct final answer. To the best of our knowledge, all existing MAD methods adopt consensus as a core mechanism in their underlying design [22]. Chan et al. [13] does not explicitly require agents to reach consensus during the debate stage. However, it still applies majority voting in the decision phase, which preserves the essential logic of consensus. C Experimental Setup In our experiments, we selected eight datasets to comprehensively cover different types of tasks. Regarding the number of samples, we referred to the configuration used in prior work [ 14,12]. Specifically, we employed the complete datasets for AIME2024 and AIME2025, while for the other datasets we selected 80 samples for evaluation. All model queries were conducted through APIs, and the temperature parameter (when supported) was set to its default value. To mitigate the influence of randomness in the evaluation, we reported outcomes that tend toward the middle of repeated runs. For consistency, we calculate tokens uniformly using the DeepSeek-V3 tokenizer6. To enable support for heterogeneous agents, we apply minor modifications to SoM. D Additional Experimental Results
* * *
## _Table 4: Comparison of reasoning accuracy between our schemes and baselines whenR= 2._
Benchmarks GSM-Level4 GSM-Level6 MATH500 Logical Fallacies AICrypto StrategyQA A VG
* * *
FREE-MAD-N 75.00 66.25 65.00 71.25 76.25 68.75 70.42 FREE-MAD-C 75.00 61.25 66.25 71.25 72.50 68.75 69.17 Baseline 1 70.00 58.75 53.75 68.75 58.75 65.00 62.50 Baseline 2 62.50 56.25 58.75 70.00 63.75 65.00 62.71 E Prompt The core prompt for constructing a consensus-free debate is as follows: 6https://api-docs.deepseek.com/quick_start/token_usage 17
* * *
## Core Prompt to Mitigating Conformity
> "Since some malicious agents may deliberately disseminate incorrect answers, you must follow the reasoning
procedure below and avoid being misled. 1. Initial Reasoning Clearly enumerate your initial logical steps and the final conclusion. 2. Analysis of Other Agents’ Reasoning Specify which agents’ reasoning is correct and which contains errors, and identify the exact type of error. You must provide concrete error descriptions rather than general comments. Note that the correct answer may not exist within the current set of answers. 3. Comparative Analysis with Your Own Reasoning Examine whether you have made similar mistakes and provide justification for your assessment. 4. Final Decision Indicate whether you will revise your conclusion (Yes/No). If yes, explain the reasoning errors; if no, justify why your reasoning stands. 5. Additional Requirements You may not rely on the principle of conformity. Majority opinion cannot be used as a basis for adoption. If you cannot definitively determine whether others are correct, you should retain your own conclusion. Each round of reasoning must independently identify errors and must not directly replicate the analysis or conclusions of other agents." 18
* * *
F Responses The responses of agents across different debate modes (including conformity and anti-conformity) are compared on various benchmark datasets, under the condition ofR= 1. GSM-Level4 Question: Raymond and Samantha are cousins. Raymond was born 158360 years before Samantha. Raymond had a son at the age of 248911. If Samantha is now 343769 years old, how many years ago was Raymond’s son born? Conformity: I apologize for the confusion. Upon reviewing the calculations, it seems there is a mistake in the first two solutions. The correct approach is to subtract Samantha’s current age from the age of Raymond when he had his son, as the son’s birth is what we’re looking for in terms of years ago. Here’s the corrected solution: Raymond’s son was born when he was 248911 years old, and Samantha is currently 343769 years old. The difference in their ages is: 343769−248911 = 94858years This is the number of years that have passed since Raymond had his son. Since we want to find out how many years ago the son was born, we subtract this from Samantha’s current age: 343769−94858 = 248911 So, Raymond’s son was born 248,911 years ago. The final answer is 248911. This matches the last agent’s solution, which is accurate. Anti-conformity: 1. Initial ReasoningCalculate the difference in their ages: Samantha’s age (343769) minus the son’s birth year (248911).Subtract this difference from Samantha’s current age to find out how many years ago the son was born. 2. Analysis of Other Agents’ ReasoningAgent 1 correctly calculates the difference in ages and then adds the birth difference for Raymond (158360) to find the years until the son’s birth. Their error is in assuming that the son’s age at the time of Samantha’s current age equals zero, which leads to a negative result. This is a sign of miscalculation.Agent 2 also performs the same calculation correctly but then subtracts the difference in years to find out how many years ago the son was born, which is correct.Agent 3 makes a mistake by subtracting the difference in years directly without considering the birth difference for Raymond. This results in an incorrect answer. 3. Comparative Analysis with My Own ReasoningI agree with both Agent 2 and myself, as we both correctly calculate the years until the son’s birth by adding the birth difference for Raymond to the difference in ages.My reasoning does not contain any errors like the other agents. 4. Final DecisionBased on the comparison, my reasoning is correct, and I will not revise my conclusion. 5. Additional RequirementsSince both Agent 2 and my own reasoning are correct, there is no need for further revision or additional explanation. Final Answer:94858 (the same as Agent 2’s answer) 19
* * *
GSM-Level6 Question: After scoring 1213526 points, Erin now has 5700191 times more points than Sara, who scored 9. How many points did Erin have before? Conformity: I apologize for the confusion in my previous response. Upon reevaluating the problem, I see that the second agent’s solution is correct. The problem states that Sara scored 9 points, and Erin has 5700191 times more points than Sara. So, we can directly calculate Erin’s initial score without needing to subtract any points. Here’s the corrected reasoning and answer... So, the answer is 51301808. This is the correct number of points Erin had before adding the 5700191 times more points. Anti-conformity: 1. Initial Reasoning: I understand that the problem states that Erin currently has 1,213,526 points and is 570,0191 times more points than Sara, who scored 9 points. To find Erin’s original score, I need to subtract the additional points she gained from her current score... 2. Analysis of Other Agents’ Reasoning:The first agent’s solution incorrectly multiplies Sara’s score by 570,0191 without considering that this is the additional points, leading to a negative result. This is a mathematical error.The second agent’s solution also makes a similar mistake by directly adding the 570,0191 to Sara’s score without adjusting for the additional points.The third agent’s solution appears to be correct, as they subtract the additional points from the current score, which is the proper approach. 3. Comparative Analysis with My Own Reasoning: Both the first and second agents’ approaches contain the same error: they add the additional points directly to Sara’s score instead of subtracting them from Erin’s current score. I will follow the correct method from the third agent. 4. Final Decision: I will revise my conclusion based on the third agent’s reasoning... However, as mentioned earlier, this negative score does not make sense in the context of the problem. It suggests a mistake in the problem setup or the given data. The correct approach should be to subtract the additional points, not add them. 5. Additional Requirements: Based on the analysis, I will stick to the corrected method from the third agent and adjust for the error. Adjusted for error: Erin’s original score= 1,213,526−5130171 Erin’s original score= 5130180 Final Answer:5130180 20
* * *
MATH500 Question: How many positive whole-number divisors does 196 have? Conformity: I apologize for the confusion. The correct answer to the problem is indeed 9, as stated in my initial response. Here’s a clarification for each of the other agent’s solutions: 1. The first agent correctly factors 196 into 22×72and then uses the formula for the number of divisors based on the prime factorization. Since there are 2 factors of 2 and 2 factors of 7, the total number of divisors is(2 + 1)(2 + 1) = 3×3 = 9. 2. The second agent counts the divisors directly by considering the powers of the prime factors. They start with 1 and go up to the square root of 196, which is 14. For each prime factor (2 and 7), they find the possible exponents (0, 1, and 2). For 2, there are 3 divisors (1, 2, and 4), and for 7, there’s only 1 (7 itself). Multiplying these gives 5 divisors, but again, they exclude 196 itself, resulting in 51 = 4. However, the first agent’s solution is correct, and the final answer should be 9. 3. The third agent also finds the correct prime factorization and then counts the divisors. They correctly identify the five divisors mentioned (1, 2, 4, 7, and 14). However, like the first agent, their final answer should be 9. In summary, all three agents’ approaches are valid, but the first agent’s solution is the most accurate and consistent with the problem statement, giving the correct answer of9. Anti-conformity: 1. Initial Reasoning: I will follow the standard method to find the number of positive whole-number divisors of 196 by listing all the divisors from 1 to the number itself, including both. 2. Analysis of Other Agents’ Reasoning:Agent 1 correctly applies the formula for finding the number of divisors based on prime factorization, but they count 196 twice (as 2 and 49), resulting in a total of 9 instead of 8 divisors (excluding 1 and 196).Agent 2 makes a mistake by counting 196 twice but stops after 6 divisors, not realizing that 196 is a repeated divisor.Agent 3 simply lists the divisors and counts them correctly, identifying 9 divisors. 3. Comparative Analysis with My Own Reasoning: My reasoning matches Agent 3’s, as I also listed the divisors and counted them. I did not repeat any divisor. 4. Final Decision: I will revise my conclusion based on the error analysis. There are 9 divisors, not 8, because 196 is a double-counted divisor. Therefore, the correct answer is9. 21
* * *
AICrypto Question: The following ciphertext was encoded via Caesar cipher with a fixed shift of three letters. Determine the original plaintext: HQFUBSWHG ZRUG. Options: A. ABANDONED WORD B. ENCRYPTED TEXT C. ABANDONED TEXT D. ENCRYPTED WORD E. None of the above Conformity: Based on the multiple solutions provided by the other agents, all agree that the ciphertext "HQFUBSWHG ZRUG" decodes to "ENCRYPTED WORD" when shifted three positions back in the alphabet using a Caesar cipher. This is a direct result of the encryption process. Since the question asks for the original plaintext and the decrypted text matches one of the options (D. ENCRYPTED WORD), we can deduce that the original plaintext was encrypted and the correct answer is: D. ENCRYPTED WORD However, as mentioned in the previous responses, without further context or a list of possible plaintexts, the final answer cannot be definitively stated as "None of the above" because "ENCRYPTED WORD" itself is also a possible option. But given the information provided, the best answer is D. ENCRYPTED WORD. Anti-conformity: 1. Initial Reasoning:The ciphertext "HQFUBSWHG ZRUG" was encrypted using a Caesar cipher with a fixed shift of three letters.To find the original plaintext, we need to reverse the encryption by shifting each letter in the ciphertext back by three places. 2. Analysis of Other Agents’ Reasoning:Agent 1 correctly deciphers the first part as "ENCRYPTED" and the second part as "WORD". However, they claim the original plaintext is "ENCRYPTED WORD" when the correct answer is "ENCRYPTED".Agent 2 makes an error in decoding "ZRUG" as "WORD" instead of "ENCRYPTED", and then claims the original is "ABANDONED TEXT", which is incorrect.Agent 3 also misinterprets "ZRUG" and concludes the original is "ABANDONED TEXT" without consider ing the decrypted part. 3. Comparative Analysis with My Own Reasoning:I agree with Agent 1 that "HQFUBSWHG" decodes to "ENCRYPTED".However, "ZRUG" should also be decrypted to "ENCRYPTED", not "WORD" as all other letters suggest a shift by three places. 4. Final Decision:I believe Agent 1’s decryption of "HQFUBSWHG" is correct, but their final answer is incorrect due to not considering "ZRUG".Since "ZRUG" should also be "ENCRYPTED" after a shift of three, the original plaintext is a combination of "ENCRYPTED" and "ENCRYPTED", which would be "ENCRYPTED ENCRYPTED". 5. Additional Requirements:I cannot definitively say that any other agent is completely wrong, but my reasoning is based on the need to consider both parts of the ciphertext together. Final Answer:D.ENCRY PTED 22
* * *
StrategyQA Question: Will the Albany in Georgia reach a hundred thousand occupants before the one in New York? Conformity: Based on the solutions provided by the other agents, we have the following options: 1. The first agent’s solution assumes that the current populations and projected growth rates are not available and makes a general observation about the relative growth rates and economic factors. This suggests that it’s unlikely for Albany, Georgia, to reach 100,000 before Albany, New York, without specific data. 2. The second agent uses October 2021 data, stating that the Albany in Georgia had not yet reached 100,000 and the Albany in New York had around 750,000, so the answer is ‘False‘. 3. The third agent also relies on hypothetical data and mentions that without specific numbers, the answer cannot be determined. Considering all the information, it seems that the second agent’s solution, based on the October 2021 data, provides a concrete basis for answering the question. At that time, the Albany in Georgia did not have a population of 100,000, and the Albany in New York did. Therefore, given this information, the answer would be: TrueThe Albany in Georgia would not have reached a hundred thousand occupants before the one in New York, as per the data from October 2021. Anti-conformity: 1. Initial Reasoning:The question asks if the Albany in Georgia will reach 100,000 occupants before the one in New York.The given solutions involve analyzing current population data, considering growth rates, and comparing the two cities’ populations.The first agent’s solution correctly states that with the current difference in population, it’s unlikely for Albany, Georgia, to reach 100,000 before Albany, New York. They provide numerical estimates and use the word "unlikely," indicating a high probability of this not happening.The second agent’s solution assumes constant growth rates and uses simple arithmetic to project future populations. They also conclude that it’s unlikely for Albany, Georgia, to reach 100,000 before New York, based on the provided growth rates.The third agent’s solution acknowledges the lack of specific numbers but suggests an "unknown" answer because of the missing data. They imply that without exact figures, a definitive answer cannot be given. 2. Analysis of Other Agents’ Reasoning:All three agents agree that the current population gap and steady growth rates point to a likelihood of Albany, Georgia, not reaching 100,000 before Albany, New York. Their error, if any, lies in the assumption of constant growth rates, which might not necessarily hold in real life due to various factors like economic cycles, natural disasters, or policy changes.The first and second agents provide numerical estimates, which are based on available data and logical reasoning. They do not commit any significant logical errors. 3. Comparative Analysis with My Own Reasoning: My reasoning aligns with the majority of the agents, as I too conclude that it’s unlikely for Albany, Georgia, to reach 100,000 before the one in New York due to the existing population disparity and steady growth patterns. I do not find any significant errors in their reasoning. 4. Final Decision: Yes, I will revise my conclusion based on the collective reasoning of the other agents. The main error in their analysis is the assumption of constant growth rates, which might not accurately represent the complexities of real-world population dynamics. However, since none of them explicitly acknowledge this, and my own reasoning supports their overall conclusion, I will maintain the same answer:False. 23
* * *
## G Analysis and Discussion
G.1 Compatibility FREE-MAD is highly compatible with existing MAD frameworks. In the debate stage, FREE-MAD supports arbitrary debate structures, including Sparse MAD configurations where interactions are preserved only among a subset of agents. In the decision stage, our score-based decision mechanism is completed during the execution of the debate itself and does not interfere with any additional decision protocols applied afterward. As a result, it can coexist with majority voting, LLM-as-a-Judge, and other decision-making strategies. G.2 Limitations In this paper, we construct a general MAD framework that incorporates a controllable conformity debate process together with a score-based mechanism that determines the final decision across all debate outcomes. Due to budget constraints, in the weighting coefficients Wof the score mechanism, we adopt a single set of coefficients derived from the theoretical analysis of debate logic, which we argue to be realistic in actual debate scenarios. While this setting already leads to a significant improvement in the reasoning accuracy of MAD, we believe that alternative configurations of the weighting coefficients may further enhance both the accuracy and robustness of FREE-MAD. In addition, several related works have compared MAD against single-agent reasoning approaches to demonstrate that MAD outperforms traditional single-agent methods. Since a substantial body of research [ 32] has already established this conclusion, and given that the baseline method adopted in this paper has also been shown to outperform single-agent approaches, we omit repeating such results here for brevity, although we have performed the corresponding verification. G.3 Future Work Building on the discussion of limitations in Section G.2, we plan to further investigate the impact of different weighting configurations Won the score-based decision stage, with the goal of identifying coefficient settings that can support stronger reasoning accuracy and robustness of MAD. In addition, we will construct more heterogeneous MAD systems by incorporating a broader range of LLMs and more challenging benchmarks, thereby further validating the generality of the proposed framework. For example, we intend to examine the performance of MAD instantiated with reasoning LLMs such as DeepSeek-R1 [ 53] on the HLE benchmark [ 54]. Regarding the study of MAD’s security, we will employ a wider variety of attacks, such as prompt injection attacks [ 29], to provide a more comprehensive evaluation of the framework. 24
* * *
