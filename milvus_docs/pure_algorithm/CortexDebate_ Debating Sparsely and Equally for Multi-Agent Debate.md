arXiv:2507.03928v1 [cs.AI] 5 Jul 2025CortexDebate: Debating Sparsely and Equally for Multi-Agent Debate Yiliu Sun1, Zicheng Zhao1, Sheng Wan2*, Chen Gong3* 1School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China. 2College of Artificial Intelligence, Nanjing Agricultural University, Nanjing, China. 3School of Automation and Intelligent Sensing, Shanghai Jiao Tong University, Shanghai, China. Correspondence: wansheng315@hotmail.com; chen.gong@sjtu.edu.cn.
* * *
## _Abstract_
Nowadays, single Large Language Model
* * *
(LLM) struggles with critical issues such as hal lucination and inadequate reasoning abilities. To mitigate these issues, Multi-Agent Debate (MAD) has emerged as an effective strategy, where LLM agents engage in in-depth debates with others on tasks. However, existing MAD methods face two major issues: (a) too lengthy input contexts, which causes LLM agents to get lost in plenty of input information and ex periences performance drop; and (b) the over confidence dilemma, where self-assured LLM agents dominate the debate, leading to low de bating effectiveness. To address these limita tions, we propose a novel MAD method called
* * *
> “CortexDebate”. Inspired by the human brain’s
tendency to establish a sparse and dynamically optimized network among cortical areas gov erned by white matter, CortexDebate constructs a sparse debating graph among LLM agents, where each LLM agent only debates with the ones that are helpful to it. To optimize the graph, we propose a module named McKinsey based Debate Matter (MDM), which acts as an artificial analog to white matter. By inte grating the McKinsey Trust Formula, a well established measure of trustworthiness from sociology, MDM enables credible evaluations that guide graph optimization. The effective ness of our CortexDebate has been well demon strated by extensive experimental results across eight datasets from four task types.
* * *
## _1 Introduction_
Recently, inspired by human cooperation, many
* * *
multi-agent interaction methods (Wan et al., 2024; Xu et al., 2023a; Tu et al., 2023; Hu et al., 2024) have been proposed to further improve the reason ing results of LLMs. These methods aim to address critical issues faced by single LLM agent, such as hallucination and poor reasoning ability. Among these methods, Multi-Agent Debate (MAD) (Zhang et al., 2024a; Du et al., 2023) has emerged as one ofthe most promising strategies, as it can effectively improve the performance of LLM agents through the debating process among them. Although previous MAD methods have achieved promising results, they still suffer from two major shortcomings. As shown in Figure 1, firstly, in these methods, each LLM agent is often required to debate with all other LLM agents, which causes its input context to expand significantly as the num ber of agents and debating rounds increase. Conse quently, since single LLM agent usually struggles to handle lengthy input contexts (Liu et al., 2024a; Luo et al., 2024), it may get lost in the vast amount of input information, leading to a significant per formance drop. Secondly, prior MAD methods de termine the debating influence of each LLM agent simply according to its own confidence, which may lead to the overconfident LLM agents gradually dominating the entire debating process. As a result, the potential useful information provided by other
* * *
> “weak” LLM agents may be ignored. Such unequal
debate is harmful to debating effectiveness, as also confirmed by (Xiong et al., 2023; Xu et al., 2023b). Therefore, inspired by the human cognition the ory (Thiebaut de Schotten and Forkel, 2022), this paper proposes a new MAD approach named Cor texDebate, which mimics the working mode of the human brain cortex. As revealed by (Thiebaut de Schotten and Forkel, 2022), given a problem, the human brain tends to establish a dynamic and sparse network among different cortical areas, and this network is gradually optimized by a special ized module named white matter. During the op timization process, the white matter focuses more on the influence between paired areas rather than the performance of a single cortical area. By treating LLM agents as cortical areas in hu man brain, our proposed CortexDebate establishes a sparse and directed debating graph, where the nodes represent participated LLM agents and the edges carry information transmission between two
* * *
Input Context Task: What is the result of 27420 × 135 + 2 × 8? 25 Think it step by step. Provide your answer and its explanation. 1) Answer: 23 Confidence: 0.9 2) Answer: 25 Confidence: 0.5 3) Answer: 25 Confidence: 0.6 Generate your answer.Answer: 23 Process: 2 × 8 =16, 20 × 13 =260, 2742605 + 16 = 23 Confidence: 0.9Answer: 25 Process: 2 × 8 =16, 20 × 13 =260, 2742605 + 16 = 25 Confidence: 0.5Answer: 25 Process: 20 × 13 = 260, 2742605 = 9, 9 + 2 × 8 = 25 Confidence: 0.6 Answer: 23 Process: 20 × 13 = 260, 2 × 8 = 16, 2742605 + 16 = 23. The answer of the task is 23. Confidence: 1.0Answer: 23 Process: 23 is right, with high confidence. 274 2605 + 16 = 23, not 25. Confidence: 0.8Answer: 23 Process: 2742605 + 16 = 145 + 16 = 9 + 16 = 25 (not 23, I may make a mistake) Confidence: 0.6 Since three LLM agents reach a consensus, the final answer is 23. 51 43 872 6Welcome to the debate! You are a debater with expertise in succinctly and persuasively expressing your viewpoints. You will engage in discussions with others. Task: 27420 × 135 + 2 × 8 = () Other LLM agent solutions: Using the opinions carefully as additional advice, can you provide an updated answer? Examine your solution.  1284 3 57 6Input Context Task: What is the result of 27420 × 135 + 2 × 8? 25 Think it step by step. Provide your answer and its explanation. 1) Answer: 23 Confidence: 0.9 2) Answer: 25 Confidence: 0.5 3) Answer: 25 Confidence: 0.6 Generate your answer.Answer: 23 Process: 2 × 8 =16, 20 × 13 =260, 2742605 + 16 = 23 Confidence: 0.9Answer: 25 Process: 2 × 8 =16, 20 × 13 =260, 2742605 + 16 = 25 Confidence: 0.5Answer: 25 Process: 20 × 13 = 260, 2742605 = 9, 9 + 2 × 8 = 25 Confidence: 0.6 Answer: 23 Process: 20 × 13 = 260, 2 × 8 = 16, 2742605 + 16 = 23. The answer of the task is 23. Confidence: 1.0Answer: 23 Process: 23 is right, with high confidence. 274 2605 + 16 = 23, not 25. Confidence: 0.8Answer: 23 Process: 2742605 + 16 = 145 + 16 = 9 + 16 = 25 (not 23, I may make a mistake) Confidence: 0.6 Since three LLM agents reach a consensus, the final answer is 23. 51 43 872 6Welcome to the debate! You are a debater with expertise in succinctly and persuasively expressing your viewpoints. You will engage in discussions with others. Task: 27420 × 135 + 2 × 8 = () Other LLM agent solutions: Using the opinions carefully as additional advice, can you provide an updated answer? Examine your solution.  1284 3 57 6Figure 1: Shortcomings of the existing MAD methods: (a) Debating with all others causes lengthy contexts input to LLM agents. They may get lost in the vast amount of input information and perform unsatisfactorily; (b) Determining the debating impact of LLM agents simply based on their self-confidence may lead to the overconfident ones dominating the debate. This situation is harmful to the debating performance. LLM agents. Each directed graph edge is assigned a weight that reflects how much the performance of the tail LLM agent is expected to be improved by debating with the head LLM agent. Therefore, each tail LLM agent will not debate with the head LLM agents which do not help improve its perfor mance. It means that the edges with small weights in the debating graph will be removed, resulting in a sparse graph. As a result, the length of con text input to such tail LLM agent will also be re duced. To optimize the edge weights of the debat ing graph, akin to the white matter dynamically governing the optimization of sparse graph among different cortical areas in human brain, our Cor texDebate introduces a module named McKinsey based Debate Matter (MDM) that serves as the artificial white matter. To alleviate the overconfi dence dilemma present in prior works, MDM con siders both the performance of head LLM agent and the performance improvement expectation of tail LLM agent in deciding each edge weight. Specif ically, MDM innovatively introduces McKinsey Trust Formula (Lamarre et al., 2012) to calculate edge weights, which has been widely used in soci ology to evaluate the level of trustworthiness of a person through four aspects, including credibility, reliability, intimacy, and self-orientation. Among them, the first two evaluate individual abilities, while the last two evaluate the collaboration effec tiveness with others. Therefore, this formula may suppress overconfident LLM agents, and also bal ance individual competence with teamwork abilityof LLM agents in MAD. The effectiveness of our CortexDebate has been well confirmed by the experiments on diverse tasks, including math, world knowledge question answer ing, reasoning, and long-context understanding. For instance, when compared with the state-of-the art methods, in math task, CortexDebate increases Result Accuracy (RA) by up to 9.00% on GSM-IC dataset and 10.00% on MATH dataset, respectively. In reasoning task, CortexDebate increases RA by up to 9.00% on GPQA dataset and 12.33% on ARC C dataset, respectively. Besides, apart from achiev ing high performance, our CortexDebate signifi cantly reduces the length of context input to each LLM agent, with a maximum reduction of 70.79%. The main contributions of this paper are summa rized as follows: 1) We propose a new MAD method named Cor texDebate, which can improve the performance of LLM agents by establishing a sparse and dynamic debating graph and reducing the burden of lengthy input context during the debate. 2) We propose a new module named MDM, which introduces McKinsey Trust Formula to eval uate both the confidence of each LLM agent and the usefulness to its debating component, thereby alleviating the overconfidence of LLM agents. 3) We conduct extensive experiments to show that our proposed CortexDebate outperforms rep resentative baseline methods across multiple tasks such as math, world knowledge question answer ing, reasoning, and long-context understanding.
* * *
## 2 Related Work
In a MAD system, each LLM agent presents its viewpoint and scrutinizes the viewpoints of other LLM agents across multiple rounds of debate (Sun et al., 2024a). In summary, the existing MAD meth ods can be categorized as two types, namely se quential debate andparallel debate. Sequential Debate. In these methods (Hu et al., 2025; Brown-Cohen et al., 2023; Michael et al., 2023; Wang et al., 2025; He et al., 2024), LLM agents generate their viewpoints in turn. Each LLM agent can only obtain the viewpoints of its preced ing LLM agents. For example, Liang et al. (2023) require two LLMs to refute each other in turn. In addition to debaters, Guan et al. (2025) add extra roles, such as judge and critic. The judge speaks before debaters to explain the task, and the critic speaks last to summarize debates. However, in a sequential debate system, each LLM agent must wait for previous LLM agents to finish reasoning before it starts. This makes debating time increase linearly with the number of LLM agents, leading to low efficiency which limits the scalability. Parallel Debate. In these methods (Pham et al., 2023; Yin et al., 2023; Chern et al., 2024; Khan et al., 2024; Liang et al., 2024; Li et al., 2024a; Hegazy, 2024; Zhang et al., 2024b), all LLM agents simultaneously generate their viewpoints based on the viewpoints of other LLM agents in the last debating round. For example, Chan et al. (2023) re quire LLM agents to critique all answers generated in the last debating round and update its answer in each debating round simultaneously. In addi tion to the answers generated in the last round, Sun et al. (2024b) also provide each LLM agent with task-related information retrieved from the web. Besides, some methods (Duan and Wang, 2024; Yoffe et al., 2024) try to adjust the debating influ ence of each LLM agent to improve the debating effectiveness. For example, Chen et al. (2023) re quire each LLM agent to generate the confidence score for its own answer, and then inputs the score to other LLM agents along with the answer. Since sequential debate systems face the low efficiency issue mentioned above, our proposed CortexDebate follows the parallel debate frame work. Compared with existing parallel debating methods which require each LLM agent to debate with all others in each round, our CortexDebate dynamically decides the necessary debating agents by establishing a sparse debating graph among allinvolved LLM agents, so that the input context to each agent can be shortened. This is also in con trary to (Liu et al., 2024b; Li et al., 2024b) in which the debating opponents are fixed. Furthermore, dif ferent from prior methods which determine the debating impact of each LLM agent simply based on its own confidence, we introduce the McKin sey Trust Formula so that both the confidence of each LLM agent and the usefulness to its debating component can be evaluated.
* * *
## _3 Preliminaries_
In this section, we provide the problem definition
* * *
for our CortexDebate, and introduce the McKinsey Trust Formula which plays an important role in our proposed CortexDebate. 3.1 Problem Definition Our CortexDebate establishes a directed debating graph among nLLM agents, G= (A,E), where A={Ai}n i=1is the vertex set representing partic ipating LLM agents and E={Ei→j}i,j∈[1,2,...,n] is the directed edge set representing information transmission. Here, each directed edge Ei→jis as signed a weight Wi→jthat indicates the expected improvement in the performance of agent Ajby debating with Ai. All the weights {Wi→j}are dynamically optimized during the debate process. Given a problem Q, the agents {Ai}n i=1engage in Drounds of debate. In the d-th debate round, each LLM agent Aiscrutinizes the outputs of the LLM agents connected to it, and then generates its own output Od ialong with a self-confidence score Hd i. Afterwards, the final answer of this debate round, i.e.,Fd, is obtained by majority voting. 3.2 McKinsey Trust Formula The McKinsey Trust Formula (Lamarre et al., 2012) is widely used in sociology to evaluate the level of trustworthiness of a person within a group. This formula can be expressed as: T=C×R×I S, (1) where C,R,I, and Sdenote credibility, relia bility, intimacy, and self-orientation, respectively. Among them, credibility measures professional competence, reliability measures the stability of task performance, intimacy measures the relation ship with the evaluated person, and self-orientation measures the self-orientation level of the evaluated person within a group.
* * *
Question: What is the result of 27420 × 135 + 2 × 8? Correct Answer: 25 Answer: 23 Process: 2 × 8 =16, 20 × 13 = 260... Confidence: 0.9Answer: 25 Process: 20 × 13 = 260, 2 × 8 = 16... Confidence: 0.7Answer: 29 Process: 2 + 8 =10, 20 × 13 = 260... Confidence: 0.5Phase 1: Initial Answer Generation Phase 2: Multi-round Debate Answer: 25 Process: 20 × 13 = 260, 274260 = 14... Confidence: 0.5Answer: 25 Process: 20 × 13 = 260, 2 × 8 = 16... Confidence: 0.9Answer: 23 Process: 2 × 8 =16, 20 × 13 = 260... Confidence: 0.3 23 25Answer: 25 No consensus Answer: 25 Process: 20 × 13 = 260, 274260 = 14... Confidence: 0.7Answer: 25 Process: 20 × 13 = 260, 2 × 8 = 16... Confidence: 0.9Answer: 25 Process: 2 × 8 =16, 20 × 13 = 260... Confidence: 0.6 other25Answer: 25 A consensus Step 3: Answer Regeneration Phase 3: Final Answer Generation =argmax (=)Therefore, the final answer to the task is 25. Process: 20 × 13 = 260, 2 × 8 = 16, 274260 = 14, 145 = 9, 9 + 16 = 25 =××÷ W: 01 Step 1: Edge Weight Optimization Step 2: Sparse Graph EstablishmentMcKinsey-based Debate Matter Step 4: Debate Termination Step 4: Debate TerminationInvovled Agents: Large Language Models Step 1Output Components: 1) Answer: a numerical number 2) Process: an answer explanation 3) Confidence: answer confidence [0, 1]McKinsey Trust Formula [0, 1] Fully-connected → 0/1 Sparse: connect disconnect < ≥ Input Context: not lengthy Other LLM agent solutions: Using they as additional advice, can you provide an updated answer?  Majority Voting: Question: What is the result of 27420 × 135 + 2 × 8? Correct Answer: 25 Answer: 23 Process: 2 × 8 =16, 20 × 13 = 260... Confidence: 0.9Answer: 25 Process: 20 × 13 = 260, 2 × 8 = 16... Confidence: 0.7Answer: 29 Process: 2 + 8 =10, 20 × 13 = 260... Confidence: 0.5Phase 1: Initial Answer Generation Phase 2: Multi-round Debate Answer: 25 Process: 20 × 13 = 260, 274260 = 14... Confidence: 0.5Answer: 25 Process: 20 × 13 = 260, 2 × 8 = 16... Confidence: 0.9Answer: 23 Process: 2 × 8 =16, 20 × 13 = 260... Confidence: 0.3 23 25Answer: 25 No consensus Answer: 25 Process: 20 × 13 = 260, 274260 = 14... Confidence: 0.7Answer: 25 Process: 20 × 13 = 260, 2 × 8 = 16... Confidence: 0.9Answer: 25 Process: 2 × 8 =16, 20 × 13 = 260... Confidence: 0.6 other25Answer: 25 A consensus Step 3: Answer Regeneration Phase 3: Final Answer Generation =argmax (=)Therefore, the final answer to the task is 25. Process: 20 × 13 = 260, 2 × 8 = 16, 274260 = 14, 145 = 9, 9 + 16 = 25 =××÷ W: 01 Step 1: Edge Weight Optimization Step 2: Sparse Graph EstablishmentMcKinsey-based Debate Matter Step 4: Debate Termination Step 4: Debate TerminationInvovled Agents: Large Language Models Step 1Output Components: 1) Answer: a numerical number 2) Process: an answer explanation 3) Confidence: answer confidence [0, 1]McKinsey Trust Formula [0, 1] Fully-connected → 0/1 Sparse: connect disconnect < ≥ Input Context: not lengthy Other LLM agent solutions: Using they as additional advice, can you provide an updated answer?  Majority Voting: Figure 2: Overview of our proposed CortexDebate, which is inspired by the working mode of human brain cortex and consists of three phases: (a) Initial Answer Generation: Each LLM agent generates an answer, an explanation, and its confidence score. (b) Multi-round Debate: Participating LLM agents engage in debates guided by a sparse debating graph which is dynamically optimized by MDM module. (c) Final Answer Generation: After multi-round debates, the final answer is generated by majority voting. In our MDM module, we adapt these four factors to the context of MAD. Specifically, for directed edgeEi→jconnecting agent AitoAj, credibility evaluates the professional competence of Ai. Reli ability is the average confidence score of Aito its own answers in history debates, which represents the performance reliability on the current question. Intimacy represents the average degree of differ ence in viewpoints between AiandAjin history debates, as the collision of different viewpoints can enhance the debating effectiveness (Xiong et al., 2023). Self-orientation represents the participation level of Aiin the debate (a lower participation level indicates higher self-orientation).
* * *
## _4 Methodology_
In this section, we introduce the overall framework
* * *
of our CortexDebate. As shown in Figure 2 and Al gorithm 1, CortexDebate operates in three phases, including initial answer generation,multi-round debate, and final answer generation. Unlike exist ing MAD methods that establish fully-connected and fixed graphs among LLM agents, our Cor texDebate establishes a sparse and dynamic graph, where each LLM agent selectively debates with those that can contribute to its improvement. Be-sides, CortexDebate evaluates the performance of LLM agents and their usefulness to their debating components, enabling credible graph optimization. 4.1 Phase 1: Initial Answer Generation When given a problem Q, CortexDebate allows each LLM agent Aito independently generate an initial output O0 iand a self-confidence score H0 i (see Appendix F for the specific prompt). To mit igate overconfidence, CortexDebate adopts a re calibration strategy, which has been proven to be effective in prior works (Chen et al., 2023). Our strategy can be expressed as: H0 i=  0.8, H0 i≥0.8 0.6,0.6≤H0 i<0.8 H0 i,0.3≤H0 i<0.6 0.3, H0 i<0.3. (2) 4.2 Phase 2: Multi-round Debate CortexDebate then comes into a debate phase, where the set of agents {Ai}engage in Drounds of debate. In the d-th debating round, CortexDe bate comprises four steps, including edge weight optimization,sparse graph establishment,answer regeneration, and debate termination. Step 1: Edge Weight Optimization. As the
* * *
## description of Equation (1), MDM calculates the
edge weights based on four aspects, including cred ibility,reliability,intimacy, and self-orientation. Following the definition for each aspect in the con text of MAD in Section 3.2, the specific calculation of each aspect will be given next. ForEi→j, since the scaling law for LLM agents (Hoffmann et al., 2022) can evaluate abili ties of one LLM agent, we use it to calculate credi bility Cd, which can be expressed as: L(N, M) =406.4 N0.34+410.7 M0.28+ 1.69,(3) where N,M, andLdenote the parameter number, the token number of pre-training data, and the pre training loss of one model, respectively. A smaller loss value indicates better model abilities, and thus Cdis expressed as: Cd=1 L(N, M). (4) For reliability Rdwhich represents the average confidence score of Aiin its own answers in the preceding d−1rounds, its calculation can be ex pressed as: Rd=Rd−1×(d−1) +Hd−1 i d. (5) For intimacy Id, which represents the average degree of difference in viewpoints between Aiand Ajin the preceding d−1rounds, MDM first uses cosine similarity to calculate the textual similarity between Od−1 iandOd−1 j. Subsequently, CortexDe bate calculates the average viewpoint similarity between AiandAjin the preceding d−1rounds, i.e.,Sim d, as: Sim d=Sim d−1×(d−1)+cos(Od−1 i,Od−1 j) d,(6) where cos(a, b)calculates cosine similarity be tween aandb. Since Idrepresents the average degree of difference, it is calculated as: Id= 1−Sim d. (7) For self-orientation Sd, based on the fact that less group participation indicates that one is more selfish, the MDM module uses the number of times thatAihas debated with other LLM agents in the preceding d−1rounds, denoted as Pd, to indi rectly reflect self-orientation. The calculation can be expressed as: Sd= (d−1)×(n−1)−Pd, (8) where (d−1)×(n−1)denotes the maximum number of times that one LLM agent can debate with others in the preceding d−1rounds.Therefore, following Equation (1), the weight of edgeEi→jcan be calculated as: Wd i→j=Cd×Rd×Id Sd. (9) Step 2: Sparse Graph Establishment. ForAj, it can debate with the other n−1LLM agents. In other words, there are n−1directed edges pointing to it, with Ajas the tail node. CortexDebate deter mines the set of debating opponents for Ajaccord ing to the weights of these edgesn Wd i→jon i=1, i̸=j. Firstly, the average weight of these edges, i.e., Wd j, is calculated as: Wd j=1 n−1P i(i̸=j)Wd i→j. (10) Secondly, the edges with weights below Wd jare removed, resulting in a sparse debating graph. The process can be expressed as: Wd i→j=( 1, W i→j≥Wd j 0, W i→j
* * *
as: Ofinal = arg max oX i1(Oi=o), (14) where odenotes a distinct answer generated by any of the LLM agents. If all the generated answers are different after debates, we treat the final result as incorrect. By excluding fallback strategies, we can clearly attribute the observed performance solely to the debate mechanism itself.
* * *
## _5 Experiments_
This section introduces the experimental setup, ex
* * *
perimental results, and analysis of our experiments. 5.1 Experimental Setup In this part, we introduce the details of the experi mental setup. Tasks. In our experiments, we consider four typical tasks, namely: (a) math task, (b) world knowledge question answering task, (c) reasoning task, and (d) long-context understanding task. For the math task, we use GSM-IC (Shi et al., 2023) and MATH (Hendrycks et al., 2021) datasets. For the world knowledge question answering task, we use MMLU (Hendrycks et al., 2020) and MMLU pro (Wang et al., 2024) datasets. For the reasoning task, we use GPQA (Rein et al., 2023) and ARC C (Clark et al., 2018) dataset. For the long-context understanding task, we use LongBench (Bai et al., 2023) and SQuAD (Rajpurkar, 2016) datasets. More details on the employed datasets for experi ments can be found in Appendix A. Evaluation Metrics. For LongBench dataset, we follow (Bai et al., 2023) and utilize the Macro Average (M-Avg), which calculates the average score over major sub-task categories. For SQuAD dataset, we follow (Rajpurkar, 2016) and utilize theExact Match (EM), which calculates the per centage of outputs containing correct answers. For the remaining six datasets, we follow (Shi et al., 2023; Hendrycks et al., 2021, 2020; Wang et al., 2024; Rein et al., 2023; Clark et al., 2018; Sun et al., 2025) and utilize the Result Accuracy (RA), which calculates the percentage of correct results. Baseline Methods. Our proposed CortexDebate is compared with the three categories of methods: 1)No debate: Multi-agent V oting (MaV) (Wang et al., 2022), 2) Full debate: Multi-LLM Debate (MLD) (Du et al., 2023), RECONCILE (Chen et al., 2023), ChatEval (Chan et al., 2023), and Peer Re view Debate (PRD) (Xu et al., 2023b), 3) Partdebate: GroupDebate (GD) (Liu et al., 2024b) and Neighbor Debate (ND) (Li et al., 2024b). Among them, no debate methods are the multi-agent meth ods without using debating strategies, full debate methods are the MAD methods where each LLM agents are required to debate with all others, and part debate methods are the MAD methods where each LLM agents only debates with part of the oth ers. Detailed introduction of these baseline meth ods can be found in Appendix G. For fairness, the maximum number of debating rounds is set to 5 for all debating methods. Backbone Models. The backbone models in volved in the debating system for our experiments are Qwen-2.5-7B-Instruct-Turbo (Team, 2024), Mistral-7B-Instruct (Jiang et al., 2023), Typhoon 1.5-8B-Instruct (Pipatanakul et al., 2023), Llama 3.1-8B-Instruct-Turbo (Dubey et al., 2024), and Gemma-2-9B-Instruct (Yang et al., 2024). For sim plicity, we refer to them as Qwen, Mistral, Ty phoon, Llama, and Gemma, respectively. Implementation Details. We follow prior works (Du et al., 2023; Chen et al., 2023; Besta et al., 2024) to experiment on a subset of 100 ex amples for each dataset. For each experiment, we conduct three runs on the same examples with the same setups and report average results along with their variances. We also conduct large-scale ex periments on the more challenging datasets from each task ( i.e.MATH, MMLU-pro, GPQA, and LongBench) and observe similar results, which are detailed in Appendix C. 5.2 Main Results In this part, we present the experimental results and detailed analysis to highlight the effectiveness of our proposed CortexDebate. CortexDebate outperforms baseline methods.
* * *
## _Table 1 reports the accuracy of our CortexDebate_
and baseline methods on eight datasets. Com
* * *
pared with the baseline methods, our CortexDe bate achieves the highest accuracy and performs stably on all adopted datasets. Besides, we can find that the effectiveness and stability of the full debate methods ( i.e., MLD, RECONCILE, Chat Eval, and PRD) drops on complex reasoning and long-context tasks ( i.e., GPQA, LongBench, and SQuAD). It is because the reasoning process in creases with the complexity of the task, leading to the lengthy context issue mentioned in Section 1. However, our CortexDebate still performs well and stably due to its sparse debating graph which
* * *
Type MethodGSM-IC MATH MMLU MMLU-pro GPQA ARC-C LongBench SQuAD RA↑ M-Avg ↑ EM↑ No Debate MaV 70.33±1.5646.00±2.6769.33±0.22 46.00±4.67 27.33±2.8976.00±0.67 45.11±1.09 85.33±1.56 Full DebateMLD 72.67±0.2247.33±0.8971.33±1.56 47.33±0.89 28.33±2.8979.33±0.22 48.87±2.21 86.33±0.22 RECONCILE 75.67±0.2250.33±4.2275.00±2.67 53.67±2.89 31.00±0.6783.67±2.89 52.55±2.68 88.33±6.89 ChatEval 74.33±0.8949.00±0.6773.00±0.67 49.33±0.89 31.33±0.8982.67±1.56 53.56±6.16 87.33±6.22 PRD 77.00±0.6751.33±0.8977.33±1.56 54.00±0.67 32.00±2.0084.33±0.89 50.21±6.09 87.67±4.22 Part DebateGD 76.00±2.6749.67±1.5674.00±2.67 51.67±0.89 32.67±0.2282.00±2.00 55.97±0.59 90.33±0.89 ND 73.67±1.5649.00±0.6771.67±2.89 48.67±1.56 32.33±1.5681.33±2.89 54.55±6.18 88.33±1.56 Ours 79.33±0.2256.00±0.6782.33±0.22 59.33±0.22 36.33±1.5688.33±0.89 60.31±0.32 93.33±0.89
* * *
## _Table 1: Comparison results on the four different types of tasks. The unit of all the results is “ %”. The format of_
the results is “(average result) ±(variance)”. “ ↑” means that higher values are better. The best records under each
* * *
metric are highlighted in bold. 60%65%70%75%80% 02000400060008000MaV MLD RECONCILE ChatEval PRD GD ND Ours 40%45%50%55%60% 02250450067509000 60%66%72%78%84% 030006000900012000 30%40%50%60%70% 0400080001200016000 20%25%30%35%40% 05000100001500020000 70%75%80%85%90% 030006000900012000 0%20%40%60%80% 0200000400000600000800000 75%80%85%90%95% 06250125001875025000GSM-IC MATH MMLU MMLU-pro GPQA ARC-C LongBench SQuAD60%65%70%75%80% 02000400060008000MaV MLD RECONCILE ChatEval PRD GD ND Ours 40%45%50%55%60% 02250450067509000 60%66%72%78%84% 030006000900012000 30%40%50%60%70% 0400080001200016000 20%25%30%35%40% 05000100001500020000 70%75%80%85%90% 030006000900012000 0%20%40%60%80% 0200000400000600000800000 75%80%85%90%95% 06250125001875025000GSM-IC MATH MMLU MMLU-pro GPQA ARC-C LongBench SQuAD
* * *
## _Figure 3: Comparison results of average length of context input to the LLM agents on eight datasets. We reflect the_
length of one input context through its token number. In each combined chart, the left vertical axis (representing
* * *
token number) corresponds to the bar chart, while the right vertical axis (representing task accuracy) corresponds to the line chart. reduces input context length and MDM module which makes each LLM agent debate with those that are helpful to it. CortexDebate significantly reduces input con text length. For each adopted dataset, we calculate the average token number of context input to a sin gle LLM agent in each method and present the re sults in Figure 3. Compared with MaV, MAD meth ods generally incur long context input to each LLM agent, indicating a significant challenge in reducing input context length while maintaining superior ac curacy in MAD methods. Our proposed CortexDe bate takes a further step, as it achieves both shorter input context length and higher task performance compared with other MAD baseline methods. The specific numerical values of the results shown in
* * *
## _Figure 3 are presented in Appendix B._
CortexDebate debates effectively and equally. Engaging in more effective debates is what MAD
* * *
systems strive for. To study this, in Figures 4a and 4b, we plot the average scores and proportion of examples achieving consensus on the answerson eight adopted datasets after each debating round, respectively. From Figure 4a, we have two impor tant observations: (a) As the debate proceeds, the performance of our CortexDebate continues to im prove. (b) Compared with the baseline methods, our CortexDebate maintains superior performance and achieves the highest score of 69.41%. From
* * *
## _Figure 4b, our observations are likewise twofold:_
(a) In the initial rounds, since CortexDebate encour
* * *
ages the equal collision of different viewpoints, its consensus proportion is relatively low. However, as the debate proceeds, a high consensus propor tion is achieved. (b) Compared with other meth ods, RECONCILE maintains the highest consensus proportion while its score fluctuates as shown in
* * *
## _Figure 4a. This is due to the overconfidence-caused_
unequal debate, where the debate is dominated by
* * *
a few LLM agents and others tend to surrender. Differently, our CortexDebate alleviates this issue and maintains equally debates among LLM agents, thereby achieving consistent growth in score and consensus proportion. The numerical results are
* * *
## 55 58 61 64 67 70
1 2 3 4 5Average Score (%) Debate RoundMLD RECONCILE ChatEval PRD GD ND Ours55 58 61 64 67 70 1 2 3 4 5Average Score (%) Debate RoundMLD RECONCILE ChatEval PRD GD ND Ours(a) Average scores of our CortexDebate and baseline meth ods after each debating round. 405060708090100 1 2 3 4 5Consensus (%) Debate RoundMLD RECONCILE ChatEval PRD GD ND Ours405060708090100 1 2 3 4 5Consensus (%) Debate RoundMLD RECONCILE ChatEval PRD GD ND Ours (b) Proportion of examples achieving answer consensus.
* * *
## _Figure 4: Results of average task scores and consensus_
proportions for MAD methods after each round. Method Score ↑
* * *
Fully-connected Graph 60.49 + MDM 63.76 Sparse Graph 62.72 + Self-evaluation (RECONCILE) 62.13 + Peer Evaluation (PRD) 66.71 + MDM (w/o IdandSdin Equation (9)) 66.69 + MDM (Ours) 69.41
* * *
## _Table 2: Ablation study on our proposed CortexDebate._
> “↑” means that higher values are better. The best record
is highlighted in bold. presented in Appendix B. 5.3 Performance Investigation
* * *
In this section, we conduct in-depth investigation on our CortexDebate to analyze its effectiveness. For each method, we use its average score on eight adopted datasets to represent its performance. Each component of CortexDebate is indis pensable. To show that every component of Cor texDebate ( i.e., sparse debating graph and MDM module) is indispensable, we conduct an ablation study. For the fully-connected graph, we follow the basic MAD framework where each LLM agent debates with all others. For the sparse graph, we use different evaluation strategies to optimize theMethod (CortexDebate) DVC CVR CVR/DVC without I and S factors 3.71 1.26 33.96 with I and S factors 8.44 4.83 64.92
* * *
## _Table 3: Comparison results of our CortexDebate_
with and without considering intimacy (I) and self
* * *
orientation (S) factors. /uni00000014 /uni00000015 /uni00000016 /uni00000017 /uni00000018 /uni0000002f/uni0000002f/uni00000030/uni00000003/uni00000024/uni0000004a/uni00000048/uni00000051/uni00000057/uni00000003/uni00000031/uni00000058/uni00000050/uni00000045/uni00000048/uni00000055/uni00000014 /uni00000015 /uni00000016 /uni00000017 /uni00000018/uni00000027/uni00000048/uni00000045/uni00000044/uni00000057/uni00000048/uni00000003/uni00000035/uni00000052/uni00000058/uni00000051/uni00000047/uni00000017/uni0000001c/uni00000011/uni00000015/uni00000013 /uni00000018/uni00000014/uni00000011/uni0000001c/uni0000001b /uni00000018/uni00000017/uni00000011/uni0000001a/uni00000019 /uni00000018/uni0000001a/uni00000011/uni00000018/uni00000015 /uni00000019/uni00000013/uni00000011/uni00000016/uni00000014 /uni00000018/uni00000013/uni00000011/uni00000016/uni0000001b /uni00000018/uni00000017/uni00000011/uni00000015/uni00000013 /uni00000018/uni0000001b/uni00000011/uni00000013/uni00000015 /uni00000019/uni00000014/uni00000011/uni0000001b/uni00000017 /uni00000019/uni00000018/uni00000011/uni00000019/uni00000018 /uni00000018/uni00000015/uni00000011/uni0000001b/uni0000001b /uni00000018/uni00000019/uni00000011/uni00000018/uni0000001b /uni00000019/uni00000013/uni00000011/uni00000015/uni00000019 /uni00000019/uni00000016/uni00000011/uni0000001c/uni00000018 /uni00000019/uni0000001a/uni00000011/uni00000019/uni00000016 /uni00000018/uni00000018/uni00000011/uni00000014/uni0000001a /uni00000018/uni0000001b/uni00000011/uni00000019/uni00000019 /uni00000019/uni00000015/uni00000011/uni00000014/uni00000016 /uni00000019/uni00000018/uni00000011/uni00000019/uni00000015 /uni00000019/uni0000001c/uni00000011/uni00000014/uni00000013 /uni00000018/uni00000019/uni00000011/uni00000018/uni0000001b /uni00000018/uni0000001c/uni00000011/uni0000001a/uni0000001b /uni00000019/uni00000015/uni00000011/uni0000001c/uni0000001c /uni00000019/uni00000019/uni00000011/uni00000015/uni00000013 /uni00000019/uni0000001c/uni00000011/uni00000017/uni00000014 /uni00000018/uni00000013/uni00000011/uni00000013/uni00000018/uni00000015/uni00000011/uni00000018/uni00000018/uni00000018/uni00000011/uni00000013/uni00000018/uni0000001a/uni00000011/uni00000018/uni00000019/uni00000013/uni00000011/uni00000013/uni00000019/uni00000015/uni00000011/uni00000018/uni00000019/uni00000018/uni00000011/uni00000013/uni00000019/uni0000001a/uni00000011/uni00000018 /uni00000014 /uni00000015 /uni00000016 /uni00000017 /uni00000018 /uni0000002f/uni0000002f/uni00000030/uni00000003/uni00000024/uni0000004a/uni00000048/uni00000051/uni00000057/uni00000003/uni00000031/uni00000058/uni00000050/uni00000045/uni00000048/uni00000055/uni00000014 /uni00000015 /uni00000016 /uni00000017 /uni00000018/uni00000027/uni00000048/uni00000045/uni00000044/uni00000057/uni00000048/uni00000003/uni00000035/uni00000052/uni00000058/uni00000051/uni00000047/uni00000017/uni0000001c/uni00000011/uni00000015/uni00000013 /uni00000018/uni00000014/uni00000011/uni0000001c/uni0000001b /uni00000018/uni00000017/uni00000011/uni0000001a/uni00000019 /uni00000018/uni0000001a/uni00000011/uni00000018/uni00000015 /uni00000019/uni00000013/uni00000011/uni00000016/uni00000014 /uni00000018/uni00000013/uni00000011/uni00000016/uni0000001b /uni00000018/uni00000017/uni00000011/uni00000015/uni00000013 /uni00000018/uni0000001b/uni00000011/uni00000013/uni00000015 /uni00000019/uni00000014/uni00000011/uni0000001b/uni00000017 /uni00000019/uni00000018/uni00000011/uni00000019/uni00000018 /uni00000018/uni00000015/uni00000011/uni0000001b/uni0000001b /uni00000018/uni00000019/uni00000011/uni00000018/uni0000001b /uni00000019/uni00000013/uni00000011/uni00000015/uni00000019 /uni00000019/uni00000016/uni00000011/uni0000001c/uni00000018 /uni00000019/uni0000001a/uni00000011/uni00000019/uni00000016 /uni00000018/uni00000018/uni00000011/uni00000014/uni0000001a /uni00000018/uni0000001b/uni00000011/uni00000019/uni00000019 /uni00000019/uni00000015/uni00000011/uni00000014/uni00000016 /uni00000019/uni00000018/uni00000011/uni00000019/uni00000015 /uni00000019/uni0000001c/uni00000011/uni00000014/uni00000013 /uni00000018/uni00000019/uni00000011/uni00000018/uni0000001b /uni00000018/uni0000001c/uni00000011/uni0000001a/uni0000001b /uni00000019/uni00000015/uni00000011/uni0000001c/uni0000001c /uni00000019/uni00000019/uni00000011/uni00000015/uni00000013 /uni00000019/uni0000001c/uni00000011/uni00000017/uni00000014 /uni00000018/uni00000013/uni00000011/uni00000013/uni00000018/uni00000015/uni00000011/uni00000018/uni00000018/uni00000018/uni00000011/uni00000013/uni00000018/uni0000001a/uni00000011/uni00000018/uni00000019/uni00000013/uni00000011/uni00000013/uni00000019/uni00000015/uni00000011/uni00000018/uni00000019/uni00000018/uni00000011/uni00000013/uni00000019/uni0000001a/uni00000011/uni00000018
* * *
## _Figure 5: Task performance of CortexDebate under_
different LLM agent numbers and debating rounds. edge weights of the debating graph, including self
* * *
evaluation (Chen et al., 2023), peer evaluation (Xu et al., 2023b), MDM (w/o IdandSdin Equa tion(9)), and MDM (see Appendix E for detailed introduction). As shown in Table 2, compared with
* * *
> “fully-connected graph + MDM”, “sparse graph +
MDM” increases the average score by 5.65%. It is because sparse debating graph structure allevi ates lengthy input context issue and allows LLM agents to make full use of their input information. For different optimization strategies, the average task score of self-evaluation is only 62.13%. It is due to the overconfidence dilemma mentioned in Section 1. Peer evaluation and MDM (w/o Idand Sdin Equation (9)) alleviate this issue, achieving better performance compared with self-evaluation. Moreover, MDM further improves the task perfor mance, since it considers both the performance of each LLM agent and the usefulness to its debat ing components, thereby conducting more credi ble evaluations compared with Peer evaluation and MDM (w/o IdandSdin Equation (9)) which only evaluate individual performance. Considering cooperation performance among agents is essential. On MATH dataset, we com pare the average numbers of different viewpoint collisions (DVC) and correct viewpoint revision (CVR) per question of our CortexDebate with and without using intimacy (I) and self-orientation (S)
* * *
AgentFcG CortexDebate RA↑Avg-DN ↓RA↑Avg-DN ↓ Qwen 54.00 13.58 58.00 11.53 Mistral 49.00 13.58 56.00 6.24 Typhoon 47.00 13.58 53.00 8.83 Llama 51.00 13.58 56.00 11.37 Gemma 45.00 13.58 51.00 5.46
* * *
## _Table 4: Task performance of every participated LLM_
agent under the fully-connected debating graph and our
* * *
proposed CortexDebate. “ ↑” means that higher values are better, and “ ↓” means that lower values are better. factors. As shown in Table 3, we can find that in corporating I and S increases both the frequency and quality of viewpoint interactions. This con firms that considering interactions among agents is essential for enhancing collective reasoning in LLM-based systems. CortexDebate excels in large-scale debates. To explore the influence of LLM agent number and de bating rounds on our CortexDebate, we evaluate the task performance of CortexDebate under different numbers of participating LLM agents and debating rounds. We present the results in Figure 5. We can see that as the number of LLM agents and the debating rounds increase, the task performance of our CortexDebate continues to improve. Moreover, compared with debating rounds, the increase in the number of LLM agents contributes more to the per formance improvement of CortexDebate. These results demonstrate the potential of CortexDebate for application in large-scale debates. CortexDebate retains helpful debates. To fur ther show the effectiveness of the retained edges and corresponding nodes in our CortexDebate, we conduct a detailed analysis. On MATH dataset, we calculate the average debating number (Avg-DN) and RA of every participated LLM agent under the fully-connected graph (FcG) and our proposed debating graph. As shown in Table 4, our pro posed CortexDebate reduces debates among the LLM agents, while improving the performance of every LLM agent. It suggests that our CortexDe bate retains helpful debates while pruning harmful ones.
* * *
## _6 Conclusion_
In this paper, we propose a new MAD method
* * *
termed “CortexDebate” to improve the reasoningabilities of multi-agent interaction systems. Specif ically, our CortexDebate establishes a sparse debat ing graph among participating LLM agents, which reduces input information burdens of LLM agents. Besides, by integrating the McKinsey Trust For mula, our proposed MDM module conducts cred ible evaluations to gradually optimize the debat ing graph, making the debating process equal, in depth, and effective. Due to the above designs, our method alleviates two major issues faced by existing MAD systems ( i.e., too lengthy input con texts and overconfidence-caused unequal debates), and shows superior performance to various state of-the-art MAD methods on various typical tasks. In the future, we plan to continue exploring the potential of CortexDebate in large-scale debates and complex tasks ( i.e., domain expert systems). Limitations Despite the impressive performance of our pro posed CortexDebate, we acknowledge that it has two main limitations. Firstly, as a multi-agent de bate method, compared with single-agent methods, it is inevitable that there will be a decrease in effi ciency and an increase in cost when solving tasks. Secondly, despite the success, the reasoning ability of LLM agents remains an important factor that limits the performance of CortexDebate. Although our proposed CortexDebate improves the debate strategy among LLM agents, mistakes may still occur due to the poor reasoning ability of LLM agents. Acknowledgments This research is supported by NSF of China (Nos: 62336003, 12371510) and NSF of Jiangsu Province (No: BK20241469).
* * *
## _References_
Yushi Bai, Xin Lv, Jiajie Zhang, Hongchang Lyu,
* * *
Jiankai Tang, Zhidian Huang, Zhengxiao Du, Xiao Liu, Aohan Zeng, Lei Hou, et al. 2023. Longbench: A bilingual, multitask benchmark for long context understanding. In Annual Meeting of the Association for Computational Linguistics. Maciej Besta, Nils Blach, Ales Kubicek, Robert Ger stenberger, Michal Podstawski, Lukas Gianinazzi, Joanna Gajda, Tomasz Lehmann, Hubert Niewiadom ski, Piotr Nyczyk, et al. 2024. Graph of thoughts: Solving elaborate problems with large language mod els. In AAAI Conference on Artificial Intelligence.
* * *
## Jonah Brown-Cohen, Geoffrey Irving, and Georgios Pil-
iouras. 2023. Scalable ai safety via doubly-efficient debate. In International Conference on Machine Learning. Chi-Min Chan, Weize Chen, Yusheng Su, Jianxuan Yu, Wei Xue, Shanghang Zhang, Jie Fu, and Zhiyuan Liu. 2023. Chateval: Towards better llm-based eval uators through multi-agent debate. In International Conference on Learning Representations. Justin Chih-Yao Chen, Swarnadeep Saha, and Mohit Bansal. 2023. Reconcile: Round-table conference improves reasoning via consensus among diverse llms. arXiv preprint arXiv:2309.13007. Steffi Chern, Ethan Chern, Graham Neubig, and Pengfei Liu. 2024. Can large language models be trusted for evaluation? scalable meta-evaluation of llms as evaluators via agent debate. arXiv preprint arXiv:2401.16788. Peter Clark, Isaac Cowhey, Oren Etzioni, Tushar Khot, Ashish Sabharwal, Carissa Schoenick, and Oyvind Tafjord. 2018. Think you have solved question an swering? try arc, the ai2 reasoning challenge. arXiv preprint arXiv:1803.05457. Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, et al. 2021. Training verifiers to solve math word problems. arXiv preprint arXiv:2110.14168. Yilun Du, Shuang Li, Antonio Torralba, Joshua B Tenen baum, and Igor Mordatch. 2023. Improving factual ity and reasoning in language models through multia gent debate. In International Conference on Machine Learning. Zhihua Duan and Jialin Wang. 2024. Enhancing multi agent consensus through third-party llm integra tion: Analyzing uncertainty and mitigating halluci nations in large language models. arXiv preprint arXiv:2411.16189. Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Amy Yang, Angela Fan, et al. 2024. The llama 3 herd of models. arXiv preprint arXiv:2407.21783. Yong Guan, Hao Peng, Lei Hou, and Juanzi Li. 2025. Mmd-ere: Multi-agent multi-sided debate for event relation extraction. In Proceedings of the 31st Inter national Conference on Computational Linguistics. Zhitao He, Pengfei Cao, Chenhao Wang, Zhuoran Jin, Yubo Chen, Jiexin Xu, Huaijun Li, Kang Liu, and Jun Zhao. 2024. Agentscourt: Building judicial decision making agents with court debate simulation and legal knowledge augmentation. In Findings of the Associ ation for Computational Linguistics: EMNLP 2024. Mahmood Hegazy. 2024. Diversity of thought elicits stronger reasoning capabilities in multi-agent debate frameworks. arXiv preprint arXiv:2410.12853.Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob Steinhardt. 2020. Measuring massive multitask language under standing. In International Conference on Learning Representations. Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn Song, and Jacob Steinhardt. 2021. Measuring mathematical problem solving with the math dataset. Advances in Neural Information Processing Systems. Jordan Hoffmann, Sebastian Borgeaud, Arthur Mensch, Elena Buchatskaya, Trevor Cai, Eliza Rutherford, Diego de Las Casas, Lisa Anne Hendricks, Johannes Welbl, Aidan Clark, et al. 2022. Training compute optimal large language models. Advances in Neural Information Processing Systems. Qitian Jason Hu, Jacob Bieker, Xiuyu Li, Nan Jiang, Benjamin Keigwin, Gaurav Ranganath, Kurt Keutzer, and Shriyash Kaustubh Upadhyay. 2024. Router bench: A benchmark for multi-llm routing system. arXiv preprint arXiv:2403.12031. Zhe Hu, Hou Pong Chan, Jing Li, and Yu Yin. 2025. Debate-to-write: A persona-driven multi-agent framework for diverse argument generation. In Inter national Conference on Computational Linguistics. Albert Q Jiang, Alexandre Sablayrolles, Arthur Men sch, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas, Florian Bressand, Gianna Lengyel, Guil laume Lample, Lucile Saulnier, et al. 2023. Mistral 7b.arXiv preprint arXiv:2310.06825. Akbir Khan, John Hughes, Dan Valentine, Laura Ruis, Kshitij Sachan, Ansh Radhakrishnan, Edward Grefenstette, Samuel R Bowman, Tim Rocktäschel, and Ethan Perez. 2024. Debating with more persua sive llms leads to more truthful answers. In Interna tional Conference on Machine Learning. Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yu taka Matsuo, and Yusuke Iwasawa. 2022. Large lan guage models are zero-shot reasoners. Advances in Neural Information Processing Systems. Eric Lamarre, T Mansour, and J Tetrault. 2012. Mckin sey on cooperatives. Renhao Li, Minghuan Tan, Derek F Wong, and Min Yang. 2024a. Coevol: Constructing better responses for instruction finetuning through multi-agent coop eration. In Conference on Empirical Methods in Natural Language Processing. Yunxuan Li, Yibing Du, Jiageng Zhang, Le Hou, Pe ter Grabowski, Yeqing Li, and Eugene Ie. 2024b. Improving multi-agent debate with sparse communi cation topology. In Findings of the Association for Computational Linguistics: EMNLP 2024. Jingcong Liang, Rong Ye, Meng Han, Ruofei Lai, Xinyu Zhang, Xuanjing Huang, and Zhongyu Wei. 2024.
* * *
## Debatrix: Multi-dimensinal debate judge with iter-
ative chronological analysis based on llm. In Find ings of the Association for Computational Linguistics: ACL 2024. Tian Liang, Zhiwei He, Wenxiang Jiao, Xing Wang, Yan Wang, Rui Wang, Yujiu Yang, Zhaopeng Tu, and Shuming Shi. 2023. Encouraging divergent think ing in large language models through multi-agent debate. In Annual Meeting Of The Association For Computational Linguistics. Nelson F Liu, Kevin Lin, John Hewitt, Ashwin Paran jape, Michele Bevilacqua, Fabio Petroni, and Percy Liang. 2024a. Lost in the middle: How language models use long contexts. Transactions of the Asso ciation for Computational Linguistics, 12:157–173. Tongxuan Liu, Xingyu Wang, Weizhe Huang, Wenjiang Xu, Yuting Zeng, Lei Jiang, Hailong Yang, and Jing Li. 2024b. Groupdebate: Enhancing the efficiency of multi-agent debate using group discussion. arXiv preprint arXiv:2409.14051. Linhao Luo, Zicheng Zhao, Chen Gong, Gholam reza Haffari, and Shirui Pan. 2024. Graph constrained reasoning: Faithful reasoning on knowl edge graphs with large language models. arXiv preprint arXiv:2410.13080. Julian Michael, Salsabila Mahdi, David Rein, Jack son Petty, Julien Dirani, Vishakh Padmakumar, and Samuel R Bowman. 2023. Debate helps supervise unreliable experts. arXiv preprint arXiv:2311.08702. Chau Pham, Boyi Liu, Yingxiang Yang, Zhengyu Chen, Tianyi Liu, Jianbo Yuan, Bryan A Plummer, Zhaoran Wang, and Hongxia Yang. 2023. Let models speak ciphers: Multiagent debate through embeddings. In International Conference on Learning Representa tions. Kunat Pipatanakul, Phatrasek Jirabovonvisut, Potsawee Manakul, Sittipong Sripaisarnmongkol, Ruangsak Patomwong, Pathomporn Chokchainant, and Kasima Tharnpipitchai. 2023. Typhoon: Thai large language models. arXiv preprint arXiv:2312.13951. P Rajpurkar. 2016. Squad: 100,000+ questions for machine comprehension of text. In Conference on Empirical Methods in Natural Language Processing. David Rein, Betty Li Hou, Asa Cooper Stickland, Jack son Petty, Richard Yuanzhe Pang, Julien Dirani, Ju lian Michael, and Samuel R Bowman. 2023. Gpqa: A graduate-level google-proof q&a; benchmark. arXiv preprint arXiv:2311.12022. Freda Shi, Xinyun Chen, Kanishka Misra, Nathan Scales, David Dohan, Ed H Chi, Nathanael Schärli, and Denny Zhou. 2023. Large language models can be easily distracted by irrelevant context. In Interna tional Conference on Machine Learning.Qiushi Sun, Zhangyue Yin, Xiang Li, Zhiyong Wu, Xipeng Qiu, and Lingpeng Kong. 2024a. Corex: Pushing the boundaries of complex reasoning through multi-model collaboration. In ICLR 2024 Workshop on Large Language Model (LLM) Agents. Xiaoxi Sun, Jinpeng Li, Yan Zhong, Dongyan Zhao, and Rui Yan. 2024b. Towards detecting llms hallu cination via markov chain-based multi-agent debate framework. arXiv preprint arXiv:2406.03075. Yiliu Sun, Yanfang Zhang, Zicheng Zhao, Sheng Wan, Dacheng Tao, and Chen Gong. 2025. Fast-slow thinking: Complex task solving with large language models. arXiv preprint arXiv:2504.08690. Qwen Team. 2024. Qwen2.5: A party of foundation models. Michel Thiebaut de Schotten and Stephanie J Forkel. 2022. The emergent properties of the connected brain. Science, 378(6619):505–510. Lifu Tu, Semih Yavuz, Jin Qu, Jiacheng Xu, Rui Meng, Caiming Xiong, and Yingbo Zhou. 2023. Unlocking anticipatory text generation: A constrained approach for faithful decoding with large language models. In Conference on Empirical Methods in Natural Lan guage Processing. Fanqi Wan, Longguang Zhong, Ziyi Yang, Rui jun Chen, and Xiaojun Quan. 2024. Fusechat: Knowledge fusion of chat models. arXiv preprint arXiv:2408.07990. Haotian Wang, Xiyuan Du, Weijiang Yu, Qianglong Chen, Kun Zhu, Zheng Chu, Lian Yan, and Yi Guan. 2025. Learning to break: Knowledge-enhanced rea soning in multi-agent debate system. Neurocomput ing, 618:129063. Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc V Le, Ed H Chi, Sharan Narang, Aakanksha Chowdhery, and Denny Zhou. 2022. Self-consistency improves chain of thought reasoning in language models. In International Conference on Learning Representa tions. Yubo Wang, Xueguang Ma, Ge Zhang, Yuansheng Ni, Abhranil Chandra, Shiguang Guo, Weiming Ren, Aaran Arulraj, Xuan He, Ziyan Jiang, et al. 2024. Mmlu-pro: A more robust and challenging multi-task language understanding benchmark. Advances in Neural Information Processing Systems. Kai Xiong, Xiao Ding, Yixin Cao, Ting Liu, and Bing Qin. 2023. Examining inter-consistency of large lan guage models collaboration: An in-depth analysis via debate. In Findings of the Association for Computa tional Linguistics: EMNLP 2023. Fangyuan Xu, Weijia Shi, and Eunsol Choi. 2023a. Re comp: Improving retrieval-augmented lms with com pression and selective augmentation. In International Conference on Learning Representations.
* * *
Zhenran Xu, Senbao Shi, Baotian Hu, Jindi Yu, Dong fang Li, Min Zhang, and Yuxiang Wu. 2023b. To wards reasoning in large language models via multi agent peer review collaboration. arXiv preprint arXiv:2311.08152. Ziyi Yang, Fanqi Wan, Longguang Zhong, Tianyuan Shi, and Xiaojun Quan. 2024. Weighted-reward pref erence optimization for implicit model fusion. arXiv preprint arXiv:2412.03187. Zhangyue Yin, Qiushi Sun, Cheng Chang, Qipeng Guo, Junqi Dai, Xuanjing Huang, and Xipeng Qiu. 2023. Exchange-of-thought: Enhancing large lan guage model capabilities through cross-model com munication. In Conference on Empirical Methods in Natural Language Processing. Luke Yoffe, Alfonso Amayuelas, and William Yang Wang. 2024. Debunc: mitigating hallucina tions in large language model agent communica tion with uncertainty estimations. arXiv preprint arXiv:2407.06426. Jintian Zhang, Xin Xu, Ningyu Zhang, Ruibo Liu, Bryan Hooi, and Shumin Deng. 2024a. Exploring collaboration mechanisms for llm agents: A social psychology view. In ICLR 2024 Workshop on Large Language Model (LLM) Agents. Mingqing Zhang, Haisong Gong, Qiang Liu, Shu Wu, and Liang Wang. 2024b. Breaking event rumor detec tion via stance-separated multi-agent debate. arXiv preprint arXiv:2412.04859. A Dataset Details The eight datasets used in our experiments are clas sic datasets that are widely employed to evaluate the performance of agent-based methods. Here, we provide an introduction to the eight datasets used in our experiments. GSM-IC. It is a grade-school math problem dataset derived from GSM8K (Cobbe et al., 2021). For each problem in GSM8K, GSM-IC keeps the base problem description and adds to it one irrel evant sentence that does not affect the solution of the problem. MATH. It is a math dataset containing challeng ing competition mathematics problems. Each of them has a full step-by-step solution. MMLU. It contains 57 types of multiple-choice problems, such as elementary mathematics, US history, computer science, and so on. To acquire high performance on the MMLU datasset, mod els must possess extensive world knowledge and strong problem-solving ability. MMLU-pro. It contains questions sourced from multiple origins, such as MMLU, TheoremQA, andSciBench. Moreover, it expands the option number of each problem from 4 to 10. GPQA. It contains 448 graduate-level question answering problems, covering knowledge in vari ous fields such as biology, physics, and chemistry. ARC-C. It contains complex questions on nat ural science, presented in the form of multiple choice options. LongBench. It is a dataset designed to evaluate the long-context understanding capabilities of mod els. It encompasses six major categories of tasks, including single-document QA, multi-document QA, summarization, few-shot learning, code com pletion, and synthetic tasks. SQuAD. It is a dataset used to evaluate the read ing comprehension ability of models. The dataset requires models to answer different questions from given long texts. B Supplementary Experimental Results In this section, we provide the experimental result data involved in the charts which are presented in Sections 5.2 and 5.3. For Figure 3, we provide the data in Table 7. Compared with the full debate methods ( i.e., MLD, RECONCILE, ChatEval, and MPRC), our Cor texDebate significantly reduces the length of the contextual input for each LLM agent, with a max imum reduction of 70.79%. Moreover, compared with the part debate methods ( i.e., GD and ND), our CortexDebate can reduce the input context length by at least 17.62%. For Figure 4, we provide the data in Table 8. Af ter each debating round, our CortexDebate achieves the highest average score compared with the base line methods, with a global maximal score of 69.41% (67.30% for the baseline methods). C Additional Experiments In this section, we present large-scale experiments of our CortexDebate and baseline methods to fur ther demonstrate the superiority of CortexDebate. Experimental Setup. For each task ( i.e., math, world knowledge question answering, reasoning, and long-context understanding), we conduct ex periments on the more challenging one of the two datasets ( i.e., MATH, MMLU-pro, GPQA, and LongBench). For each adopted dataset, we ex periment on a subset of 1000 examples. Besides, the backbone models and evaluation metrics used
* * *
## Type MethodMATH MMLU-pro GPQA LongBench
RA↑ M-Avg ↑ No Debate MaV 47.40 46.30 29.10 43.35 Full DebateMLD 49.20 48.40 30.60 46.26 RECONCILE 50.70 53.10 30.80 48.33 ChatEval 49.90 49.30 31.10 51.23 PRD 51.20 54.20 32.40 47.67 Part DebateGD 50.30 51.30 34.20 54.58 ND 49.50 49.10 32.80 54.14 Ours 56.30 58.90 36.60 59.63
* * *
## _Table 5: Comparison results on the four datasets. The unit of all the results is “ %”. “↑” means that higher values_
are better. The best records under each metric are highlighted in bold. Type Method MATH MMLU-pro GPQA LongBench
* * *
No Debate MaV 1316.85 2268.10 2567.90 125034.39 Full DebateMLD 6408.39 11412.75 12868.37 585365.43 RECONCILE 6723.84 11334.12 14061.76 605688.14 ChatEval 5571.07 9219.88 12369.62 553114.66 PRD 8849.70 14946.31 18851.29 815449.95 Part DebateGD 4217.23 7265.23 8817.46 447987.68 ND 4175.27 6673.75 7971.60 394905.47 Ours 3355.20 6001.33 6503.76 321109.57
* * *
## _Table 6: Comparison results of average input context length on adopted datasets. Each result represents the average_
token number of input context. The results in gray indicate that they are not included in result comparison, since
* * *
their corresponding method (MaV) is not MAD method. The best records among the MAD methods on each dataset are highlighted in bold. Type Method GSM-IC MATH MMLU MMLU-pro GPQA ARC-C LongBench SQuAD No Debate MaV 1161.18 1277.73 1670.48 2144.39 2653.92 1582.67 105020.51 4724.95 Full DebateMLD 6287.39 6397.97 7905.84 11213.07 12947.80 7605.01 525177.19 23185.66 RECONCILE 6196.09 6574.29 8409.61 11260.15 14107.64 8770.85 525765.69 24112.64 ChatEval 5600.22 5394.71 7325.20 9160.49 12252.56 6918.96 473070.19 20781.94 PRD 7651.62 8652.23 11691.83 14829.46 18837.51 11232.72 735370.99 33350.02 Part DebateGD 3828.95 4139.04 6156.13 7159.45 8906.51 5381.72 367835.88 16073.50 ND 3149.04 4207.18 4740.46 6647.27 8016.54 4311.26 314993.80 14218.49 Ours 2413.35 3262.79 3727.65 5897.94 6340.26 3280.71 230956.05 11965.81
* * *
## _Table 7: Comparison results of average input context length on eight datasets. Each result represents the average_
token number of input context. The results in gray indicate that they are not included in result comparison, since
* * *
their corresponding method (MaV) is not MAD method. The best records among the MAD methods on each dataset are highlighted in bold.
* * *
## Type MethodScore (%) Consensus (%)
1 2 3 4 5 1 2 3 4 5 Full DebateMLD 55.99 58.76 60.32 59.63 59.82 52.88 66.88 82.00 87.88 86.50 RECONCILE 58.95 60.71 67.30 65.64 63.65 73.63 79.25 94.00 95.75 98.63 ChatEval 58.13 63.86 61.74 63.01 62.32 55.75 72.13 67.63 78.63 88.50 PRD 60.22 65.05 66.66 65.50 64.11 64.50 72.75 79.50 86.38 87.88 Part DebateGD 56.94 59.04 64.19 64.87 63.91 48.13 54.75 74.00 78.88 81.75 ND 56.21 58.65 57.52 61.65 62.19 43.38 56.63 66.13 73.00 77.75 Ours 60.31 65.65 67.63 69.10 69.41 51.75 62.13 76.75 89.63 95.50
* * *
## _Table 8: Experimental results of average task scores and consensus proportion for all the methods after each debate_
round. Edge Pruning Strategy RA ↑
* * *
Top-3 54.00 Bot-3 56.00 AMT 52.00 AAT (Ours) 57.00
* * *
## _Table 9: Task performance of CortexDebate with dif-_
ferent edge pruning strategies. “ ↑” means that higher
* * *
values are better. The best record is highlighted in bold. in the experiments are the same as mentioned in Section 5.1. Results. The experimental results are presented in Table 5. Consistent with the experimental results reported in Table 1, our proposed CortexDebate achieves the best performance on all the datasets compared with baseline methods. For instance, CortexDebate achieves a maximal RA of 56.30% on MATH dataset, 58.90% on MMLU-pro dataset, 36.60% on GPQA dataset, and 59.63% on Long Bench dataset, respectively. Moreover, for each method, we calculate the average token numbers of the contexts input to one LLM agent on each dataset and present the results in Table 6. Com pared with the full debate methods ( i.e., MLD, RECONCILE, ChatEval, and MPRC), our Cor texDebate significantly reduces the length of the contextual input for each LLM agent, with a max imum reduction of 65.50%. Moreover, compared with the part debate methods ( i.e., GD and ND), our CortexDebate can reduce the input context length by at least 17.40%. D Performance Investigation In this section, we present additional in-depth in vestigations on our CortexDebate to further analyzeText Similarity Calculation M-Avg ↑ DeTS 57.57 ±0.69 R1-P 56.91 ±3.10 Ours 60.31 ±0.32
* * *
## _Table 10: Task performance of CortexDebate with dif-_
ferent calculation strategies of text similarity. The for
* * *
mat of the results is “(average result) ±(variance)”. “ ↑” means that higher values are better. The best record is highlighted in bold. its effectiveness. D.1 Average-based Edge Pruning As present in Equation (11), our CortexDebate uses the average value as the threshold to prune the edges. To evaluate the effectiveness of adopting the average-based threshold, we conduct experi ments on MATH dataset. Specifically, we com pare the strategy of debating with the agents above the average threshold (AAT) with three alterna tives, namely Top-3 (debating with the top three agents), Bot-3 (excluding the bottom three agents), and AMT (debating with agents above the median threshold). As shown in Table 9, AAT achieves superior performance than the others, which vali dates the effectiveness of the average-based edge pruning. D.2 Text Similarity Calculation In the experiments, we use the text-embedding-3 large model released by OpenAI as the embedding model. For calculation of text similarity, we use cosine similarity which is widely used due to its ef ficiency and robustness to varying input length, and strong empirical performance. To confirm this, on LongBench dataset, we compare our strategy with
* * *
## Threshold Configurations Average Score ↑
w/o recalibration 68.62 [0.9, 0.7, 0.2 ] 68.96 [0.9, 0.6, 0.3 ] 69.03 [0.8, 0.6, 0.2 ] 69.15 [0.8, 0.5, 0.1 ] 68.84 [0.7, 0.5, 0.2 ] 68.72 [0.8, 0.6, 0.3 ](Ours) 69.41
* * *
## _Table 11: Task performance of CortexDebate with dif-_
ferent threshold configurations of the recalibration strat
* * *
egy. “↑” means that higher values are better. The best record is highlighted in bold. ag-nli-DeTS-sentence-similarity-v4 model (DeTS) that is trained on six natural language inference datasets and “DeepSeek R1 + prompt” (R1-P). The average task scores and variances over three runs are reported in Table 10. We can find that our method outperforms the two baseline methods. Moreover, we observe that large language models tend to perform unstably when used for text simi larity estimation, which is reflected by the higher variance across different runs. D.3 Confidence Recalibration As present in Equation (2), our CortexDebate adopts a recalibration strategy to mitigate overconfi dence issue of LLM agents. Following the practice of (Chen et al., 2023), we conduct experiments on different combinations of thresholds. We present the average scores on eight adopted datasets in Ta ble 11. According to the results, this recalibration strategy leads to the improved performance, and the parameter setting in our paper leads to the best performance. Moreover, our method is generally in sensitive to different threshold configurations. This demonstrates the effectiveness and robustness of the proposed confidence recalibration strategy. E Introduction of Evaluation Strategies Here we introduce the details of the evaluation strategies ( i.e., self-evaluation, peer evaluation, part MDM) mentioned in Section 5.3. Self-evaluation. In this strategy, each LLM agent is required to generate a confidence score for its generated answer. Each LLM agent will only de bate with the LLM agents whose confidence scores are above the average of the entire graph. Peer Evaluation. For each LLM agent, its answer is scored by other LLM agents, and the finalscore of the answer is the average of the received scores. Each LLM agent will only debate with the LLM agents whose scores are above the average of the entire graph. MDM (w/o IdandSdin Equation (9)).For McKinsey Trust Formula used in MDM module, this strategy only considers the first two aspects (i.e., credibility and reliability) which evaluate indi vidual abilities, neglecting the last two aspects ( i.e., intimacy and self-orientation) which evaluate the debate effectiveness between two LLM agents. F Prompts in CortexDebate We provide the specific prompts of our proposed CortexDebate in Table 12. For initial answer gener ation, CortexDebate follows (Kojima et al., 2022) and prompts each LLM agent to solve the problem step by step. For answer regeneration, the prompt contains three parts: (a) An instruction that stim ulates LLM agents to generate their new answers and self-confidence scores after scrutinizing other answers. (b) A description of the problem. (c) Some answers generated by other LLM agents. G Introduction of Baseline Methods Here we introduce the details of the baseline meth ods ( i.e., Multi-agent V oting, ChatEval, Multi LLM Debate, RECONCILE, Peer Review Debate, GroupDebate, and Neighbor Debate) in our experi ments. Multi-agent Voting. This method adopts a ma jority voting strategy to aggregate responses from multiple LLM agents. Specifically, each LLM agent independently generates a response to the given question. The final prediction is then deter mined through majority voting. ChatEval. ChatEval uses an extra LLM agent to summarize the debating results in each round of debate. The specific prompt of debating summary used in the experiments is shown in Figure 7. The summary text generated in the current round of debate will be input to each LLM agent as supple mentary information in the next round of debate. Multi-LLM Debate. Firstly, each LLM gener ates an answer to the question. Then, each LLM reads and critiques the answers generated by other LLM agents, and generates its new answer. This step is repeated multiple times. After that, the final answer is obtained through majority voting among the answers generated by all the LLM agents in the last round of debate. The specific prompt used in
* * *
Type Prompt Initial Answer GenerationQuestion: {the description of the question} Please think it step by step and generate an answer and an explanation for your answer. Also, evaluate how confident you are that your answer is correct. Your confidence score should between 0 and 1. The format of your answer must be: Answer: (...) Explanation: (...) Confidence Score: (...) Answer RegenerationQuestion: {the description of the question} There are some answers generated by other LLM agents: One LLM agent answer: {answer} One LLM agent answer: {answer}...... Using these answers as additional information, please generate a new answer and an explanation for your answer. Also, evaluate how confident you are that your answer is correct. Your confidence score should between 0 and 1. The format of your answer must be: Answer: (...) Explanation: (...) Confidence Score: (...)
* * *
## _Table 12: Prompts of our proposed CortexDebate used in the experiments._
the experiments is shown in Figure 6. RECONCILE. Given a problem, each LLM
* * *
first generates an answer and its uncertainty for the answer. Then all LLM agents enter a multi-round debate. Each debating round consists of each LLM generating a revised answer and its new uncertainty based on the answers generated by all other LLM agents from the previous round. After the multi round debate, RECONCILE obtains the final an swer through majority voting. The specific prompt used in the experiments is shown in Figure 8. Peer Review Debate. Similar to RECONCILE, this method also evaluates all the answers in each round of debate. However, this method employs a peer review strategy where the answer generated by each LLM agent is evaluated by other LLM agents. The specific prompt used in the experi ments is shown in Figure 9. GroupDebate. This method divides the LLM agents into several debate groups, with each group conducting internal debates. After the internal de bates, the result of each debate group is summa rized and placed into a shared pool. After that, eachgroup retrieves the debate summaries of all groups from the pool, which serve as the input for all the LLM agents in the next round. The specific prompt used in the experiments is shown in Figure 10. Neighbor Debate. In this method, LLMs only debate with their neighbors. The specific prompt used in the experiments is shown in Figure 11. H CortexDebate Algorithm In this section, we provide the detailed algorithm of our proposed CortexDebate. As present in Al gorithm 1, we strictly follow Sections 3 and 4, and provide the whole execution process of our pro posed CortexDebate.
* * *
## Debating Prompt for Each LLM Agent
`{source_text}`
`{compared_text_one}`
`{compared_text_two}`
`{compared_text_one}`
`{compared_text_one}`
`{chat_history}`
`{role_description}`
`{source_text}`
`{compared_text_one}`
`{compared_text_two}`
`{compared_text_one}`
`{compared_text_one}`
`{chat_history}`
`{role_description}`
These are the solutions to the problem from other agents: [other answers] Using the opinion of other LLM agents as additional advice, can you give an updated response...Debating Prompt for Each LLM Agent These are the solutions to the problem from other agents: [other answers] Using the opinion of other LLM agents as additional advice, can you give an updated response...Figure 6: Prompt of Multi-LLM Debate used in the experiments. Debate Summary [Question] [The Start of Assistant 1's Answer] [The End of Assistant 1's Answer] [The Start of Assistant 2's Answer] [The End of Assistant 2's Answer] [The Start of Assistant 3's Answer] [The End of Assistant 3's Answer] [The Start of Assistant 4's Answer] [The End of Assistant 4's Answer] [System] We would like to request your feedback on the performance of four Al assistants in response to the user question displayed above. Please consider the helpfulness, relevance, accuracy, and level of detail of their responses. Each assistant receives an overall score on a scale of 1 to 10, where a higher score indicates better overall performance. There are a few other referees assigned the same task, it's your responsibility to discuss with them and think critically before you make your final judgment. Here is your discussion history: Now it's your time to talk, please make your talk short and clear, {agent_name}!Debate Summary [Question] [The Start of Assistant 1's Answer] [The End of Assistant 1's Answer] [The Start of Assistant 2's Answer] [The End of Assistant 2's Answer] [The Start of Assistant 3's Answer] [The End of Assistant 3's Answer] [The Start of Assistant 4's Answer] [The End of Assistant 4's Answer] [System] We would like to request your feedback on the performance of four Al assistants in response to the user question displayed above. Please consider the helpfulness, relevance, accuracy, and level of detail of their responses. Each assistant receives an overall score on a scale of 1 to 10, where a higher score indicates better overall performance. There are a few other referees assigned the same task, it's your responsibility to discuss with them and think critically before you make your final judgment. Here is your discussion history: Now it's your time to talk, please make your talk short and clear, {agent_name}!
* * *
## _Figure 7: Debating summary prompt of ChatEval used in the experiments._
`{convincing_samples}`
`{initial_prompt}`
`{convincing_samples}`
`{convincing_samples}`
`{initial_prompt}`
`{convincing_samples}`
Debate Carefully review the following solutions from other agents as additional information, and provide your own answer and step-by-step reasoning to the question. Clearly state which point of view you agree or disagree with and why. There are {majority_num} agents think the answer is {majority_ans}. One agent solution: {agent_reasoning} {agent_ans} {agent_confidence} One agent solution: {agent_reasoning} {agent_ans} {agent_confidence} There are {minority_num}agents think the answer is {minority_ans}. One agent solution: {agent_reasoning} {agent_ans} {agent_confidence}Initial Answer Generation Q: {test_question} Please answer the question with step-by-step reasoning. Also, evaluate your confidence level (between 0.0 and 1.0) to indicate the possibility of your answer being right.Debate Carefully review the following solutions from other agents as additional information, and provide your own answer and step-by-step reasoning to the question. Clearly state which point of view you agree or disagree with and why. There are {majority_num} agents think the answer is {majority_ans}. One agent solution: {agent_reasoning} {agent_ans} {agent_confidence} One agent solution: {agent_reasoning} {agent_ans} {agent_confidence} There are {minority_num}agents think the answer is {minority_ans}. One agent solution: {agent_reasoning} {agent_ans} {agent_confidence}Initial Answer Generation Q: {test_question} Please answer the question with step-by-step reasoning. Also, evaluate your confidence level (between 0.0 and 1.0) to indicate the possibility of your answer being right.Figure 8: Prompt of RECONCILE used in the experiments. Peer Review Here is a solution from another agent: {Answer B} Please examine this agent's reasoning process step by step and offer feedback on its reasoning. You can rate your confidence in your feedback on a scale from 1-10, where 10 indicates the highest level of confidence. Answer Revise Here are the feedbacks for your solution from other agents: One agent feedback: {Feedback B → A} One agent feedback: {Feedback C → A} One agent feedback: {Feedback D → A} One agent feedback: {Feedback E → A} Using other agents’ solutions and feedbacks as additional information, can you provide your answer to the math problem? The original math problem is {Question} Your final answer should be a single numerical number, in the form \boxed{answer}, at the end of your response.Initial Answer Generation Can you solve the following problem? {Question} Explain your reasoning. Your final answer should be in the form \boxed{answer}, at the end of your response.Peer Review Here is a solution from another agent: {Answer B} Please examine this agent's reasoning process step by step and offer feedback on its reasoning. You can rate your confidence in your feedback on a scale from 1-10, where 10 indicates the highest level of confidence. Answer Revise Here are the feedbacks for your solution from other agents: One agent feedback: {Feedback B → A} One agent feedback: {Feedback C → A} One agent feedback: {Feedback D → A} One agent feedback: {Feedback E → A} Using other agents’ solutions and feedbacks as additional information, can you provide your answer to the math problem? The original math problem is {Question} Your final answer should be a single numerical number, in the form \boxed{answer}, at the end of your response.Initial Answer Generation Can you solve the following problem? {Question} Explain your reasoning. Your final answer should be in the form \boxed{answer}, at the end of your response.
* * *
## _Figure 9: Prompt of Peer Review Debate used in the experiments._
Starting Can you solve the following problem?  Explain your reasoning. . Inter-group Debate These are the recent opinions from all groups: Your group response: , Other group responses: . Using the reasoning from all groups as additional advice, can you give an updated answer? Examine your solution and that all groups step by step. .System Welcome to the debate! You are a seasoned debater with expertise in succinctly and persuasively expressing your viewpoints. You will be assigned to debate groups, where you will engage in discussions with fellow participants. The outcomes of each group's deliberations will be shared among all members. It is crucial for you to leverage this information effectively in order to critically analyze the question at hand and ultimately arrive at the correct answer: Best of luck! Intra-group Debate These are the recent opinions from other agents:  Using the opinions carefully as additional advice, can you provide an updated answer? Examine your solution and that other agents step by step. . Summary These are the recent/updated opinions from all agents:  Summarize these opinions carefully and completly in no more than 80 words. Aggregate and put your final answers in parentheses at the end of your response.Starting Can you solve the following problem?  Explain your reasoning. . Inter-group Debate These are the recent opinions from all groups: Your group response: , Other group responses: . Using the reasoning from all groups as additional advice, can you give an updated answer? Examine your solution and that all groups step by step. .System Welcome to the debate! You are a seasoned debater with expertise in succinctly and persuasively expressing your viewpoints. You will be assigned to debate groups, where you will engage in discussions with fellow participants. The outcomes of each group's deliberations will be shared among all members. It is crucial for you to leverage this information effectively in order to critically analyze the question at hand and ultimately arrive at the correct answer: Best of luck! Intra-group Debate These are the recent opinions from other agents:  Using the opinions carefully as additional advice, can you provide an updated answer? Examine your solution and that other agents step by step. . Summary These are the recent/updated opinions from all agents:  Summarize these opinions carefully and completly in no more than 80 words. Aggregate and put your final answers in parentheses at the end of your response.Figure 10: Prompt of GroupDebate Debate used in the experiments.
* * *
## Initial Answer Generation
Can you solve the following problem? {question} Explain your reasoning. Your final answer should be in the form of {{answer}}, at the end of your response.System You are a helpful assistant. Your task is to assist in solving a problem by providing a clear and detailed solution. Your final answer should be in the form of {{answer}}, at the end of your response. Debate These are the solutions to the problem from other agents: One agent solution: {reference solution} One agent solution: {reference solution} One agent solution: {reference solution} One agent solution: {reference solution} Using the solutions from other agents as additional information, can you provide your answer to the problem? The original problem is {question}. Your final answer should be in the form of {{answer}}, at the end of your response.Initial Answer Generation Can you solve the following problem? {question} Explain your reasoning. Your final answer should be in the form of {{answer}}, at the end of your response.System You are a helpful assistant. Your task is to assist in solving a problem by providing a clear and detailed solution. Your final answer should be in the form of {{answer}}, at the end of your response. Debate These are the solutions to the problem from other agents: One agent solution: {reference solution} One agent solution: {reference solution} One agent solution: {reference solution} One agent solution: {reference solution} Using the solutions from other agents as additional information, can you provide your answer to the problem? The original problem is {question}. Your final answer should be in the form of {{answer}}, at the end of your response.Figure 11: Prompt of Neighbor Debate used in the experiments.
* * *
## Algorithm 1 CortexDebate Method
Input: Number of LLM agents n, set of LLM agents {Ai}n i=1, set of directed edges {Ei→j}i,j∈[1,2,...,n], test question Q, maximum debating rounds D, answer extraction ans (·) Output: Final answer Ofinal 1:fori= 1tondo 2: O0 i,H0 i←Ai(Q) ▷Phase 1: Initial Answer Generation 3: Recalibration H0 ibased on Equation (2) 4: Calculate Cibased on Equations (3) and (4) 5: Pi 0←0 6:end for 7:O← O0 i n i=1▷Phase 2: Multi-round Debate 8:ford= 1toDdo 9: fori= 1tondo 10: Calculate Ri dandSi dbased on Equations (5) and (8), respectively 11: forj= 1tondo 12: ifi̸=jthen 13: Calculate Sim dandIi dbased on Equations (6) and (7), respectively 14: Calculate Wd i→jbased on Equation (9) ▷Phase 2, Step 1: Edge Weight Optimization 15: end if 16: end for 17: end for 18: forj= 1tondo 19: Debd j,Othersd j← ∅ ▷Phase 2, Step 2: Sparse Graph Establishment 20: Calculate Wd jbased on Equation (10) 21: fori= 1tondo 22: ifi̸=jthen 23: Calculate Wd i→jbased on Equation (11) 24: ifWd i→j= 1then 25: Debd j←Debd j∪ {Ai} 26: Othersd j←Othersd j∪ Od−1 i 27: end if 28: end if 29: end for 30: Od i,Hd i←Aj  Q, Othersd j ▷Phase 2, Step 3: Answer Regeneration 31: Recalibration Hd ibased on Equation (2) 32: end for 33: is_end←True ▷Phase 2, Step 4: Debate Termination 34: fori= 2tondo 35: ifans  Od 1 ̸=ans  Od i then 36: is_end←False 37: break 38: end if 39: end for 40: O← Od i n i=141: ifis_end =True then 42: break 43: end if 44:end for 45:o←set(O1, O2,···, On) 46: Get Ofinal based on Equation (14) ▷Phase 3: Final Answer Generation 47:return Ofinal
* * *
