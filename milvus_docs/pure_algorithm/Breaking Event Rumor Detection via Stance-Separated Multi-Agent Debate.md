## Breaking Event Rumor Detection via Stance-Separated Multi-Agent Debate
**Abstract**
Mingqing Zhang*1,2, Haisong Gong*1,2, Qiang Liu1,2â€ , Shu Wu1,2, Liang Wang1,2 1New Laboratory of Pattern Recognition (NLPR) State Key Laboratory of Multimodal Artificial Intelligence Systems Institute of Automation, Chinese Academy of Sciences 2School of Artificial Intelligence, University of Chinese Academy of Sciences mingqing.zhang@cripac.ia.ac.cn, gonghaisong2021@ia.ac.cn, {shu.wu, qiang.liu, wangliang }@nlpr.ia.ac.cn The rapid spread of rumors on social media platforms dur ing breaking events severely hinders the dissemination of the truth. Previous studies reveal that the lack of annotated resources hinders the direct detection of unforeseen break ing events not covered in yesterdayâ€™s news. Leveraging large language models (LLMs) for rumor detection holds signif icant promise. However, it is challenging for LLMs to pro vide comprehensive responses to complex or controversial issues due to limited diversity. In this work, we propose the Stance Separated Multi-Agent Debate (S2MAD) to address this issue. Specifically, we firstly introduce Stance Separa tion, categorizing comments as either supporting or oppos ing the original claim. Subsequently, claims are classified as subjective or objective, enabling agents to generate reason able initial viewpoints with different prompt strategies for each type of claim. Debaters then follow specific instructions through multiple rounds of debate to reach a consensus. If a consensus is not reached, a judge agent evaluates the opinions and delivers a final verdict on the claimâ€™s veracity. Extensive experiments conducted on two real-world datasets demon strate that our proposed model outperforms state-of-the-art methods in terms of performance and effectively improves the performance of LLMs in breaking event rumor detection.
* * *
## _1 Introduction_
With the widespread use of social media platforms like
* * *
_â€ Corresponding Authorare characterized by their suddenness, uniqueness, and con-_
Twitter and Weibo, the occurrence of breaking events has provided fertile ground for the spread of rumors. During these events, information asymmetry, emotional intensity, and a lack of official updates often lead to controversy, further fueling rumor dissemination. These controversies heighten information confusion, enabling rumors to spread rapidly (Knapp 1944; Yang et al. 2022). Traditional rumor detection methods depend on large cor pora gathered from public sources to train models, which are then fine-tuned on target data to adapt to specific domains (Bian et al. 2020; Qourbani et al. 2023; Gong et al. 2024b; Cui and Shang 2023; Lin et al. 2023, 2024; Zhang et al. 2024a). However, these methods face signifi cant challenges in Breaking Event Scenarios (BES), which *These authors contributed equally. troversy. This difficulty arises because breaking events oc cur abruptly, making it challenging to gather the necessary reliable datasets in real-time. This consequently limits their effectiveness in sudden, fast-paced events where up-to-date and accurate data are crucial. Recent successes of Large Language Models (LLMs) in various reasoning tasks can be attributed to their extensive knowledge base and generalization capabilities Nam et al. 2024. Given these strengths, LLMs hold significant poten tial in the realm of rumor detection, especially under the challenging conditions typical of BES. In light of this, we propose leveraging the generative capacities and compre hensive human knowledge embedded within LLMs to ad dress the challenges of rumor detection in these scenar ios. Instead of relying solely on individual LLMs, which may lack diversity and robust validation mechanisms, and thus struggle with providing comprehensive and accurate responses to complex or controversial issues, we employ a multi-agent debate mechanism. This approach integrates various agentsâ€™ viewpoints to offer more comprehensive and diverse analyses. By mimicking human debates, we prompt LLM agents to act as different debaters. These agents, with their extensive knowledge and reasoning skills, can thor oughly explore and utilize the limited resources available during BES. To elaborate on the proposed solution, we introduce Stance Separated Multi-Agent Debate (S2MAD), designed explicitly to counter the unique challenges of rumor detec tion on social media during BES. We first introduce Stance Separation, which meticulously categorizes comments on claims into groups that either support or oppose the orig inal claim. The goal is to create a clear division of opin ions, reflecting the varied perspectives typical in controver sial debates. Based on whether the initial claim is subjec tive or objective, each debater is initialized with correspond ing instructions to ensure they can clearly articulate and de fend their assigned stance. Specific debate instructions are crafted for each debater to adhere to through several rounds of debating. The aim of these debates is to reach a consen sus based on the differing viewpoints. If the debaters can not arrive at a consensus through their rounds of contention, we design a judge agent to take both debatersâ€™ opinions into consideration and render a final verdict on the claimâ€™s ve-arXiv:2412.04859v1 [cs.CL] 6 Dec 2024
* * *
## racity. This comprehensive approach ensures that the limited
information available in BES is maximally utilized, leverag ing the LLMsâ€™ abilities to mirror human critical thinking and debate dynamics. Our main contributions can be summarized as follows: â€¢ We propose the Multi-Agent Debate for Rumor De tection (S2MAD) approach, which integrates various agentsâ€™ viewpoints to provide comprehensive analyses. This mechanism allows models to correct and validate each other, improving overall accuracy and reliability. â€¢ The S2MAD approach separates responses to claim into supportive or opposing categories. This helps agents take different stances during debates and thoroughly analyze the postâ€™s veracity. â€¢ Extensive experiments on Twitter-COVID19 and Weibo COVID19 datasets validate the effectiveness of S2MAD, showing improved performance in social media rumor detection during breaking events.
* * *
## _2 Related Work_
2.1 Rumor Detection
* * *
Rumor detection on social media is a critical text mining task aimed at identifying and mitigating the spread of misinfor mation. Researchers employ diverse methods to enhance ru mor detection, crucial for maintaining information integrity on social media (Takahashi and Igata 2012; Cai, Wu, and Lv 2014; Zhang et al. 2015; Sampson et al. 2016; Pathak et al. 2020). In recent years, deep learning has advanced rumor detection by automatically extracting features from text and propagation patterns. Recurrent Neural Networks (RNNs) and their variants have been widely used in this research (Ma et al. 2015, 2016; Ma, Gao, and Wong 2018; Naumzik and Feuerriegel 2022). Researchers have developed new meth ods to analyze the complex structure of rumor propagation, with Graph Neural Networks (GNNs) being particularly sig nificant. GNNs model the structured information in rumor spread, offering deeper insights into its dynamics (Wu et al. 2020; Xu et al. 2022; Zhang et al. 2023; Wu et al. 2023; Tao et al. 2024). As Large Language Models (LLMs) have been widely applied to various tasks, some researchers are now exploring their application in detecting misinformation (Li, Zhang, and Malthouse 2024; Liu et al. 2024; Nan et al. 2024; Yan, Zheng, and Wang 2024; Gong et al. 2024a). However, these methods have not yet fully explored the potential of LLMs in breaking events scenarios. Our research primar ily focuses on this aspect, aiming to uncover the application value of LLMs in these dynamic and challenging environ ments. 2.2 Multi-agent Debate Recent research has explored how to utilize collaborative de bates between agents, either from a single model or multi ple different models, to enhance reasoning capabilities for specific tasks (Chan et al. 2023; Du et al. 2023; Liang et al. 2023; Wang et al. 2024b). Du et al. (2023) proposes a method where each agent provides its own answer to the same question and then refines it based on the responsesfrom other agents. Liang et al. (2023); Wang et al. (2024b) initialized agents with different viewpoints and had them en gage in in-depth debates, stimulating deeper analysis and resulting in a more accurate and comprehensive reasoning process. Additionally, Zhang et al. (2024b) employs Multi LLMs Collaborated Reasoning, using different LLMs as agents to check prediction rationality from various aspects and aggregating their responses through debates, to enhance the capability of video-based human-object interaction de tection. Fang et al. (2024) presets the stances of LLMs and compels them to generate justifications for predetermined answers. By engaging in counterfactual debates with a skep tical critic, this approach overrides the inherent biases of LLMs to achieve hallucination elimination. In this work, we introduced multiple agents and synthesizing their insights and judgments to deeply explore the application of multi agent debate in social media rumor detection during break ing event scenarios.
* * *
## _3 Method_
Generally, S2MAD consists of three key components: stance
* * *
`{(x0, t0),(x1, t1),Â·Â·Â·,(xn, tn)}, where xirepresents the`
separation, initial opinion generation, and multi-agent de bate. The overall framework is shown in Figure 1. For a given social media claim and its comments, we perform stance separation based on the attitudes expressed in the comments, resulting in a support stance comment set P and an oppose stance comment set N. Subsequently, we treat LLM agents as debaters (referred to as DpandDn) and feed each debater with different stance comment set to initialize their default preference to the truthfulness of the claim with specific designed prompt according to their subjectivity. At last, we conduct a multi-agent debate process. If the debate process reaches the maximum number of rounds Mwithout consensus between the two debaters, we designed a judge to attend to each debaterâ€™s opinion and conclude a final predic tion. Algorithm 1 illustrates the detailed process of S2MAD. 3.1 Problem Formulation The task of rumor detection involves distinguishing between true and false events (claims), typically modeled as a binary text classification problem. In our scenario, given a claim calong with its corresponding set of comments T(c) = textual content of ith comment and tiindicates the relative posting time compared to c. The objective is to predict the label yas either True orFalse based on the features of the claim itself and the set of comments. 3.2 Stance Separation In a debate process, it is essential for each debater to have their own stance as a foundation for the following debate process. To initiate the stance for each debater based on the comments, we first need to provide each agent with a suit able subset of all comments T(c). Building upon previous research (Wang et al. 2024a), we aim to obtain two subsets fromT(c)that representing contrasting stances. One subset comprises comments that support the claim, while the other consists of comments that oppose the claim. It is important
* * *
`{â€œReasonâ€: â€œâ€, â€œScoreâ€: â€œâ€ }Do not output any irrelevant content.`
Claim: Breaking: A child under the age of 18 has died of coronavirus in Los Angeles, public health officials announce, in a rare and tragic case. Initial Opinion ( Subjective /Non-subjective) Theoriginal post about achild dying from COVID -19inLosAngeles isdeemed Real.Supporting comments express sympathy andemphasize thevirus's impact onallages, while rebuttals raise accuracy concerns.Common knowledge confirms thatCOVID -19canaffect children, making thepost plausible. After considering theopinions ofother agents andreevaluating thepost andcomments, theclaim ofachild dying from COVID -19inLosAngeles appears Fake.Thelack ofconcrete evidence, supporting comments without credible sources, andvalid skepticism suggest theneed forcaution. Multi -Agent Debate Based ontheupdated information provided byother agents andtheanalysis oftheir views :theoriginal post about a child dying from COVID -19inLosAngeles isdeemed Real.Emotional responses andcommon knowledge support its plausibility despite valid skepticism. Based onthearguments from both AgentpandAgentn,there isinsufficient concrete evidence tofully support theclaim ofachild dying ofcoronavirus inLosAngeles. Emotional responses andawareness ofCOVID -19'simpact onallages arenoted, butthelack ofverifiable information andskepticism inthecomments suggest caution.Therefore, theclaim ofachild under 18dying ofcoronavirus inLosAngeles isdeemed Fake.Support Comments ð‘· Oppose Comments ð‘µ honest journalism So sad. terrible! â‹¯â‹¯Fake news! U hv no proofSources? â‹¯â‹¯ â‹¯â‹¯.....................â‹¯â‹¯ Stance Separation Stance Separation The original post about achild dying from COVID -19inLosAngeles isdeemed Fake.Supporting comments lack specific evidence, andrebuttal comments raise valid skepticism.Given therarity ofsevere cases inchildren andthe need forconcrete details, further verification isnecessary.AgentpAgentn JudgeClaim: Breaking: A child under the age of 18 has died of coronavirus in Los Angeles, public health officials announce, in a rare and tragic case. Initial Opinion ( Subjective /Non-subjective) Theoriginal post about achild dying from COVID -19inLosAngeles isdeemed Real.Supporting comments express sympathy andemphasize thevirus's impact onallages, while rebuttals raise accuracy concerns.Common knowledge confirms thatCOVID -19canaffect children, making thepost plausible. After considering theopinions ofother agents andreevaluating thepost andcomments, theclaim ofachild dying from COVID -19inLosAngeles appears Fake.Thelack ofconcrete evidence, supporting comments without credible sources, andvalid skepticism suggest theneed forcaution. Multi -Agent Debate Based ontheupdated information provided byother agents andtheanalysis oftheir views :theoriginal post about a child dying from COVID -19inLosAngeles isdeemed Real.Emotional responses andcommon knowledge support its plausibility despite valid skepticism. Based onthearguments from both AgentpandAgentn,there isinsufficient concrete evidence tofully support theclaim ofachild dying ofcoronavirus inLosAngeles. Emotional responses andawareness ofCOVID -19'simpact onallages arenoted, butthelack ofverifiable information andskepticism inthecomments suggest caution.Therefore, theclaim ofachild under 18dying ofcoronavirus inLosAngeles isdeemed Fake.Support Comments ð‘· Oppose Comments ð‘µ honest journalism So sad. terrible! â‹¯â‹¯Fake news! U hv no proofSources? â‹¯â‹¯ â‹¯â‹¯.....................â‹¯â‹¯ Stance Separation Stance Separation The original post about achild dying from COVID -19inLosAngeles isdeemed Fake.Supporting comments lack specific evidence, andrebuttal comments raise valid skepticism.Given therarity ofsevere cases inchildren andthe need forconcrete details, further verification isnecessary.AgentpAgentn JudgeFigure 1: Given an input claim and its related comments, we first categorize the comments based on their stance towards the claim into supporting comments Pand opposing comments N. Furthermore, we classify the claim based on whether it is a subjective expression or not, and design corresponding guiding prompts for different types of claim (subjective and non subjective). Utilizing LLMs as agents, we evaluate the truthfulness of the claim based on these different stances and generate an initial opinion. Subsequently, we conduct a multi-agent debate. If the agents do not reach a consensus after a maximum of Mrounds, a judge is designed to derive the final prediction. to note that comments not aligning with common sense are excluded from this process. To achieve this, we employ a LLM as a scorer, assigning positive scores in the range (0.0,1.0]to comments support ing the claim and negative scores in the range [âˆ’1.0,0.0) to those opposing the claim. Comments that do not adhere to common sense are assigned a score of 0.0. This scoring process can be mathematically expressed as: si=LLM(pss, c, x i), s iâˆˆ[âˆ’1,1] (1) where sirepresents the score of the ith comment, pssis the prompt template used for scoring: Instruction : First, check whether the comment conforms to common knowledge. If it does not conform to common sense, the score is 0.0. Does the comment support that the source post is real? If it supports, it will be scored from the range (0.0,1.0]according to the degree of support. The higher the score, the stronger the support. If it does not support, it will be scored from the range [âˆ’1.0,0.0) according to the degree of opposition. The stronger the degree of opposition, the lower the score. Claim : [Claim] Comment : [Comment] Now, output your answer strictly in the following format: Typically, comments on a claim ccan be plentiful, and to ensure a clear stance, we selectively choose the top kcom ments that are most supportive and most opposing to form the support stance comment set Pand oppose stance com ment set N, mathematically expressed as: P={xi|siâˆˆtopk({si|si>0}, k)} N={xi|siâˆˆtopk({âˆ’si|si<0}, k)}(2) where topk is a function that selects khighest scores. 3.3 Initial Opinion Generation We need to guide agents in analyzing claim content for ru mor detection and use the support stance comment set P and oppose stance comment set Nobtained above to gener ate initial opinions with different stances for each agent. Ac cording to previous research Liu et al. 2024, proper guid ance can enable agents to more effectively capture reasoning clues. On social media, claims generally fall into two main categories: subjective claims and objective claims. Objec tive claims involve facts, data, and verifiable information, while subjective claims express personal thoughts, such as opinions, evaluations, and emotions. These claims can con vey positive or negative sentiments. Given the significant differences in language and information between subjective
* * *
## claims and objective claims, distinguishing between these
types allows for more targeted prompts, thereby improving the accuracy of agentsâ€™ judgments. Specifically, we leverage the powerful reasoning capabil ities of LLMs to classify whether a claim is a subjective ex pression from the user and accordingly design subjectivity prompt template: Claim : [Claim] Does the claim only express the personal opinions of the user? Please answer Yes or No. By categorizing the claim into subjective expressions and objective statements, we can fully utilize the reasoning and sentiment analysis capabilities of agents, thereby enhanc ing the accuracy and efficiency of rumor detection. Next, we designed prompts to let agents generate their own initial opinions respectively. Specifically, we designed correspond ing guiding prompts for different types of claims(subjective claims and non-subjective claims). Subjective expression claims On social media, subjective expression claims often carry emotional tones and personal viewpoints, potentially including humor, satire, or cultural references. By considering these factors, we have designed corresponding prompt templates: Instruction : You need to do: (1) Evaluate whether the content of the source post is a reasonable subjective expression, considering context, humor, satire, and cultural references. (2) Evaluate whether the content of the original post may damage public trust in government or public figures. Claim : [Claim] Comment : [Comment] At the end, please choose the answer from the following options: Fake, Real. The first point, we designed Reasonability Prompts to en able agents to accurately determine whether a post reason ably expresses a personal opinion; the second point, we de signed Trust Impact Prompts to help agents assess potential damage to public trust in government or public figures, iden tifying rumors that could undermine public confidence. Non-subjective claims Non-subjective claims on social media are usually based on facts, data, or verifiable informa tion. These claims require carefully designed prompt tem plates to ensure their authenticity and reliability: Instruction :You need to do: (1) Evaluate the consistency and reliability of the sup porting comments. Look for specific facts, data, or cred ible sources. (2) Assess the consistency and reliability of the rebuttal comments. Identify any valid points that raise doubts. (3) Consider common sense and general knowledge re lated to the topic. Claim : [Claim] Comment : [Comment]Algorithm 1: S2MAD: Stance Separated Multi-Agent De bate Require: Debate claim c, Comments set T(c), Rounds M, Agents Dp, Dn, J Ensure: Final prediction Ë†y 1:procedure S2MAD( c,T(c), M) 2: //Stance Separation 3: forxiinT(c)do 4: siâ†Score xiby LLM Eq. 1 5: end for 6: Pâ†Select kcomments with highest scores 7: Nâ†Select kcomments with lowest scores Eq. 2 8: //Initial Opinion Generation 9: isSub â†Get claim câ€™s subjectivity 10: h0 pâ†Initialize DpwithPbased on isSub 11: h0 nâ†Initialize DnwithNbased on isSub Eq. 3 12: //Multi-Agent Debate 13: forj= 1toMdo 14: hj pâ†Update Dpâ€™s opinion with hjâˆ’1 n 15: hj nâ†Update Dnâ€™s opinion with hjâˆ’1 p Eq. 4 16: end for 17: ifhp=hnthen 18: return hp 19: else 20: return Judge Jâ€™s determination Eq. 5 21: end if 22:end procedure At the end, please choose the answer from the following options: Fake, Real. First, we created Support Evaluation Prompts to help agents focus on facts and credible sources. Second, we de signed Rebuttal Evaluation Prompts to enable agents to crit ically analyze opposing viewpoints and uncover any poten tial flaws or discrepancies. Moreover, we introduced Com mon Sense Verification Prompts to encourage agents to use general knowledge and logical reasoning to assess the plau sibility of claims, thereby effectively identifying misinfor mation. We generate initial opinion for claims through agents, mathematically expressed as: h0 p=LLM(pio, c, P) h0 n=LLM(pio, c, N)(3) Where piois the prompt used for generating the initial opin ion, which refers to the guiding prompts for different types of claims mentioned above. h0 prepresents the initial opinion based on the support stance comment set P, andh0 ndenotes the initial opinion based on the opposing stance comment set N. 3.4 Multi-Agent Debate In our method, instead of relying on a single agent to predict the veracity of claims, we use multiple agents to fully lever
* * *
`{Dp, Dn}. In the first round of the debate, we prompt each`
age their diverse knowledge. During the initial opinion gen eration phase, we prompt each agent to independently rea son whether a given claim is a rumor by analyzing the state ment text and comments with different stances. However, agent reasoning sometimes produces incorrect answers, and some recent studies (Gou et al. 2023; Liang et al. 2023; Zhang et al. 2024b) have also shown that agents struggle to self-correct their responses without external feedback. To address this, we incorporate a debate scheme to integrate the responses from different agents. Generally, the framework is composed of two components, which are detailed as follows: Agent as Debater Once we obtain the initial viewpoints, we designate the agents to participate in the debate. We have two agents referred to as debaters, denoted as D= debater to generate a response based on the initial opinion (h0 pandh0 n) produced by the other debaters. In subsequent rounds, each debater continues to respond based on the de bate history provided by the other debater until the maxi mum number of debate rounds Mis reached. Mathemati cally expressed as: hj p=LLM(pd, hjâˆ’1 n), jâ‰¤M hj n=LLM(pd, hjâˆ’1 p), jâ‰¤M(4) Where hj irepresents the response generated by debater iin the j-th round of the debate, pdis the prompt used for the debate: Instruction : These are the opinions from other debaters. Based on the opinion of yourself and other debaters, you need: use critical thinking to analyze the views of others. Other debatersâ€™ opinions : [Other answers] Can you give an updated response, at the end, please choose the answer from the following options: Fake, Real. In multi-round debates, to ensure that debaters are not stubborn and can deeply analyze and understand the logic and basis of arguments, we have included a critical prompt. This helps them better understand the topic of the debate and related issues, identify logical flaws, biases, or insuffi cient evidence in the opposing arguments, and thus provide stronger rebuttals. Agent as Judge Furthermore, in multi-round debates where opinions do not converge to a consensus answer, it is crucial to designate an Judge, referred to as J, to deduce the final answer. Judge Jwill assess all arguments (Agent pâ€™s last reply and Agent nâ€™s last reply) made throughout the de bate, analyze their logical coherence and the level of evi dence supporting them, and synthesize all the information to determine the most persuasive conclusion. Prompt pjde signed for the judge is as follows: Instruction : Please judge whether the post text is fake or real based on the following debate between Agent pand Agent n: Claim : [Claim]Agent parguing : [Agent pâ€™s last reply] Agent narguing : [Agent nâ€™s last reply] Consider the arguments presented by both agents and make your determination about the authenticity of the post. At the end, must choose the answer from the fol lowing options: Fake, Real. Mathematically expressed as: Ë†y=LLM(pj, hM p, hM n) (5) where Ë†ydenotes the consensus answer of debaters, and hM p andhM nrepresent the reasoning of the debaters in the final round of the debate.
* * *
## _4 Experiment_
In this section, we evaluate the proposed methods using
* * *
widely used (Lin et al. 2022, 2023; Zhang et al. 2024a) real world social media rumor datasets related to the breaking event of COVID-19, namely Twitter-COVID19 and Weibo COVID19. We conducted extensive experiments to validate the effectiveness of our approach. 4.1 Datasets We use breaking events related datasets, Twitter COVID19 Lin et al. 2022 and Weibo-COVID19 Lin et al. 2022, to evaluate the S2MAD approach. These datasets are sourced from two popular social media plat formsâ€”Twitter and Weibo. The Twitter-COVID19 dataset consists of English rumor datasets with conversation threads in tweets, providing a rich context for analysis. On the other hand, the Weibo-COVID19 dataset comprises Chi nese rumor datasets with a similar composition structure. These datasets are annotated with two labels: Rumor and Non-Rumor, which are used for the binary classification of rumors and non-rumors. We employ a range of commonly used evaluation met rics to validate the effectiveness of the proposed method. Firstly, Accuracy (ACC.) measures the proportion of cor rectly predicted samples, reflecting overall prediction pre cision. Secondly, the F1-score integrates Precision and Re call, comprising Positive F1 (RF1), Negative F1 (NF1), and Macro-average F1 (Mac-F1), assessing performance for dif ferent classes and overall average performance. 4.2 Settings We compared our model with several baseline models: the GCN-based model BiGCN Bian et al. 2020, the adver sarial contrastive learning framework ACLR-BiGCN Lin et al. 2022 built on top of BiGCN, the zero-shot rumor detection model based on prompt learning RPL Lin et al. 2023, and the test-time training model for rumor detection T3RD (Zhang et al. 2024a). In our experiments, to adapt to real-world breaking events, we tested the BiGCN, ACLR BiGCN, and T3RD models in a zero-shot setting. These models were trained on public datasets(Twitter dataset (Ma, Gao, and Wong 2017) or Weibo dataset Ma et al. 2016) and
* * *
ModelsTwitter-COVID19 Weibo-COVID19 ACC. Mac-F1 RF1 NF1 ACC. Mac-F1 RF1 NF1 BiGCN 0.593 0.557 0.647 0.468 0.619 0.534 0.720 0.349 ACLR-BiGCN 0.692 0.614 0.785 0.444 0.670 0.594 0.754 0.435 RPL 0.727 0.697 0.793 0.601 0.745 0.719 0.804 0.634 T3RD 0.735 0.701 0.808 0.593 0.797 0.788 0.832 0.743 Qwen1.5 0.565 0.565 0.580 0.549 0.698 0.670 0.762 0.578 Qwen1.5 + S2MAD 0.645 +.080 0.645 +.080 0.634 +.054 0.655 +.106 0.737 +.039 0.757 +.087 0.765 +.003 0.748 +.170 GPT3.5 0.643 0.567 0.749 0.384 0.762 0.682 0.843 0.520 GPT3.5 + S2MAD 0.765 +.122 0.737 +.170 0.827 +.078 0.647 +.263 0.810 +.048 0.764 +0.082 0.869 +.026 0.658 +.138
* * *
## _Table 1: Rumor detection results on the target datasets. GPT3.5 refers to the GPT-3.5 Turbo model, and Qwen1.5 refers to the_
Qwen1.5-7b-chat model. then directly tested on target datasets to evaluate their perfor
* * *
mance and adaptability. This approach allows for a better as sessment of the modelsâ€™ effectiveness in handling breaking events. Additionally, we used Qwen1.5-7b-chat and GPT 3.5 turbo as our baseline models under zero-shot settings. Specifically, for each sample, we randomly selected 40 com ments and used Vanilla Prompt Liu et al. 2024 for infer ence. S2MAD was performed in a zero-shot setting, requir ing no training data, using all samples from the evaluation dataset. During the stance separation phase, we utilized glm 3-turbo as our scorer. Initially, we employed Qwen1.5-7b chat as the base debater model for our experiments. Addi tionally, we validated S2MADâ€™s performance by conduct ing experiments with GPT-3.5 turbo as the debater. In our experiments, the open-source Qwen1.5-7b-chat model was run on a remote machine server with 2 NVIDIA RTX 3090 (24G) GPUs. During the experiments, to accommodate the contentious nature of opinions in breaking events, we set the temperature to 0.2, while all other hyperparameters for gen erating LLM outputs were kept at their default settings. 4.3 Overall Performance
* * *
## _Table 1 shows the comparison of our method with vari-_
ous baseline models on two real-world datasets related to
* * *
breaking events, Twitter-COVID19 and Weibo-COVID19. The data clearly indicates that S2MAD consistently and sig nificantly improves model performance across both datasets, regardless of whether Qwen1.5-7b-chat or GPT-3.5 turbo is used as the backbone model. Leveraging the strong reasoning capabilities of the propa gation graph structure, the four graph-based detection mod els exhibit good performance, with T3RD showing the best results. Our results with the two backbone models, Qwen1.5-7b-chat and GPT-3.5 turbo, reveal that LLMs, when applied directly to social media rumor detection dur ing breaking events in a zero-shot setting, do not demon strate strong reasoning capabilities. This finding corrobo rates our earlier discussion. However, when our methodis applied to these two backbone models, their perfor mance improves significantly. Specifically, on the Twitter COVID19 dataset, S2MAD enhances Qwen1.5-7b-chat by 8% and GPT-3.5 turbo by 12.2%. On the Weibo-COVID19 dataset, S2MAD boosts Qwen1.5-7b-chat by 3.9% and GPT 3.5 turbo by 4.8%. Furthermore, our proposed S2MAD method achieves the best performance when used with the GPT-3.5 turbo backbone model. These results strongly demonstrate the superiority of S2MAD. 4.4 Ablation Study Debate Rounds First, we analyzed the impact of debate rounds in S2MAD using GPT-3.5 turbo. In Figure 2, we in creased the number of debate rounds while keeping the num ber of debaters fixed at two. We found that when the number of debate rounds did not exceed two, S2MAD showed a sig nificant performance improvement on the Twitter-COVID19 and Weibo-COVID19 datasets. However, we observed that when the number of debate rounds exceeded two, the accu racy of the model on both datasets showed slight fluctua tions, and the final performance was similar to that of two rounds of debate. We speculate that after the second round, the debaters have largely reached a consensus on the veracity of most samples, and only on a few samples where consen sus was not reached did the Judge show unstable responses based on the debatersâ€™ fully expressed viewpoints. There fore, we default to conducting two rounds of debate. Effectiveness of Stance Separation We examined the im pact of stance separation in S2MAD using GPT-3.5 turbo. To ensure the validity of the validation, we no longer fil tered comments based on their support or opposition to the claims. Instead, we randomly sampled up to forty comments from each claim, divided them into two equal parts, and as signed them to two agents, thereby removing any specific stance bias. The agents then generated initial perspectives based on their respective sets of comments, while other ex perimental settings remained consistent with S2MAD. As shown in Table 2, removing stance separation led to a de cline in S2MADâ€™s performance across both datasets. These
* * *
## Model Twitter-COVID19 Weibo-COVID19
Full Model 0.765 0.810 w/o Stance 0.648 0.674 w/o Non-Sub 0.575 0.801 w/o Sub 0.703 0.706 w/o Debate 0.645 0.737
* * *
## _Table 2: Experimental results of S2MAD with different_
settings using GPT-3.5 turbo. â€œw/o Stanceâ€ indicates no
* * *
stance separation. â€œw/o Non-Sub/Subâ€ indicates applying the initial opinion prompt corresponding to subjective/non subjective claims to the entire dataset. â€œw/o Debateâ€ inde cates no debate process. 012345 Weibo-COVID190.650.700.750.800.85Value 012345 Twitter-COVID190.600.650.700.750.80Value ACC. Mac-F1012345 Weibo-COVID190.650.700.750.800.85Value 012345 Twitter-COVID190.600.650.700.750.80Value ACC. Mac-F1
* * *
## _Figure 2: Comparison of different numbers of debate rounds_
in our proposed S2MAD approach using GPT-3.5 turbo. results clearly demonstrate the effectiveness of stance sep
* * *
aration in improving the performance of S2MAD, thereby supporting our assertion that categorizing comments based on their stance towards the original claim allows the model to better understand and process the information, leading to more accurate rumor detection. Effectiveness of Categorizing the Claim Further, we ex tensively studied the impact of categorizing claims into sub jective and non-subjective types in our approach using GPT 3.5 turbo. Specifically, during the initial opinion generation phase, we stopped distinguishing between subjective and non-subjective claims and instead used the initial opinion prompts for both types across the entire dataset. Our experi mental results, presented in Table 2, show that the full model achieved an accuracy of 0.765 on the Twitter-COVID19 dataset and 0.810 on the Weibo-COVID19 dataset. When the initial opinion prompt for non-subjective claims was removed (â€œw/o Non-Subâ€), the accuracy dropped to 0.575 on Twitter-COVID19 and 0.801 on Weibo-COVID19. Sim ilarly, removing the prompt for subjective claims (â€œw/o Subâ€) resulted in accuracies of 0.703 on Twitter-COVID19 and 0.706 on Weibo-COVID19. These findings demonstrate that categorizing claims into subjective and non-subjective types significantly enhances our modelâ€™s performance. By using appropriate prompts for each claim type, our approach achieves better results in social media rumor detection dur ing breaking events. 01020304050 all Twitter_Covid190.400.600.80Value BiGCN ACLR-BiGCN T3RD S2MAD 01020304050 all Weibo_Covi190.30.40.50.60.70.8Value BiGCN ACLR-BiGCN T3RD S2MAD01020304050 all Twitter_Covid190.400.600.80Value BiGCN ACLR-BiGCN T3RD S2MAD 01020304050 all Weibo_Covi190.30.40.50.60.70.8Value BiGCN ACLR-BiGCN T3RD S2MADFigure 3: Early detection performance is evaluated at differ ent checkpoints based on the post count. Effectiveness of Debate We investigated the effectiveness of incorporating debate in our rumor detection approach. Specifically, keeping other experimental settings the same, we compared the performance of our complete approach ar chitecture with a single-agent reasoning model to evaluate the impact of debate on our approach. In Table 2, â€œ/o De bateâ€ denotes the removal of the debate component, where a single agent performs reasoning under the same conditions. As shown, removing the debate from S2MAD led to a de crease in accuracy of 12% on the Twitter-COVID19 dataset and 7.3% on the Weibo-COVID19 dataset. These findings clearly demonstrate the effectiveness of the multi-agent de bate in improving the performance of our model in social media rumor detection during breaking events. This sup ports our earlier assertion that the debate process allows for a more thorough examination of claims by considering mul tiple perspectives, leading to more accurate and reliable de tection outcomes. 4.5 Early Detection Early detection plays a crucial role in effectively prevent ing the widespread dissemination of rumors, making it an important metric for model evaluation. By setting different checkpoints, models are assessed using the post count up to each detection point. The performance of each model is eval uated using the Macro F1 score. Figure 3 illustrates the early detection performance of our model compared to others at various checkpoints. Notably, our model maintains compet itive or superior performance across different checkpoints on both datasets. This indicates that our approach is particularly adept at identifying potential rumors before they gain signif icant traction, thereby providing a valuable tool in combat ing the spread of false information online.
* * *
## _5 Conclusion_
In this paper, we investigate the use of multi-agent debate
* * *
for rumor detection in social media within the context of breaking event scenarios. We propose an approach called S2MAD. S2MAD uses LLMs to separate comments based on their stance towards the claim. Furthermore, we catego rize claims into subjective and non-subjective types and de sign different guide prompts to direct agents in reasoning about the veracity of the claims based on comments with different stances to generate initial opinions. Subsequently, we conduct a multi-agent debate based on these initial opin
* * *
ions. Finally, after reaching the maximum number of de bate rounds, if the agents have not reached a consensus on the veracity of the claims, we employ a designed Judge to provide the final conclusion. We validated the effectiveness of S2MAD through extensive experiments on two datasets related to breaking event scenarios, Weibo-COVID19 and Twitter-COVID19.
* * *
## _References_
Bian, T.; Xiao, X.; Xu, T.; Zhao, P.; Huang, W.; Rong,
* * *
Y.; and Huang, J. 2020. Rumor Detection on Social Me dia with Bi-Directional Graph Convolutional Networks. In The Thirty-Fourth AAAI Conference on Artificial Intelli gence, AAAI 2020, The Thirty-Second Innovative Applica tions of Artificial Intelligence Conference, IAAI 2020, The Tenth AAAI Symposium on Educational Advances in Artifi cial Intelligence, EAAI 2020, New York, NY, USA, February 7-12, 2020, 549â€“556. AAAI Press. Cai, G.; Wu, H.; and Lv, R. 2014. Rumors detection in Chi nese via crowd responses. In Wu, X.; Ester, M.; and Xu, G., eds., 2014 IEEE/ACM International Conference on Ad vances in Social Networks Analysis and Mining, ASONAM 2014, Beijing, China, August 17-20, 2014, 912â€“917. IEEE Computer Society. Chan, C.-M.; Chen, W.; Su, Y.; Yu, J.; Xue, W.; Zhang, S.; Fu, J.; and Liu, Z. 2023. Chateval: Towards better llm based evaluators through multi-agent debate. ArXiv preprint, abs/2308.07201. Cui, W.; and Shang, M. 2023. KAGN: knowledge-powered attention and graph convolutional networks for social media rumor detection. Journal of big Data, 10(1): 45. Du, Y.; Li, S.; Torralba, A.; Tenenbaum, J. B.; and Mor datch, I. 2023. Improving factuality and reasoning in lan guage models through multiagent debate. ArXiv preprint, abs/2305.14325. Fang, Y.; Li, M.; Wang, W.; Lin, H.; and Feng, F. 2024. Counterfactual Debating with Preset Stances for Hallucina tion Elimination of LLMs. ArXiv preprint, abs/2406.11514. Gong, H.; Ma, H.; Liu, Q.; Wu, S.; and Wang, L. 2024a. Navigating the Noisy Crowd: Finding Key Information for Claim Verification. ArXiv preprint, abs/2407.12425. Gong, H.; Xu, W.; Wu, S.; Liu, Q.; and Wang, L. 2024b. Het erogeneous Graph Reasoning for Fact Checking over Texts and Tables. In Proceedings of the AAAI Conference on Arti ficial Intelligence, volume 38, 100â€“108. Gou, Z.; Shao, Z.; Gong, Y.; Shen, Y.; Yang, Y.; Duan, N.; and Chen, W. 2023. Critic: Large language models can self-correct with tool-interactive critiquing. ArXiv preprint, abs/2305.11738. Knapp, R. H. 1944. A psychology of rumor. Public opinion quarterly, 8(1): 22â€“37. Li, X.; Zhang, Y.; and Malthouse, E. C. 2024. Large Language Model Agent for Fake News Detection. ArXiv preprint, abs/2405.01593. Liang, T.; He, Z.; Jiao, W.; Wang, X.; Wang, Y.; Wang, R.; Yang, Y.; Tu, Z.; and Shi, S. 2023. Encouraging divergentthinking in large language models through multi-agent de bate. ArXiv preprint, abs/2305.19118. Lin, H.; Ma, J.; Chen, L.; Yang, Z.; Cheng, M.; and Guang, C. 2022. Detect Rumors in Microblog Posts for Low Resource Domains via Adversarial Contrastive Learning. In Findings of the Association for Computational Linguistics: NAACL 2022, 2543â€“2556. Seattle, United States: Associa tion for Computational Linguistics. Lin, H.; Ma, J.; Yang, R.; Yang, Z.; and Cheng, M. 2024. Towards low-resource rumor detection: Unified contrastive transfer with propagation structure. Neurocomputing, 578: 127438. Lin, H.; Yi, P.; Ma, J.; Jiang, H.; Luo, Z.; Shi, S.; and Liu, R. 2023. Zero-shot rumor detection with propagation structure via prompt learning. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 37, 5213â€“5221. Liu, Q.; Tao, X.; Wu, J.; Wu, S.; and Wang, L. 2024. Can Large Language Models Detect Rumors on Social Media? ArXiv preprint, abs/2402.03916. Ma, J.; Gao, W.; Mitra, P.; Kwon, S.; Jansen, B. J.; Wong, K.; and Cha, M. 2016. Detecting Rumors from Microblogs with Recurrent Neural Networks. In Kambhampati, S., ed., Proceedings of the Twenty-Fifth International Joint Confer ence on Artificial Intelligence, IJCAI 2016, New York, NY, USA, 9-15 July 2016, 3818â€“3824. IJCAI/AAAI Press. Ma, J.; Gao, W.; Wei, Z.; Lu, Y.; and Wong, K. 2015. Detect Rumors Using Time Series of Social Context Information on Microblogging Websites. In Bailey, J.; Moffat, A.; Ag garwal, C. C.; de Rijke, M.; Kumar, R.; Murdock, V.; Sellis, T. K.; and Yu, J. X., eds., Proceedings of the 24th ACM Inter national Conference on Information and Knowledge Man agement, CIKM 2015, Melbourne, VIC, Australia, October 1923, 2015, 1751â€“1754. ACM. Ma, J.; Gao, W.; and Wong, K.-F. 2017. Detect Rumors in Microblog Posts Using Propagation Structure via Kernel Learning. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), 708â€“717. Vancouver, Canada: Association for Computational Linguistics. Ma, J.; Gao, W.; and Wong, K.-F. 2018. Rumor Detection on Twitter with Tree-structured Recursive Neural Networks. InProceedings of the 56th Annual Meeting of the Associa tion for Computational Linguistics (Volume 1: Long Papers), 1980â€“1989. Melbourne, Australia: Association for Compu tational Linguistics. Nam, D.; Macvean, A.; Hellendoorn, V.; Vasilescu, B.; and Myers, B. 2024. Using an llm to help with code understand ing. In Proceedings of the IEEE/ACM 46th International Conference on Software Engineering, 1â€“13. Nan, Q.; Sheng, Q.; Cao, J.; Hu, B.; Wang, D.; and Li, J. 2024. Let Silence Speak: Enhancing Fake News Detection with Generated Comments from Large Language Models. ArXiv preprint, abs/2405.16631. Naumzik, C.; and Feuerriegel, S. 2022. Detecting false ru mors from retweet dynamics on social media. In Proceed ings of the ACM web conference 2022, 2798â€“2809.
* * *
Pathak, A. R.; Mahajan, A.; Singh, K.; Patil, A.; and Nair, A. 2020. Analysis of techniques for rumor detection in social media. Procedia Computer Science, 167: 2286â€“2296. Qourbani, A.; Khodaparast, M.; Othman Yahya, R.; Habibi, M.; Nouralishahi, A.; and Rezaeipanah, A. 2023. Toward rumor detection in social networks using multi-layer autoen coder neural network. Social Network Analysis and Mining, 14(1): 8. Sampson, J.; Morstatter, F.; Wu, L.; and Liu, H. 2016. Lever aging the Implicit Structure within Social Media for Emer gent Rumor Detection. In Mukhopadhyay, S.; Zhai, C.; Bertino, E.; Crestani, F.; Mostafa, J.; Tang, J.; Si, L.; Zhou, X.; Chang, Y.; Li, Y.; and Sondhi, P., eds., Proceedings of the 25th ACM International Conference on Information and Knowledge Management, CIKM 2016, Indianapolis, IN, USA, October 24-28, 2016, 2377â€“2382. ACM. Takahashi, T.; and Igata, N. 2012. Rumor detection on twit ter. In The 6th International Conference on Soft Computing and Intelligent Systems, and The 13th International Sympo sium on Advanced Intelligence Systems, 452â€“457. IEEE. Tao, X.; Wang, L.; Liu, Q.; Wu, S.; and Wang, L. 2024. Se mantic Evolvement Enhanced Graph Autoencoder for Ru mor Detection. In Proceedings of the ACM on Web Confer ence 2024, 4150â€“4159. Wang, B.; Ma, J.; Lin, H.; Yang, Z.; Yang, R.; Tian, Y.; and Chang, Y. 2024a. Explainable Fake News Detection With Large Language Model via Defense Among Compet ing Wisdom. In Proceedings of the ACM on Web Conference 2024, 2452â€“2463. Wang, Q.; Wang, Z.; Su, Y.; Tong, H.; and Song, Y. 2024b. Rethinking the Bounds of LLM Reasoning: Are Multi-Agent Discussions the Key? ArXiv preprint, abs/2402.18272. Wu, J.; Xu, W.; Liu, Q.; Wu, S.; and Wang, L. 2023. Ad versarial contrastive learning for evidence-aware fake news detection with graph neural networks. IEEE Transactions on Knowledge and Data Engineering. Wu, Z.; Pi, D.; Chen, J.; Xie, M.; and Cao, J. 2020. Rumor detection based on propagation graph neural network with attention mechanism. Expert systems with applications, 158: 113595. Xu, W.; Wu, J.; Liu, Q.; Wu, S.; and Wang, L. 2022. Evidence-aware fake news detection with graph neural net works. In Proceedings of the ACM web conference 2022, 2501â€“2510. Yan, Y.; Zheng, P.; and Wang, Y. 2024. Enhancing large language model capabilities for rumor detection with knowledge-powered prompting. Engineering Applications of Artificial Intelligence, 133: 108259. Yang, Z.; Ma, J.; Chen, H.; Lin, H.; Luo, Z.; and Chang, Y. 2022. A Coarse-to-fine Cascaded Evidence-Distillation Neural Network for Explainable Fake News Detection. In Proceedings of the 29th International Conference on Com putational Linguistics, 2608â€“2621. Gyeongju, Republic of Korea: International Committee on Computational Linguis tics.Zhang, H.; Liu, X.; Yang, Q.; Yang, Y.; Qi, F.; Qian, S.; and Xu, C. 2024a. T3RD: Test-Time Training for Rumor Detec tion on Social Media. In Proceedings of the ACM on Web Conference 2024, 2407â€“2416. Zhang, H.; Zhang, W.; Qu, H.; and Liu, J. 2024b. En hancing Human-Centered Dynamic Scene Understanding via Multiple LLMs Collaborated Reasoning. ArXiv preprint, abs/2403.10107. Zhang, K.; Yu, J.; Shi, H.; Liang, J.; and Zhang, X.-Y. 2023. Rumor detection with diverse counterfactual evi dence. In Proceedings of the 29th ACM SIGKDD Con ference on Knowledge Discovery and Data Mining, 3321â€“ 3331. Zhang, Q.; Zhang, S.; Dong, J.; Xiong, J.; and Cheng, X. 2015. Automatic detection of rumor on social network. In Natural Language Processing and Chinese Computing: 4th CCF Conference, NLPCC 2015, Nanchang, China, October 9-13, 2015, Proceedings 4, 113â€“122. Springer.
* * *
